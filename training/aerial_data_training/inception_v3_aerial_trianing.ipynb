{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adampotton/MDM3-Rep-3/blob/main/inception_v3_aerial_trianing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArnHp1gGfHfL"
      },
      "source": [
        "# Mounting Google Drive and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdLp-2Wbdo6U",
        "outputId": "12bed47c-4dbc-4ed9-ddae-11a8effbc55a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files, drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPg69w9fcGf-"
      },
      "source": [
        "# Loading Numpy Data Arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM3cA_OMfD8X",
        "outputId": "65d32fd9-7aaa-4b41-db63-e458fb80ae0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n",
            "['aerial_pseudotsuga_menziesii', 'aerial_picea_abies', 'aerial_betula_spec', 'aerial_abies_alba', 'aerial_pinus_nigra', 'aerial_larix_decidua', 'aerial_larix_kaempferi', 'aerial_pinus_strobus', 'aerial_pinus_sylvestris', 'aerial_fraxinus_excelsior', 'aerial_fagus_sylvatica', 'aerial_acer_pseudoplatanus', 'aerial_quercus_robur', 'aerial_quercus_petraea', 'aerial_quercus_rubra', 'aerial_tilia_spec', 'aerial_populus_spec', 'aerial_prunus_spec', 'aerial_alnus_spec', 'train_images.npy', 'train_labels.npy', 'test_images.npy', 'test_labels.npy', 'val_images.npy', 'val_labels.npy']\n"
          ]
        }
      ],
      "source": [
        "#if you get an error the first time just run it again\n",
        "os.chdir('../../../')\n",
        "!pwd\n",
        "os.chdir('content')\n",
        "os.chdir(r'drive/MyDrive/Aerial Data')\n",
        "print(os.listdir())\n",
        "\n",
        "train_labels = np.load('train_labels.npy')\n",
        "train_images = np.load('train_images.npy')\n",
        "test_labels = np.load('test_labels.npy')\n",
        "test_images = np.load('test_images.npy')\n",
        "val_labels = np.load('val_labels.npy')\n",
        "val_images = np.load('val_images.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# If Not using colab the following can be used to import the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-7lEmQDmf06beJUD3NaQk82125NGqYpm\n",
            "To: c:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\data\\aerial_data\\val_labels.npy\n",
            "100%|██████████| 38.9k/38.9k [00:00<?, ?B/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-54Z1sN8uYgNG66MwWumRTlYMJmX7wWw\n",
            "From (redirected): https://drive.google.com/uc?id=1-54Z1sN8uYgNG66MwWumRTlYMJmX7wWw&confirm=t&uuid=510fa68d-caf5-408a-9a59-45cf796a8dc1\n",
            "To: c:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\data\\aerial_data\\val_images.npy\n",
            "100%|██████████| 171M/171M [00:14<00:00, 11.6MB/s] \n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1aJkI-7d5KCAAYCoXkrEcHVXvSsXc_-8n\n",
            "From (redirected): https://drive.google.com/uc?id=1aJkI-7d5KCAAYCoXkrEcHVXvSsXc_-8n&confirm=t&uuid=337c523f-4708-43a3-8990-a3ffb1a8c052\n",
            "To: c:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\data\\aerial_data\\train_labels.npy\n",
            "100%|██████████| 1.36G/1.36G [01:57<00:00, 11.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vKs-th9eHU_oMXTasVm-FD9Dximer82Q\n",
            "To: c:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\data\\aerial_data\\train_images.npy\n",
            "100%|██████████| 310k/310k [00:00<00:00, 4.35MB/s]\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download(r'https://drive.google.com/file/d/1-7lEmQDmf06beJUD3NaQk82125NGqYpm/view?usp=drive_link', r'../../data/aerial_data/val_labels.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1-54Z1sN8uYgNG66MwWumRTlYMJmX7wWw/view?usp=drive_link', r'../../data/aerial_data/val_images.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1vKs-th9eHU_oMXTasVm-FD9Dximer82Q/view?usp=drive_link', r'../../data/aerial_data/train_labels.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1aJkI-7d5KCAAYCoXkrEcHVXvSsXc_-8n/view?usp=drive_link', r'../../data/aerial_data/train_images.npy',fuzzy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading numpy files from memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "#system specific\n",
        "folder = '../../data/aerial_data'\n",
        "train_images = np.load(os.path.join(folder, 'train_images.npy'))\n",
        "train_labels = np.load(os.path.join(folder, 'train_labels.npy'))\n",
        "val_images = np.load(os.path.join(folder, 'val_images.npy'))\n",
        "val_labels = np.load(os.path.join(folder, 'val_labels.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zFEOXefkLVV",
        "outputId": "0d22abcb-ead4-4531-a9a7-7379b33404c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data:\n",
            "images shape:\n",
            "(3688, 304, 304, 4)\n",
            "labels shape:\n",
            "(3688,)\n",
            "val data:\n",
            "images shape:\n",
            "(462, 304, 304, 4)\n",
            "labels shape:\n",
            "(462,)\n",
            "image format check:\n",
            "[[ 55  50  54 ...  79  85  78]\n",
            " [ 58  55  51 ...  86  88  83]\n",
            " [ 58  60  51 ...  89  82  83]\n",
            " ...\n",
            " [165 175 173 ... 119 105 111]\n",
            " [172 169 167 ... 114 116 123]\n",
            " [174 170 162 ... 128 131 133]]\n",
            "label check:\n",
            "Fagus_sylvatica\n"
          ]
        }
      ],
      "source": [
        "#inspecting data\n",
        "print(\"train data:\")\n",
        "print(\"images shape:\")\n",
        "print(train_images.shape)\n",
        "print(\"labels shape:\")\n",
        "print(train_labels.shape)\n",
        "\n",
        "#print(\"test data:\")\n",
        "#print(\"images shape:\")\n",
        "#print(test_images.shape)\n",
        "#print(\"labels shape:\")\n",
        "#print(test_labels.shape)\n",
        "\n",
        "print(\"val data:\")\n",
        "print(\"images shape:\")\n",
        "print(val_images.shape)\n",
        "print(\"labels shape:\")\n",
        "print(val_labels.shape)\n",
        "\n",
        "print(\"image format check:\")\n",
        "print(train_images[0,:,:,0])\n",
        "\n",
        "print(\"label check:\")\n",
        "print(train_labels[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhZptPJtcRl5"
      },
      "source": [
        "# Performing Feature Extraction on Inception-V3, which is currently trained on image net\n",
        "Adapted from: <https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/finetuning_torchvision_models_tutorial.ipynb#scrollTo=NiFT4EYmprqG>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HzgA5ZHDUKo"
      },
      "source": [
        "# Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYkVMsSdcXlF",
        "outputId": "50a4c307-1d55-46d0-a133-67aa651d0f24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bench\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda is available =  True\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Number of tree species categories\n",
        "num_classes = 19\n",
        "\n",
        "# Batch size for training (should be a power of 2 if training on the GPU and is limited by memory)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "#True if we are just training the output layer of the network\n",
        "feature_extract = True\n",
        "\n",
        "print(\"cuda is available = \",torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00lUag6fDajn"
      },
      "source": [
        "# Function For training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aK47xAU8eqqM"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=True):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        print(outputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            #deep copying the model if its performance has improved\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print(\"epoch {} complete\".format(epoch))\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights and return best model\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XIgz_TRkoyI"
      },
      "source": [
        "# Ensuring that model parameters are not used during training since we are only interested in the final layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P_1vlVVeknVh"
      },
      "outputs": [],
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMnqaEq2ibRf"
      },
      "source": [
        "# Defining function to reshape the model to account for the number of classes\n",
        "By default Inception-v3 has 1000 classes as it is trained on imageNet, whilst our dataset has 19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pelFjz0lprqH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def initialize_inception_model(num_classes, feature_extract, use_pretrained=True, model=None):\n",
        "  # Initialize these variables which will be set in this if statement. Each of these\n",
        "  #   variables is model specific.\n",
        "  model_ft = None\n",
        "  input_size = 0\n",
        "\n",
        "  \"\"\" Inception v3\n",
        "  Be careful, expects (299,299) sized images and has auxiliary output\n",
        "  \"\"\"\n",
        "  if model is None:\n",
        "    if use_pretrained:\n",
        "      model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', weights='Inception_V3_Weights.IMAGENET1K_V1')\n",
        "    else:\n",
        "      model_ft = models.inception_v3('pytorch/vision:v0.10.0', 'inception_v3')\n",
        "  else:\n",
        "    model_ft = model\n",
        "  #\"switching off\" training on the majority of the model weights if feature_extract\n",
        "  set_parameter_requires_grad(model_ft, feature_extract)\n",
        "  # Handle the auxilary net\n",
        "  num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "  model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "  # Handle the primary net\n",
        "  num_ftrs = model_ft.fc.in_features\n",
        "  model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "  input_size = 299\n",
        "  #adding an initial 1x1 convolutional layer to handle 4 channel input and reduce it to 3 channels\n",
        "  input_embedding_module = nn.Sequential(nn.Conv2d(4, 3, kernel_size=1))#keeping this module seperate for future use\n",
        "  #wrapping the pretrained modek and the input embedding module together for a combined model\n",
        "  model_ft = nn.Sequential(input_embedding_module, model_ft)\n",
        "\n",
        "  return model_ft, input_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvCE732PQME9"
      },
      "source": [
        "# Initializing Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdqIslSxQF09",
        "outputId": "578c2b85-4a50-49de-b584-a22c3bfe9a98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\bench/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=19, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=19, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#initializing model\n",
        "#Initialize the model for this run\n",
        "model_ft, input_size = initialize_inception_model(num_classes, feature_extract, use_pretrained=True)\n",
        "print(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc8biARA66oL"
      },
      "source": [
        "# Formatting Loaded Data and creating data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Categories: ['Abies_alba' 'Acer_pseudoplatanus' 'Alnus_spec.' 'Betula_spec.'\n",
            " 'Fagus_sylvatica' 'Fraxinus_excelsior' 'Larix_decidua' 'Larix_kaempferi'\n",
            " 'Picea_abies' 'Pinus_nigra' 'Pinus_strobus' 'Pinus_sylvestris'\n",
            " 'Populus_spec.' 'Prunus_spec.' 'Pseudotsuga_menziesii' 'Quercus_petraea'\n",
            " 'Quercus_robur' 'Quercus_rubra' 'Tilia_spec.']\n",
            "Train Labels Numeric: [ 4 12  8 17  4  4 14  3  8 11]\n",
            "Val Categories: ['Abies_alba' 'Acer_pseudoplatanus' 'Alnus_spec.' 'Betula_spec.'\n",
            " 'Fagus_sylvatica' 'Fraxinus_excelsior' 'Larix_decidua' 'Larix_kaempferi'\n",
            " 'Picea_abies' 'Pinus_nigra' 'Pinus_strobus' 'Pinus_sylvestris'\n",
            " 'Populus_spec.' 'Prunus_spec.' 'Pseudotsuga_menziesii' 'Quercus_petraea'\n",
            " 'Quercus_robur' 'Quercus_rubra' 'Tilia_spec.']\n",
            "Val Labels Numeric: [ 3  2  4 14  8  2  4  2  2  8]\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "#converting numpy arrays into RGB PIL images, ignoring the IR channel for now\n",
        "train_images_pil = [Image.fromarray(image) for image in train_images[:,:,:,1:]]\n",
        "val_images_pil = [Image.fromarray(image) for image in val_images[:,:,:,1:]]\n",
        "#creating one hot encoding labels from numpy arrays\n",
        "train_categories, train_labels_numeric = np.unique(train_labels, return_inverse=True)\n",
        "val_categories, val_labels_numeric = np.unique(val_labels, return_inverse=True)\n",
        "\n",
        "print(\"Train Categories:\", train_categories)\n",
        "print(\"Train Labels Numeric:\", train_labels_numeric[0:10])\n",
        "print(\"Val Categories:\", val_categories)\n",
        "print(\"Val Labels Numeric:\", val_labels_numeric[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categories are consistent between train and val sets\n"
          ]
        }
      ],
      "source": [
        "if np.all(train_categories == val_categories):\n",
        "    print(\"categories are consistent between train and val sets\")\n",
        "    categories = train_categories = val_categories\n",
        "else:\n",
        "    raise ValueError(\"Train and val categories don't match\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iBUGQu37VXm",
        "outputId": "52176e3f-8f40-4acd-9999-3c833de0f5a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        }
      ],
      "source": [
        "# normalization for training and validation\n",
        "# hardcoded normalization values for the model\n",
        "# right now validation and training transform is the same and no augmentation\n",
        "image_transform = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "#creating a custom pytorch dataset for the numpy arrays we loaded earlier\n",
        "#with applied transforms\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "          \n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "#creating training and validation pytorch datasets\n",
        "training_dataset = CustomDataset(train_images_pil, train_labels_numeric, image_transform)\n",
        "val_dataset = CustomDataset(val_images_pil, val_labels_numeric, image_transform)\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True),\n",
        "                    'val': torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIbdexT1A2l8"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxVIfck-A54U",
        "outputId": "e37efeb0-d405-4b4e-d3fe-cff967a9b7df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sending model to cuda:0\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "number of parameters to train = 4\n",
            "parameter 0: torch.Size([19, 768])\n",
            "parameter 1: torch.Size([19])\n",
            "parameter 2: torch.Size([19, 2048])\n",
            "parameter 3: torch.Size([19])\n"
          ]
        }
      ],
      "source": [
        "## Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"sending model to\",device)\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Creating the Optimizer\n",
        "if feature_extract:\n",
        "  params_to_update = []\n",
        "  for name,param in model_ft.named_parameters():\n",
        "    if param.requires_grad==True:\n",
        "      params_to_update.append(param)\n",
        "      print(\"\\t\",name)\n",
        "else:\n",
        "  params_to_update = model_ft.parameters()\n",
        "\n",
        "print(\"number of parameters to train =\",len(params_to_update))\n",
        "for i, param in enumerate(params_to_update):\n",
        "  print(\"parameter {}:\".format(i),param.shape)\n",
        "\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcrgqxB0tf9E",
        "outputId": "b811be3e-cb65-4996-ec9c-6a62127fe24b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "tensor([[-4.9718e-01, -4.8370e-01, -3.1744e-01, -2.8775e-01,  2.5357e-01,\n",
            "         -3.8921e-02, -1.1774e-01, -1.8936e-01,  5.0018e-01,  3.5547e-01,\n",
            "          9.6847e-01,  3.8564e-01,  2.6615e-01, -1.2514e-01,  5.5356e-01,\n",
            "         -1.4196e-01, -3.4161e-01,  2.1829e-01,  3.1945e-02],\n",
            "        [ 3.4900e-02, -5.5534e-01,  3.4044e-02,  5.8297e-02,  3.3350e-01,\n",
            "         -2.1746e-01,  6.1971e-02,  1.2572e-01, -1.1469e-01,  5.2622e-01,\n",
            "          2.5835e-01,  2.1484e-01, -3.5044e-01, -4.1788e-01,  6.7111e-02,\n",
            "         -1.3402e-01, -6.0881e-02,  3.6824e-01, -2.1206e-04],\n",
            "        [-4.5222e-02, -4.5376e-02,  4.4272e-01, -1.6767e-01,  2.2726e-01,\n",
            "          3.6450e-01,  1.4987e-01,  5.4698e-01,  4.2293e-02,  1.3217e-01,\n",
            "          2.2159e-01,  5.8948e-01, -2.0537e-01, -2.5204e-01,  3.5813e-01,\n",
            "          4.8925e-01,  3.3458e-01, -3.1526e-01, -4.1019e-01],\n",
            "        [-1.0634e-01, -2.2952e-01, -3.9815e-01, -3.1800e-01, -1.0479e-01,\n",
            "         -5.2794e-01,  1.4630e-01,  1.5989e-01,  4.7698e-02, -1.9439e-01,\n",
            "          5.5413e-01, -2.9397e-02,  1.5513e-01, -1.5636e-02,  4.6322e-01,\n",
            "          3.6827e-01, -3.4348e-01,  2.4668e-01,  1.8299e-01],\n",
            "        [ 5.3870e-02,  1.3939e-01,  6.4400e-01,  8.5010e-02,  5.1737e-01,\n",
            "         -1.1273e-01,  1.0300e-01,  9.3107e-02,  1.8091e-01,  2.8502e-01,\n",
            "          5.7181e-01,  3.4577e-02,  8.0985e-02, -2.8821e-02,  4.9993e-01,\n",
            "          6.0031e-01,  3.9032e-02, -6.8323e-02,  5.2451e-03],\n",
            "        [-1.8022e-01, -2.7129e-01, -6.0938e-02,  2.8892e-01,  3.0511e-01,\n",
            "         -3.6789e-01, -5.5253e-02,  1.4180e-01,  5.1019e-02,  2.2641e-01,\n",
            "          8.8162e-02,  2.7344e-01,  1.2381e-01,  1.3352e-01,  1.6222e-01,\n",
            "          6.3341e-01,  1.8952e-01, -1.0677e-01,  1.7418e-01],\n",
            "        [-5.4251e-01, -4.9622e-01,  2.0752e-01,  2.5689e-01,  2.2247e-02,\n",
            "          3.3360e-01, -5.3079e-02,  3.2956e-01, -6.3965e-02,  5.5739e-01,\n",
            "         -2.3070e-01,  8.5018e-02,  5.4313e-02, -2.6701e-01,  5.4650e-01,\n",
            "          3.9155e-01, -1.5603e-01, -3.8813e-01,  2.2287e-02],\n",
            "        [ 2.1478e-01, -1.4001e-01,  3.4131e-01,  2.9088e-01,  1.9827e-02,\n",
            "         -2.1130e-01,  1.4644e-01, -1.2587e-01, -1.9840e-01,  2.7298e-01,\n",
            "          2.8757e-01,  1.9468e-01, -3.1901e-01, -3.1842e-01,  6.4382e-01,\n",
            "          1.6333e-01,  1.2770e-01, -4.8296e-02, -1.6481e-01],\n",
            "        [-2.0479e-02, -2.7517e-01,  7.7553e-02, -6.2944e-02,  2.6558e-01,\n",
            "         -1.9555e-01, -1.8181e-01,  9.8046e-02,  3.0661e-02,  3.1427e-01,\n",
            "          3.0461e-01,  5.4459e-02, -1.7084e-01,  3.7747e-02,  1.4985e-01,\n",
            "          2.7595e-01,  5.7993e-01, -1.7237e-01, -4.7614e-02],\n",
            "        [-9.3493e-02, -5.2477e-01,  4.5976e-01,  2.3284e-01,  2.0551e-01,\n",
            "         -1.1108e-01,  2.2487e-01, -8.9737e-02,  2.7495e-02,  6.7190e-01,\n",
            "          7.2392e-01,  7.0909e-02, -2.8913e-01, -3.5052e-01,  2.9906e-01,\n",
            "          5.9890e-01, -9.8287e-01,  1.1318e-01,  3.4374e-01],\n",
            "        [ 4.5210e-01, -2.1591e-01,  1.2916e-01, -1.1767e-01,  3.8843e-01,\n",
            "         -3.8170e-01,  6.8299e-03,  3.3907e-01, -3.2507e-02,  8.0238e-01,\n",
            "          2.8000e-01, -5.5686e-02,  4.2473e-02,  2.0825e-01,  7.1223e-01,\n",
            "          3.1182e-01,  2.2298e-01, -3.0803e-01,  7.9441e-02],\n",
            "        [ 2.5110e-01, -3.9249e-01, -2.1939e-01,  1.0743e-01,  4.5468e-01,\n",
            "         -2.5203e-01, -7.1846e-02, -8.2781e-02,  8.3127e-02,  2.5370e-01,\n",
            "          2.4412e-01, -1.2674e-01, -4.9499e-02,  2.7238e-01,  1.3816e-01,\n",
            "          6.4830e-01,  2.5468e-01, -1.8196e-01, -8.7305e-02],\n",
            "        [-2.6098e-01, -1.9100e-02, -1.3581e-01, -1.6914e-01,  2.2931e-01,\n",
            "         -9.0392e-02,  1.6940e-01,  4.6188e-02,  4.3165e-02,  2.8495e-01,\n",
            "          2.5856e-01,  3.9992e-01,  3.3506e-01, -2.4070e-02, -1.8316e-01,\n",
            "          2.5571e-01,  2.7088e-01,  3.8571e-01,  4.6385e-01],\n",
            "        [-1.9253e-01, -2.0402e-01, -1.0265e-01,  2.8395e-01,  4.5883e-01,\n",
            "         -6.9057e-01, -1.2162e-01,  6.3442e-01,  4.4114e-02,  9.2139e-02,\n",
            "          1.6232e-01, -5.7108e-02, -5.2541e-02,  2.7752e-01,  8.3793e-01,\n",
            "          1.6367e-01,  5.6440e-01, -3.7968e-03, -9.0858e-02],\n",
            "        [-1.0860e-01, -8.2912e-01, -6.3086e-02,  1.1912e-01,  4.6341e-01,\n",
            "          5.6986e-02,  2.1334e-01,  4.1376e-02, -4.2973e-01,  1.9598e-01,\n",
            "          6.2628e-02,  2.7800e-01, -3.4700e-02,  1.0661e-01,  2.9976e-01,\n",
            "          7.0579e-02, -5.2413e-02, -1.8525e-01, -5.6449e-02],\n",
            "        [ 4.1424e-02, -5.0613e-01,  7.1766e-01, -6.7394e-02,  8.0855e-01,\n",
            "         -5.1850e-01,  6.1028e-01, -5.3362e-02,  1.1600e-01,  6.9227e-02,\n",
            "         -1.5990e-01,  8.7387e-02,  1.3208e-01, -7.5468e-02,  4.1815e-01,\n",
            "          1.3233e-01, -1.0776e-02, -3.5448e-01, -4.9551e-01],\n",
            "        [ 1.9756e-01, -3.3359e-01, -9.5083e-02,  3.4130e-02, -2.6997e-01,\n",
            "          7.7313e-02,  1.6282e-01, -1.6146e-01, -4.7150e-02,  4.7414e-01,\n",
            "         -2.9632e-01,  2.6122e-01, -1.7698e-01, -4.3884e-01,  4.5638e-01,\n",
            "          3.4212e-01,  3.2416e-02, -4.0902e-01, -1.5394e-01],\n",
            "        [-9.9509e-02, -2.4258e-01,  3.8574e-01, -2.7202e-02,  2.7678e-01,\n",
            "         -3.3890e-02, -1.0407e-01, -6.6063e-02, -8.2823e-02,  2.8938e-01,\n",
            "          2.2762e-01,  6.2139e-02,  3.0297e-02, -5.9159e-02, -1.9464e-01,\n",
            "          2.5134e-01,  4.8336e-01, -3.4481e-01, -9.6532e-02],\n",
            "        [-2.5366e-01, -3.0403e-01,  5.4079e-01,  3.7277e-01,  1.4416e-01,\n",
            "          9.3912e-02,  4.5938e-01,  2.3311e-01, -3.7996e-01,  2.9118e-01,\n",
            "          5.6010e-01,  2.1147e-02,  3.3828e-02, -4.9162e-01,  3.3963e-01,\n",
            "          2.3732e-01, -1.4748e-01, -1.9823e-01,  2.5577e-02],\n",
            "        [-2.5239e-01, -5.2610e-01,  3.2131e-01, -3.9584e-01,  5.2641e-01,\n",
            "          4.2705e-02,  2.5615e-01,  7.0159e-01,  3.9518e-01,  5.7941e-01,\n",
            "          6.8585e-02,  2.2448e-01, -1.2839e-01, -8.1912e-03,  1.4291e-01,\n",
            "          1.7446e-01, -4.4922e-02,  8.3563e-02,  6.3149e-02],\n",
            "        [-7.4403e-02, -2.9503e-01,  3.8719e-01,  3.3533e-01,  1.2349e-01,\n",
            "          5.9980e-01,  3.9734e-01,  2.0735e-01,  2.4650e-01,  3.9138e-01,\n",
            "         -4.0812e-02,  1.9850e-01, -1.2101e-02, -3.7696e-02,  1.2340e-01,\n",
            "          3.0382e-02, -9.9579e-02, -6.4279e-01, -3.5863e-01],\n",
            "        [ 6.1692e-02, -5.0141e-02,  2.7783e-01, -1.2213e-03,  3.3155e-01,\n",
            "         -4.8392e-01, -2.0787e-01,  1.8656e-01, -1.5602e-01,  2.1106e-01,\n",
            "          1.7376e-01,  2.5584e-01, -3.1297e-01, -4.3730e-02,  3.0436e-01,\n",
            "         -3.8418e-02,  3.5935e-01, -3.3714e-01,  4.2470e-01],\n",
            "        [-2.2818e-01, -1.5252e-01,  2.3408e-02, -1.3634e-02,  6.1850e-01,\n",
            "         -4.1132e-02,  2.1910e-02, -2.0305e-01, -1.6846e-01, -6.4904e-03,\n",
            "          1.0470e-01,  2.7861e-02, -2.4762e-01, -7.3740e-02,  1.6624e-01,\n",
            "         -1.6076e-02,  2.1384e-01, -5.4995e-01, -3.0678e-01],\n",
            "        [-2.1696e-01, -5.6525e-01,  1.1941e-02, -2.8396e-01,  1.7409e-01,\n",
            "          2.6338e-01,  3.3988e-01,  2.4217e-01,  2.1485e-01,  2.7489e-01,\n",
            "         -3.8188e-01,  1.6570e-01, -3.3050e-01, -9.6744e-02,  3.3135e-01,\n",
            "          1.5517e-01, -1.9653e-02,  5.7919e-01,  1.8332e-01],\n",
            "        [-1.3875e-01, -2.6246e-01,  4.3936e-01, -4.9618e-02,  3.5918e-01,\n",
            "          9.6597e-02,  4.0995e-01,  4.8499e-01, -7.9512e-02,  8.2101e-01,\n",
            "          3.9957e-01, -3.5405e-02,  2.4819e-01,  1.6126e-01,  8.0512e-01,\n",
            "          2.7813e-01, -2.0878e-01, -4.5978e-01, -1.6933e-02],\n",
            "        [-6.8040e-01, -8.5324e-01,  5.7191e-01, -2.7032e-01,  2.7592e-01,\n",
            "         -1.0003e-01,  2.1592e-01, -3.3381e-01,  4.6527e-02,  3.8100e-01,\n",
            "         -1.3930e-02,  2.0318e-02, -1.0541e-01, -6.4102e-02,  2.6674e-01,\n",
            "          1.5460e-01, -4.6046e-02, -3.7672e-01, -1.5245e-01],\n",
            "        [ 9.2658e-02, -4.3708e-01,  4.0929e-01, -1.6616e-01,  1.6322e-01,\n",
            "         -5.5561e-01,  4.8394e-01, -2.2883e-02, -5.5255e-01,  4.9224e-01,\n",
            "          1.2675e-01, -6.5218e-02,  3.1011e-01, -1.7462e-01,  2.3580e-01,\n",
            "          7.5631e-01,  1.9873e-01, -4.8683e-01, -3.0307e-02],\n",
            "        [ 2.6259e-01,  4.5256e-02, -6.2510e-02,  3.9798e-01,  7.2954e-02,\n",
            "         -4.0946e-01, -2.1800e-01,  1.3339e-01, -2.7050e-02,  7.5395e-02,\n",
            "          6.0437e-01, -1.1694e-01, -2.0983e-01, -1.5748e-01,  2.7143e-01,\n",
            "          5.9746e-01,  1.1573e-01,  2.2906e-02, -1.2311e-01],\n",
            "        [-1.9515e-01, -8.3747e-02, -4.0041e-01, -4.7721e-02,  2.8455e-01,\n",
            "         -4.4047e-01,  2.2768e-01,  1.0986e-01,  2.1650e-01,  5.2020e-01,\n",
            "          1.1900e-01,  4.0177e-01,  1.1882e-01,  2.3200e-01,  1.7708e-01,\n",
            "          3.5926e-01, -2.0047e-01, -2.1322e-01, -2.4636e-01],\n",
            "        [-1.0947e-01, -2.3644e-02,  4.6235e-01, -6.2180e-01, -1.3512e-01,\n",
            "          2.6417e-01,  4.5214e-01, -1.0377e-01,  2.6027e-01,  5.8191e-01,\n",
            "          4.4319e-01,  5.3387e-01, -3.5876e-01, -2.7107e-02,  2.9549e-01,\n",
            "          4.1977e-01, -1.7917e-01, -7.6539e-01, -1.8007e-01],\n",
            "        [-4.7061e-01, -3.3071e-01,  1.4835e-01, -1.4352e-02,  4.1127e-01,\n",
            "         -2.2707e-01,  1.9146e-01,  1.1740e-01,  9.2796e-02,  2.6155e-01,\n",
            "          2.5389e-01,  3.2025e-01, -1.9293e-01,  2.5828e-01,  1.9163e-01,\n",
            "          2.3343e-01, -1.0807e-01, -4.8523e-01, -3.5177e-01],\n",
            "        [-1.9019e-01, -3.7159e-01,  2.8615e-01, -1.8267e-01,  2.6425e-01,\n",
            "         -2.0074e-01, -1.6981e-02, -4.7387e-02, -2.2009e-02,  3.1445e-01,\n",
            "         -3.7399e-02,  1.5594e-01, -1.0012e-02, -9.0609e-01,  4.5875e-01,\n",
            "          4.9580e-02,  2.6883e-01, -4.8346e-01,  4.1080e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 2.4104e-02, -4.4881e-01,  1.3954e-01,  4.7791e-01,  3.5361e-01,\n",
            "         -1.4435e-01, -1.1694e-02,  9.4689e-02,  5.9742e-01,  2.5878e-01,\n",
            "          8.8749e-02,  6.0273e-01, -1.8560e-01, -3.1696e-01,  3.8858e-01,\n",
            "          2.7395e-01,  6.4377e-02,  6.7915e-02, -7.1389e-02],\n",
            "        [-1.7780e-01, -6.6413e-01,  4.3791e-01, -3.8001e-01,  6.4247e-01,\n",
            "         -3.5204e-01,  1.0553e-01,  1.9584e-02, -7.9237e-02,  3.7551e-01,\n",
            "          3.2948e-01,  6.7831e-02,  7.4503e-02, -1.8450e-01,  4.2133e-01,\n",
            "          2.2040e-02,  3.9755e-01, -1.4999e-01, -2.1794e-01],\n",
            "        [ 4.1883e-02, -3.5477e-01, -2.3013e-02, -2.6231e-01, -1.6546e-02,\n",
            "          1.4184e-02,  2.9156e-01,  5.4341e-01,  2.8173e-01,  4.3824e-01,\n",
            "         -5.3519e-01, -1.9999e-01, -2.6668e-02, -2.3608e-01, -1.6579e-02,\n",
            "         -2.4390e-01, -5.5481e-02, -2.3142e-01, -2.9360e-02],\n",
            "        [-9.9307e-02, -3.1349e-01,  2.8948e-01, -1.2006e-01,  2.9122e-01,\n",
            "         -4.5769e-01,  3.7215e-01,  1.5824e-01,  5.4950e-02,  1.8787e-01,\n",
            "          2.5452e-01,  1.7874e-01,  2.4753e-01,  2.5436e-01,  1.1992e-01,\n",
            "         -1.1208e-01, -7.5107e-02,  2.1156e-02,  2.3509e-01],\n",
            "        [-6.2281e-01, -6.7872e-01,  1.8186e-01,  1.3939e-01, -1.5683e-01,\n",
            "         -2.1595e-01, -7.2310e-01,  1.0335e-01, -3.5150e-01,  3.2572e-01,\n",
            "          7.5497e-01,  7.1861e-01, -4.0681e-01,  1.5171e-01,  1.2966e+00,\n",
            "          4.5011e-01,  3.1135e-01, -4.9383e-01,  1.7118e-01],\n",
            "        [-5.5779e-01, -7.3987e-01, -1.7568e-01, -1.3941e-01,  3.4077e-01,\n",
            "         -3.9314e-03,  1.7336e-01,  2.5476e-01,  7.8900e-02,  3.7487e-01,\n",
            "          3.6846e-01,  1.6533e-01, -2.5822e-01,  2.9559e-01,  4.3237e-01,\n",
            "         -3.6315e-01, -3.3809e-01, -5.6105e-01,  4.2347e-01],\n",
            "        [ 7.7111e-03, -9.9715e-01,  6.5028e-01,  5.0318e-01,  7.2595e-01,\n",
            "         -3.8148e-01, -7.5309e-02, -1.6133e-01, -7.0505e-01,  5.0159e-01,\n",
            "         -1.4004e-01, -5.2812e-01, -1.2943e-01,  3.0012e-01,  7.9603e-01,\n",
            "          1.5398e-01, -3.9823e-01, -7.1350e-01,  1.8404e-01],\n",
            "        [-2.8253e-02, -4.7053e-01,  4.9578e-01,  1.3230e-01,  7.5639e-01,\n",
            "         -2.2780e-01,  1.4548e-01, -2.3751e-01, -4.5543e-02,  3.7368e-01,\n",
            "          1.0061e-01, -3.1789e-01, -2.6954e-01, -1.7796e-01,  4.6122e-01,\n",
            "          2.8760e-01, -9.9406e-02, -3.8764e-01, -1.8183e-01],\n",
            "        [-3.4497e-01, -3.8490e-01,  2.8353e-02,  3.8172e-01,  7.0282e-01,\n",
            "         -4.1792e-01,  6.5052e-01,  2.2358e-01, -4.3281e-01,  5.8728e-01,\n",
            "          1.4960e-01,  1.7774e-01,  2.8768e-01, -2.1115e-01,  4.4683e-01,\n",
            "          1.2495e-01,  3.2318e-02, -1.9124e-01, -8.7713e-02],\n",
            "        [-6.2846e-01,  1.2211e-01,  3.3479e-01, -1.8541e-01, -4.0171e-03,\n",
            "          1.6699e-01, -4.4869e-02, -5.2266e-02, -1.0679e-01,  1.0236e-01,\n",
            "          3.0444e-01,  3.8929e-02,  6.3036e-04, -3.8333e-01,  3.4762e-01,\n",
            "          1.9374e-01,  2.8503e-01,  1.3939e-01, -4.2079e-02],\n",
            "        [ 1.6115e-01, -6.4404e-02,  8.9641e-03,  3.7405e-01,  2.6281e-01,\n",
            "         -4.3599e-01,  2.1321e-01, -1.7538e-01,  1.8628e-01,  4.4082e-02,\n",
            "          4.3624e-01,  5.5200e-01, -1.3037e-01,  2.5833e-01, -1.9836e-01,\n",
            "          3.3233e-01, -3.3523e-02, -2.3210e-01, -1.4111e-01],\n",
            "        [-2.0698e-01, -2.4811e-01, -4.4358e-01,  1.7368e-01,  4.5442e-01,\n",
            "         -1.2020e-02,  3.3392e-01, -3.1267e-01,  2.1323e-01,  2.7281e-01,\n",
            "          9.8653e-02,  3.0923e-01, -1.6327e-01,  1.3100e-01,  3.7841e-01,\n",
            "          4.8688e-01,  3.5157e-01, -1.0763e-01, -7.4910e-02],\n",
            "        [ 1.4486e-01, -3.4399e-01,  2.3822e-01, -1.1998e-01,  3.3436e-01,\n",
            "         -3.1065e-01,  2.6093e-01, -1.0203e-01, -3.5482e-01,  1.2469e-01,\n",
            "         -1.0863e-01, -2.8863e-01,  2.3319e-02,  1.7321e-01,  3.6159e-01,\n",
            "          4.8666e-01, -1.7435e-01, -2.1333e-01,  7.2657e-02],\n",
            "        [ 3.1201e-01, -3.7277e-01,  3.2885e-01, -1.4355e-01,  3.2630e-01,\n",
            "          3.2240e-01, -1.0838e-01,  1.4984e-01, -4.2809e-01,  1.0342e-01,\n",
            "          2.4015e-01,  1.9427e-01, -3.0006e-01,  4.3215e-01,  1.8298e-01,\n",
            "          1.4244e-01, -1.7471e-02,  1.7108e-01, -4.5440e-01],\n",
            "        [ 7.7280e-02,  1.2257e-02,  3.4466e-01,  1.2200e-01,  3.1060e-01,\n",
            "         -1.0779e-01, -8.6264e-02, -2.3594e-01, -1.4471e-01,  2.9435e-01,\n",
            "          1.3340e-01,  1.1398e-01, -1.1527e-01, -1.5628e-01,  1.0592e-01,\n",
            "          2.2932e-01,  2.2282e-01,  7.4641e-02,  1.2102e-01],\n",
            "        [-1.7591e-01, -1.2859e-01,  2.6850e-02, -2.3941e-01,  2.0914e-01,\n",
            "         -1.2210e-01,  6.1769e-01, -7.8545e-02,  1.3401e-01, -3.8337e-02,\n",
            "         -6.1976e-02,  1.6302e-01,  1.8047e-01, -7.7453e-02,  1.5033e-01,\n",
            "          7.4240e-02, -5.6298e-02, -1.3980e-01, -2.1075e-01],\n",
            "        [-2.4155e-01, -4.7941e-01, -8.0172e-02, -8.5164e-02,  6.9598e-02,\n",
            "         -2.9286e-01, -1.6196e-01, -2.0512e-01,  2.7049e-01,  3.0187e-01,\n",
            "         -3.9328e-01,  5.2087e-01,  9.0510e-02, -1.8586e-01,  1.1502e-01,\n",
            "          6.5009e-01,  1.7967e-01, -1.3089e-01,  5.1555e-01],\n",
            "        [ 1.3164e-01,  1.8293e-01,  1.8740e-01,  2.7460e-01,  6.7119e-01,\n",
            "         -2.4437e-01,  3.8506e-02, -8.9086e-02,  5.1750e-01,  4.4995e-01,\n",
            "          2.3042e-01,  4.6191e-02, -1.7162e-01,  1.7677e-01,  1.4293e-01,\n",
            "          3.1140e-01, -7.7690e-02, -4.9828e-02, -8.8519e-02],\n",
            "        [-3.8376e-01, -6.2533e-01,  4.3150e-01,  3.7778e-01,  2.1720e-01,\n",
            "         -2.4508e-01,  7.7465e-01,  4.6134e-01,  1.6978e-01,  2.5185e-02,\n",
            "          2.7593e-01,  2.0220e-01,  1.0148e-01, -3.1195e-01,  2.0527e-01,\n",
            "          6.3459e-02, -2.7957e-01,  2.8890e-01,  3.4086e-01],\n",
            "        [-4.8751e-02, -3.0238e-01, -2.8143e-02,  7.2905e-03,  7.6546e-01,\n",
            "         -9.3347e-02,  9.2153e-02,  4.9125e-01,  6.0510e-03,  5.6537e-01,\n",
            "          1.9738e-01, -2.0750e-01, -1.5133e-01, -2.1088e-01,  4.2470e-01,\n",
            "          3.1277e-01,  1.4912e-01, -6.1163e-01,  7.5532e-02],\n",
            "        [-1.0880e-01,  2.0730e-02,  1.5797e-01,  1.5570e-01,  1.7456e-01,\n",
            "         -1.5358e-01,  1.7485e-01,  1.6713e-01, -5.9605e-02,  7.8133e-01,\n",
            "          6.1734e-02,  4.2865e-01,  2.4598e-01,  1.3229e-01, -1.1564e-01,\n",
            "          2.3108e-01, -1.9302e-01,  1.9868e-01,  3.8740e-02],\n",
            "        [ 5.2515e-02, -2.1823e-01, -8.1395e-02,  2.1016e-01,  5.5583e-01,\n",
            "         -2.6821e-01, -4.7443e-01, -5.9061e-01, -5.3997e-04,  4.8838e-01,\n",
            "         -4.1898e-01,  1.8638e-01,  2.1679e-01, -1.2641e-01,  6.4853e-02,\n",
            "          3.3586e-01, -6.3196e-02, -3.0030e-01,  2.8241e-01],\n",
            "        [ 2.3476e-02,  1.5859e-01,  2.4463e-01,  6.5502e-02,  2.1574e-01,\n",
            "         -1.7001e-01,  1.9831e-01,  3.1465e-01, -1.2415e-01,  2.9798e-01,\n",
            "         -2.2325e-01,  2.4894e-01,  3.5460e-01, -1.0325e-01,  1.1134e-01,\n",
            "          1.8409e-01,  3.4560e-01,  1.3773e-01, -4.7427e-02],\n",
            "        [-3.8119e-01,  3.4346e-01, -1.3356e-01, -2.7313e-01,  4.2419e-01,\n",
            "          2.4280e-01, -2.6952e-01,  4.3034e-02,  3.0122e-01,  7.5447e-04,\n",
            "         -2.9919e-01,  3.4729e-01,  3.3062e-01, -4.6867e-01,  6.8651e-01,\n",
            "         -7.8665e-02,  2.1781e-02, -2.6142e-01, -2.3508e-02],\n",
            "        [-3.4494e-01, -2.4803e-01,  1.4957e-01,  9.2115e-02,  6.4947e-01,\n",
            "         -3.1592e-01,  9.6557e-02, -3.4211e-02, -2.0014e-01,  8.6788e-02,\n",
            "         -2.1700e-01,  4.0108e-01,  1.4914e-02,  1.2617e-01,  1.1728e-01,\n",
            "          5.2370e-01,  1.3839e-01,  4.3412e-02,  3.0840e-01],\n",
            "        [-5.5063e-02, -4.6377e-01,  1.1112e-01, -1.9135e-01,  1.7856e-01,\n",
            "         -5.1969e-01,  1.9980e-01,  1.1557e-01, -3.0183e-02,  4.9511e-01,\n",
            "          1.3549e-01,  7.6683e-01, -8.0596e-02, -3.4362e-01,  2.5352e-01,\n",
            "          7.0260e-01, -1.7996e-02, -5.3641e-01, -4.0472e-01],\n",
            "        [ 9.9098e-02, -4.1966e-01, -1.9039e-01, -3.1869e-01,  8.3839e-02,\n",
            "         -2.5305e-01,  3.3047e-01, -2.0708e-01, -1.3656e-02,  2.3979e-01,\n",
            "         -1.4929e-02,  2.5507e-01, -2.2194e-01,  3.6903e-01,  5.1363e-01,\n",
            "          4.0779e-01,  6.8210e-01, -3.1866e-01,  3.3364e-01],\n",
            "        [ 3.5669e-02,  2.9212e-02,  6.0093e-01, -2.2165e-01,  1.3096e-01,\n",
            "         -2.0165e-01,  6.2586e-01,  3.2583e-01, -4.0547e-03,  4.2643e-01,\n",
            "          2.8542e-01, -3.6535e-01, -4.4490e-01,  1.1743e-01,  8.1677e-03,\n",
            "         -2.1753e-01, -3.2613e-01, -6.3627e-01,  7.4247e-02],\n",
            "        [-2.0912e-01, -4.7470e-01,  2.6963e-01,  3.8795e-01,  1.2940e-01,\n",
            "          1.0847e-02,  8.2131e-02,  6.0965e-02, -7.5831e-03,  2.2819e-01,\n",
            "          2.0532e-01,  6.1142e-01, -6.4365e-01, -7.1461e-02,  5.6094e-01,\n",
            "          1.8916e-01,  4.5221e-01, -4.9105e-01,  3.0594e-01],\n",
            "        [ 3.1680e-02, -2.6198e-01,  4.5562e-01, -2.0025e-01,  4.0265e-01,\n",
            "         -1.1087e-01,  8.4168e-02, -1.1708e-03,  5.4767e-01,  8.9641e-01,\n",
            "          1.1248e-01, -6.6571e-02, -2.4997e-01,  2.2302e-02,  1.3484e-01,\n",
            "          1.7725e-01, -5.2763e-02, -2.5879e-01, -3.1183e-01],\n",
            "        [-1.7382e-01, -5.7698e-01,  1.8109e-02,  9.9699e-02,  8.8509e-02,\n",
            "         -6.4043e-01, -2.1940e-01,  2.8752e-01,  1.6628e-01,  4.8066e-02,\n",
            "          4.8292e-01,  1.7038e-01,  3.0572e-01,  2.1807e-01,  4.7455e-01,\n",
            "          7.5368e-01,  1.0747e-01,  1.7764e-01,  6.6097e-02],\n",
            "        [-3.6177e-01, -2.2843e-01, -2.9834e-01, -2.6147e-01,  1.5031e-01,\n",
            "         -2.9764e-01,  1.6566e-01,  3.9556e-01,  1.4289e-01,  6.9570e-01,\n",
            "         -2.3211e-01,  2.7201e-01, -4.7785e-02, -3.9242e-01,  3.5747e-01,\n",
            "          3.2632e-01, -1.0348e-01, -5.4868e-01, -2.8177e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-8.9912e-02, -5.2081e-01,  5.0305e-01, -9.3327e-02,  1.4292e-01,\n",
            "          1.8116e-01, -1.6694e-01,  4.0772e-01,  7.0059e-02,  4.3748e-01,\n",
            "          1.0612e-02,  4.4312e-01, -3.4811e-01,  1.4355e-01,  4.0668e-01,\n",
            "         -1.6072e-01,  2.2141e-01, -1.9974e-01,  2.1508e-01],\n",
            "        [-1.4636e-01,  1.7650e-02, -1.2679e-01,  6.4767e-02, -3.0160e-01,\n",
            "          1.5707e-02,  2.4154e-01, -1.6817e-01,  3.7641e-01,  2.0360e-01,\n",
            "         -2.7703e-01,  5.8674e-02,  4.7409e-02,  1.3403e-01,  5.2075e-02,\n",
            "          1.8314e-01,  4.8313e-01,  6.6951e-02, -1.7225e-01],\n",
            "        [-2.9546e-02, -2.3610e-01,  3.0000e-01, -2.7622e-01,  5.3166e-01,\n",
            "         -3.0781e-01,  3.5556e-01,  1.8373e-01,  4.2507e-01,  3.4725e-01,\n",
            "          6.5181e-01,  2.0462e-01, -1.2212e-01, -3.2484e-02,  8.1561e-02,\n",
            "          1.5776e-01,  1.8121e-01, -2.7644e-01,  4.4764e-01],\n",
            "        [ 7.2381e-02, -4.5779e-01, -1.1008e-01, -2.4343e-02,  3.5180e-01,\n",
            "         -4.8924e-02, -2.3715e-01, -2.2213e-01, -3.1793e-01,  2.2852e-01,\n",
            "          3.9417e-02,  1.5555e-01,  1.0907e-02, -2.1727e-01,  4.2397e-02,\n",
            "         -2.4276e-01,  2.7466e-01, -4.4787e-02,  1.0673e-01],\n",
            "        [-2.1992e-01, -4.1759e-01, -1.5998e-01,  1.1244e-01, -8.4740e-02,\n",
            "         -3.7618e-02,  1.1314e-01,  5.9775e-02,  4.1133e-01,  3.1240e-02,\n",
            "          1.7069e-01, -3.6379e-01, -1.0404e-01,  4.1163e-01,  5.3307e-01,\n",
            "          3.7824e-01, -3.9375e-01,  7.7838e-02,  3.2959e-02],\n",
            "        [-1.9640e-01, -2.9269e-01,  4.7728e-01,  5.9824e-02, -7.2123e-02,\n",
            "          7.1077e-02,  3.4853e-01, -2.3123e-01,  1.2865e-01,  4.3242e-01,\n",
            "         -6.1462e-02, -2.0653e-01,  3.0387e-01, -3.8491e-01,  6.9022e-01,\n",
            "          3.6508e-02,  7.9341e-03, -2.4487e-01, -6.0376e-02],\n",
            "        [-2.7094e-01, -1.6867e-01, -4.2872e-02, -2.4924e-01,  1.3310e-01,\n",
            "         -3.4367e-01, -9.3107e-02,  2.1618e-02, -1.7902e-01,  5.5525e-01,\n",
            "          4.8745e-01,  7.3512e-02, -3.9725e-01,  3.7921e-02,  1.0243e-01,\n",
            "         -2.1004e-01,  2.0184e-01, -5.7857e-02, -4.3803e-01],\n",
            "        [-6.4819e-01, -2.5602e-01,  5.5787e-01, -4.6277e-01,  5.1976e-01,\n",
            "         -2.2573e-01,  1.7046e-01, -5.8876e-01,  2.7193e-01,  4.4272e-01,\n",
            "         -1.9882e-01,  4.2189e-01, -2.1984e-01, -1.0435e-01,  3.2947e-01,\n",
            "         -1.0298e-01, -4.0953e-01, -1.8425e-01, -4.1509e-02],\n",
            "        [ 1.7737e-01, -5.6708e-01, -5.4134e-03,  6.9712e-02,  3.6436e-01,\n",
            "         -2.2805e-01,  1.1285e-01, -1.0881e-01,  4.5712e-01,  7.7713e-02,\n",
            "          1.4880e-01, -1.3296e-01, -4.8347e-02, -4.5936e-01,  1.6209e-01,\n",
            "          4.6433e-01,  2.6879e-01, -2.5717e-01,  5.4344e-02],\n",
            "        [-2.2850e-01, -3.0656e-01, -2.4118e-01, -4.3555e-03,  2.4487e-01,\n",
            "         -5.5288e-01, -1.8284e-01,  2.1085e-01, -5.8828e-02,  3.9366e-01,\n",
            "          3.5046e-01,  4.6166e-02, -1.2527e-01, -1.9438e-01,  4.1288e-01,\n",
            "          2.2977e-01,  2.7011e-01, -5.0157e-01,  1.1717e-01],\n",
            "        [-1.8458e-01, -1.1686e+00,  5.8157e-02, -4.6527e-01,  2.5423e-01,\n",
            "         -5.3690e-01,  3.9101e-02,  3.0845e-01,  5.5777e-01,  4.1784e-01,\n",
            "          1.6192e-01,  6.2087e-01, -1.5212e-01, -1.8423e-01,  1.5746e-01,\n",
            "          7.3404e-01,  3.4583e-01, -4.6301e-01,  4.1749e-02],\n",
            "        [-2.9412e-01,  1.7794e-01,  2.8285e-01, -9.8768e-02,  5.6580e-01,\n",
            "         -3.8884e-01,  7.3221e-01, -1.1288e-01,  5.2162e-01,  3.2452e-01,\n",
            "         -7.1313e-02,  1.2470e-01,  1.4480e-01,  1.2090e-02,  2.3641e-01,\n",
            "         -1.1437e-01,  5.3698e-01,  1.6581e-01,  4.6180e-01],\n",
            "        [-6.3561e-01, -2.4619e-01,  4.7122e-01, -1.3888e-01,  1.0689e-01,\n",
            "         -9.3475e-04, -6.2570e-02,  5.5953e-01,  1.5093e-01,  2.4603e-01,\n",
            "          9.2150e-02,  1.2124e-01,  5.8146e-02, -3.1750e-01,  8.4444e-01,\n",
            "          1.2797e-01,  1.9950e-01, -2.5762e-01,  1.9017e-01],\n",
            "        [ 4.5692e-02, -3.2145e-01,  2.3225e-01, -1.8552e-01,  7.6978e-01,\n",
            "         -3.8952e-01,  6.2049e-02, -1.4042e-02,  2.0392e-01,  1.8286e-01,\n",
            "         -1.9738e-02,  2.1203e-01, -2.4961e-01, -3.7365e-02,  3.1234e-01,\n",
            "          3.8591e-01,  2.4810e-01, -3.4013e-01,  3.8477e-01],\n",
            "        [-1.6073e-01, -7.8321e-02, -6.8673e-02, -1.9508e-01, -4.3350e-02,\n",
            "          1.5982e-02, -7.5947e-02,  2.9372e-01, -2.4425e-01,  3.9693e-01,\n",
            "         -4.5053e-02, -4.7547e-01, -1.2699e-01, -3.7658e-01,  3.7882e-01,\n",
            "          4.6666e-01, -6.5175e-02, -6.1480e-01,  4.2352e-02],\n",
            "        [-4.0587e-01, -7.6786e-02,  2.2371e-01, -3.5718e-01,  4.2390e-01,\n",
            "         -1.7124e-01,  1.0799e-01, -8.3460e-03, -9.7653e-02,  3.9202e-01,\n",
            "          1.2151e-01,  6.1113e-03,  5.4246e-01,  8.3432e-02, -7.0017e-03,\n",
            "         -1.4297e-01,  4.3685e-01,  2.9809e-01, -5.1171e-01],\n",
            "        [-4.8468e-01, -1.0913e-01,  3.4637e-01, -3.4981e-01,  6.1847e-01,\n",
            "         -5.3100e-01,  8.5219e-02,  2.9644e-01, -2.8870e-01,  2.1627e-01,\n",
            "          4.7606e-02, -4.9441e-02, -5.5150e-01, -2.4354e-01,  2.3111e-01,\n",
            "          2.6091e-01,  6.3441e-01, -1.6142e-01,  2.7717e-01],\n",
            "        [-5.5403e-01, -5.2215e-01, -8.5116e-02,  6.5150e-02,  4.3845e-01,\n",
            "          1.8357e-01, -8.8922e-02,  3.9953e-02, -1.6457e-01,  6.6437e-01,\n",
            "          2.0400e-02, -1.5995e-02, -5.7334e-02, -9.1839e-02,  1.6314e-01,\n",
            "          2.6532e-01, -5.3234e-03,  2.8152e-01,  4.6150e-02],\n",
            "        [-2.8764e-02, -4.6863e-01,  2.8840e-01, -2.0434e-01,  4.0213e-01,\n",
            "          9.4664e-03, -1.0981e-01,  3.9674e-01,  1.3260e-01,  2.9100e-01,\n",
            "          2.9449e-01,  1.8741e-01, -7.4152e-01,  9.5498e-02,  8.8742e-01,\n",
            "          7.6556e-01, -2.5214e-01, -1.1380e-01, -1.3858e-01],\n",
            "        [-1.0046e-01, -6.8267e-01,  1.5658e-02,  3.4264e-02,  6.4875e-01,\n",
            "          2.2045e-01,  1.5989e-01,  7.6241e-02, -9.8677e-02,  4.8007e-01,\n",
            "         -2.5500e-01,  5.7257e-01,  3.1070e-01,  1.9665e-01, -1.0652e-01,\n",
            "          5.9338e-01, -2.0962e-02, -1.7550e-01, -1.5765e-01],\n",
            "        [-3.6073e-01, -1.1103e-01,  1.9322e-01,  6.0994e-02,  5.3193e-01,\n",
            "         -3.4370e-01,  1.3216e-01,  2.8024e-01, -2.1618e-01,  4.4978e-01,\n",
            "          3.7749e-01,  5.5603e-01, -1.7341e-01, -2.6936e-01,  4.4397e-01,\n",
            "         -7.3504e-02,  3.7826e-01, -2.5775e-01, -3.0772e-02],\n",
            "        [-7.5891e-01, -1.9657e-02,  3.1180e-01, -1.5818e-01,  5.9544e-02,\n",
            "         -1.0469e-01, -1.2258e-02,  3.3721e-01,  1.2152e-01,  4.4633e-01,\n",
            "          4.6253e-02,  9.8107e-02,  2.4167e-01, -6.1423e-02,  7.4809e-02,\n",
            "          2.7999e-01,  9.9703e-02, -2.6423e-01,  2.3764e-01],\n",
            "        [ 4.8099e-02, -6.3708e-02,  2.0503e-01,  1.8021e-01,  4.0783e-01,\n",
            "          6.7703e-01,  2.2823e-01,  3.8028e-01,  3.3238e-01,  5.8215e-01,\n",
            "          1.3137e-01, -7.2182e-03, -1.7390e-01, -2.8419e-02,  4.3468e-01,\n",
            "          2.2007e-01,  5.4381e-01,  1.4542e-01, -1.3809e-01],\n",
            "        [-1.2003e-01, -3.4153e-01,  6.1443e-01,  8.2241e-02,  4.6282e-01,\n",
            "         -1.3685e-01,  1.3848e-01,  2.8012e-02, -2.4982e-01,  2.3261e-01,\n",
            "          1.2397e-01,  1.2641e-01,  5.7357e-02, -4.4007e-01,  2.4047e-01,\n",
            "          5.6953e-01,  5.9177e-01, -1.0994e-01,  2.1365e-01],\n",
            "        [-1.0368e-01, -1.1245e-01, -2.0337e-01,  2.9140e-01,  4.6833e-01,\n",
            "         -1.3947e-01,  2.9668e-01, -1.4785e-01,  1.9619e-03,  3.4458e-01,\n",
            "          3.6905e-01,  3.1090e-01, -8.6853e-02, -2.5518e-01,  4.3981e-01,\n",
            "          2.4487e-01, -9.7712e-02, -1.9799e-01, -4.6353e-02],\n",
            "        [-3.9878e-01, -5.2446e-01,  2.8788e-01, -1.9294e-01, -8.0426e-02,\n",
            "         -3.3002e-01, -4.5655e-02, -3.4829e-01, -9.3793e-02,  7.7742e-01,\n",
            "          4.2783e-01,  2.4910e-01, -2.4138e-01,  7.6808e-02,  5.2544e-01,\n",
            "          2.3739e-01,  1.9116e-02, -2.7126e-01,  2.8167e-01],\n",
            "        [-6.5912e-02, -5.7267e-01,  2.2619e-02,  6.4023e-02,  7.1623e-01,\n",
            "         -5.1346e-01,  3.0524e-01, -5.9010e-02,  6.4475e-01,  5.4976e-01,\n",
            "          4.2689e-01,  3.7561e-01,  8.9707e-02,  1.0113e-01, -5.2522e-03,\n",
            "          3.2981e-01, -4.7756e-01, -2.7902e-02,  2.0262e-01],\n",
            "        [ 2.7711e-01, -4.7437e-02,  1.5702e-01,  8.6880e-02,  1.0224e-01,\n",
            "         -1.8671e-01, -4.0296e-01,  3.7649e-01,  1.2505e-01,  1.1611e-01,\n",
            "          2.3677e-01,  2.2902e-02, -2.7890e-01, -1.8498e-01,  6.6396e-01,\n",
            "          2.7910e-01, -1.9522e-01, -1.6016e-01, -2.7960e-01],\n",
            "        [-2.3786e-01,  8.3993e-02,  1.2660e-01, -1.3927e-01,  4.6710e-01,\n",
            "         -5.5597e-01, -2.1213e-01, -2.7205e-01,  3.7421e-02,  7.0878e-02,\n",
            "         -1.5404e-01, -1.7454e-01, -1.3690e-01,  1.0106e-01,  1.2392e-01,\n",
            "          3.1950e-01,  3.6229e-02,  4.0595e-01, -1.1818e-01],\n",
            "        [-1.8713e-01, -7.0602e-02, -8.6766e-02, -5.8537e-02,  6.6400e-01,\n",
            "         -3.4074e-01, -2.2962e-01,  2.4260e-01, -3.0494e-01,  9.6638e-01,\n",
            "          4.4473e-01,  3.1791e-01, -1.8669e-01, -3.4443e-01,  2.9962e-01,\n",
            "          6.9366e-01,  1.8072e-01, -3.3166e-01,  3.3087e-01],\n",
            "        [-3.3499e-01,  3.9043e-03,  1.6011e-01,  5.9076e-01,  2.3647e-01,\n",
            "         -4.4570e-01,  1.6850e-01, -2.4878e-01,  4.9357e-01,  1.4182e-01,\n",
            "          2.1583e-01,  2.6792e-01, -2.1071e-01,  2.9245e-01, -2.2869e-01,\n",
            "          2.1111e-01,  2.7157e-01, -4.2766e-01, -3.4387e-01],\n",
            "        [ 2.3241e-01,  4.7900e-02, -1.6343e-01,  3.8014e-03,  1.6371e-01,\n",
            "         -1.2305e-01,  8.4892e-02,  1.1763e-01, -4.5339e-01, -1.7907e-01,\n",
            "          3.1460e-01, -1.4375e-01, -9.7522e-02,  2.4750e-01,  5.2594e-02,\n",
            "          4.4857e-01,  4.1475e-02,  3.0463e-01, -1.8931e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-4.7684e-01, -1.0133e+00,  1.5020e-01,  3.0920e-01, -8.4471e-02,\n",
            "         -3.8365e-01, -9.0974e-02, -2.5839e-01,  5.8970e-01,  8.8226e-01,\n",
            "         -1.1271e-01, -3.8680e-02,  4.6455e-01, -2.0202e-02,  1.3083e-01,\n",
            "          4.7254e-01,  1.5673e-01, -5.5867e-01,  5.0315e-01],\n",
            "        [ 1.6560e-01, -6.2427e-02, -3.4591e-02, -6.2315e-01,  6.4413e-01,\n",
            "          1.1104e-01, -3.6758e-02,  3.3433e-03,  1.9353e-01, -5.9324e-02,\n",
            "          7.9402e-02, -3.5418e-01, -5.4006e-01, -2.4595e-01,  5.3124e-01,\n",
            "          3.9200e-02,  8.2801e-02,  3.4061e-01, -2.1367e-01],\n",
            "        [-3.3336e-01, -1.9068e-01, -1.4097e-01,  1.1990e-01, -1.8669e-01,\n",
            "          1.5511e-01, -2.3654e-01,  4.8139e-01,  2.7788e-01,  4.5132e-02,\n",
            "         -3.5620e-01,  2.4777e-01,  6.7710e-01, -7.5506e-03, -1.7081e-01,\n",
            "         -1.1004e-01,  3.5144e-01,  2.4700e-01, -4.4335e-01],\n",
            "        [ 1.3252e-01, -4.6902e-01,  3.4242e-02,  2.0567e-01,  5.4973e-01,\n",
            "          2.8162e-02,  1.8104e-01, -2.3240e-02,  1.6121e-01,  9.2649e-01,\n",
            "         -1.5517e-02,  8.3435e-03, -1.6691e-01, -1.7560e-01,  4.7378e-02,\n",
            "          4.5196e-01,  1.8711e-01, -5.1070e-01,  1.1827e-01],\n",
            "        [ 3.3000e-02, -2.3581e-01,  2.4036e-01,  1.7016e-02,  7.5367e-01,\n",
            "         -3.7740e-01,  3.0219e-01, -1.6296e-02,  3.7061e-02,  4.5368e-01,\n",
            "          5.5673e-01,  2.9837e-01,  7.9006e-02, -1.6806e-01, -1.4576e-01,\n",
            "          4.8883e-01,  1.4622e-01, -1.1107e-01,  3.5415e-02],\n",
            "        [-1.7759e-01, -3.1826e-01,  3.2723e-01, -1.1391e-01,  2.5966e-01,\n",
            "         -7.2950e-01,  1.9459e-02,  1.1455e-01,  2.5232e-01, -2.4243e-01,\n",
            "         -7.2542e-02,  1.4651e-01, -3.6573e-02,  3.8354e-02,  6.0765e-01,\n",
            "          3.6540e-01,  2.2958e-01,  2.0983e-01,  1.6919e-01],\n",
            "        [-1.7527e-01, -4.0935e-01,  3.0016e-01, -1.1908e-01,  4.7686e-01,\n",
            "         -3.0624e-01,  4.8154e-02, -2.1918e-01, -2.3281e-01,  3.9693e-01,\n",
            "          1.9683e-01,  1.6483e-01,  2.8938e-01, -1.1991e-01,  1.5115e-01,\n",
            "         -1.0624e-01,  1.6378e-01,  1.0240e-01, -4.3154e-02],\n",
            "        [-4.7576e-01, -7.4464e-01,  1.4746e-01,  4.4256e-02,  5.1926e-01,\n",
            "         -9.8193e-03, -8.2875e-02,  2.6206e-04,  9.7899e-02,  1.5738e-01,\n",
            "         -1.4437e-01,  2.9026e-02,  3.5693e-01, -3.2344e-01,  1.8651e-02,\n",
            "          8.5661e-01, -4.4608e-01, -1.7501e-01,  2.0839e-01],\n",
            "        [-1.2990e-01,  2.1037e-02, -1.1994e-01, -1.8038e-01,  2.5304e-01,\n",
            "         -3.0129e-01, -1.1205e-01, -2.0187e-02,  2.7302e-01,  2.7472e-01,\n",
            "         -7.2583e-02,  2.8952e-01,  3.2077e-01, -1.5994e-02,  1.1853e-01,\n",
            "          2.0148e-01,  2.4383e-01, -5.8031e-01,  4.3952e-02],\n",
            "        [-1.0810e-03, -2.6178e-01,  7.4760e-02,  2.4937e-02,  1.6542e-02,\n",
            "         -3.2491e-01,  2.2490e-01,  1.9757e-01, -1.4021e-01,  4.9842e-01,\n",
            "          1.5320e-01, -2.3064e-01, -1.1975e-02,  1.9327e-01,  2.6143e-01,\n",
            "          2.0665e-02,  2.3218e-01, -2.5688e-01,  1.7733e-01],\n",
            "        [ 5.5385e-02, -5.6101e-02, -1.0351e-01,  1.3869e-01, -8.5386e-02,\n",
            "         -2.1059e-01,  1.8015e-01, -3.4670e-01,  1.5318e-01,  4.8288e-01,\n",
            "          4.7816e-02,  2.0004e-01, -3.1080e-01, -3.6445e-01,  4.7260e-02,\n",
            "          2.9842e-01, -8.0287e-02,  1.6226e-01,  3.8650e-01],\n",
            "        [-3.2719e-01, -2.4604e-01,  1.3195e-01,  2.9970e-01,  3.3787e-01,\n",
            "         -3.2750e-02, -2.2172e-01,  7.7880e-02,  4.7227e-01,  6.9650e-01,\n",
            "          2.6274e-01, -1.2680e-01, -2.8896e-02, -2.9118e-01,  7.8675e-01,\n",
            "         -1.3391e-01, -3.8879e-02, -3.3624e-01, -8.8512e-02],\n",
            "        [-2.6751e-01, -2.2290e-01,  7.4977e-02, -2.9879e-01,  8.8185e-01,\n",
            "          1.5861e-01,  2.6780e-02, -1.9036e-01,  2.3619e-01,  3.3953e-01,\n",
            "          3.5718e-01,  1.8115e-01, -5.6279e-01, -2.8410e-02,  5.2523e-01,\n",
            "          3.7676e-01,  4.1770e-01, -2.8830e-01, -2.4328e-01],\n",
            "        [ 5.3960e-02, -3.1166e-01,  5.2873e-01, -3.1813e-02,  5.6292e-01,\n",
            "         -2.0913e-02,  1.1969e-01,  1.7105e-01, -1.0182e-01, -7.9852e-02,\n",
            "          5.4459e-02,  2.3705e-01,  8.3289e-02, -2.5600e-01,  2.0469e-01,\n",
            "          1.0584e-01, -1.1104e-01, -2.1217e-01,  1.4954e-01],\n",
            "        [-1.3425e-02, -2.4702e-02, -1.2777e-01, -7.1967e-02,  9.6535e-01,\n",
            "         -2.7499e-03, -1.2293e-01, -1.3188e-02,  6.4541e-01,  2.3578e-01,\n",
            "         -2.0960e-02,  4.7091e-01,  4.0725e-01,  1.4342e-02,  3.9869e-01,\n",
            "         -2.9878e-01, -1.4083e-02,  1.1821e-01,  2.7071e-01],\n",
            "        [-3.8125e-01, -8.8820e-02, -2.5185e-02, -2.5789e-01,  5.5002e-01,\n",
            "         -1.1554e-01,  2.0391e-01, -1.2456e-01, -9.1544e-02, -3.3857e-02,\n",
            "          7.5502e-02,  2.7099e-01, -5.8289e-03, -2.1962e-01, -5.5008e-02,\n",
            "          3.0013e-01,  4.7512e-02, -3.0974e-01, -2.2366e-01],\n",
            "        [-5.2759e-01,  6.0164e-02,  6.3493e-01,  8.4143e-02,  3.2627e-01,\n",
            "         -1.1713e-01,  3.2350e-01, -1.1022e-02, -6.3331e-03,  3.4653e-01,\n",
            "          1.5091e-01, -1.1856e-02, -9.9017e-02,  1.7220e-02, -5.1295e-02,\n",
            "          5.5343e-02,  1.1846e-01,  2.0743e-01,  4.2907e-01],\n",
            "        [-1.7608e-01, -2.4299e-01,  4.0099e-02, -5.0939e-02, -4.2499e-02,\n",
            "          4.8770e-02,  2.1160e-01, -1.9012e-02, -4.5795e-01,  1.6928e-01,\n",
            "          4.2429e-02, -5.2615e-02, -1.5795e-01,  1.2577e-02,  3.7240e-01,\n",
            "         -9.2143e-02,  4.9885e-01, -4.9274e-01,  3.3960e-01],\n",
            "        [-2.7780e-02, -4.4895e-02,  5.3121e-01,  2.2174e-01,  5.7662e-01,\n",
            "         -2.1355e-02,  3.0882e-01, -8.3361e-02, -1.6775e-01,  2.4183e-01,\n",
            "          2.2480e-01,  9.1347e-02,  9.9112e-02,  7.1042e-01, -2.4276e-01,\n",
            "          3.9642e-01,  5.5406e-01,  2.3607e-01, -1.0042e-01],\n",
            "        [-5.9902e-01,  2.2975e-01,  6.4764e-02, -1.4306e-01,  2.5897e-01,\n",
            "         -1.8591e-01,  3.0221e-01, -2.8772e-02,  6.7942e-02,  1.3232e-01,\n",
            "         -6.5104e-01,  3.2899e-01,  3.9485e-02,  5.0069e-02,  2.2329e-02,\n",
            "          4.0637e-01,  4.4845e-01, -3.8173e-01, -8.3409e-02],\n",
            "        [ 1.2720e-01, -3.4991e-01,  4.5293e-01, -2.8465e-01,  5.4749e-01,\n",
            "         -4.0407e-01, -3.9514e-01, -2.7738e-02, -1.0227e-01,  4.5309e-01,\n",
            "          1.4369e-01,  2.0747e-01, -3.1489e-01,  6.6674e-02, -7.2845e-02,\n",
            "          1.9879e-01, -2.2162e-01, -3.9785e-01, -3.9055e-01],\n",
            "        [-1.3793e-01, -4.4857e-01, -1.9648e-01, -4.4886e-01, -9.8160e-02,\n",
            "          2.4571e-01,  5.1317e-01,  3.6866e-01,  1.9411e-01,  2.5912e-01,\n",
            "          5.6324e-01,  2.1908e-01, -2.9241e-01, -2.0765e-01,  5.4643e-01,\n",
            "          9.4208e-02,  5.4270e-01,  7.2802e-03, -4.0536e-02],\n",
            "        [-6.5864e-02, -1.8658e-01,  1.4505e-01,  3.7111e-01,  2.5069e-01,\n",
            "         -5.1896e-02, -5.3462e-02,  1.1409e-01, -1.0867e-01,  5.1731e-01,\n",
            "         -1.4252e-01,  5.2434e-01, -7.3712e-01, -1.9095e-01,  1.8207e-01,\n",
            "          2.6467e-01,  6.9637e-02, -1.5987e-01, -1.4202e-01],\n",
            "        [-4.5716e-01, -5.5236e-01,  4.3032e-01, -1.0531e-01,  1.8601e-01,\n",
            "         -1.7925e-01,  2.3934e-01, -5.8361e-02,  3.3013e-01,  1.9738e-01,\n",
            "          6.4219e-01,  1.7149e-01, -3.3305e-01, -3.4592e-01,  1.7235e-01,\n",
            "          6.0001e-01,  1.3757e-01,  2.5096e-01,  5.3813e-01],\n",
            "        [-1.1618e-01, -8.0600e-02,  3.5631e-01,  1.4986e-01,  2.4591e-01,\n",
            "         -3.5216e-01, -1.8368e-01,  1.2690e-02, -5.7042e-01, -3.2095e-02,\n",
            "          2.0692e-02, -1.6300e-02,  2.5431e-01,  4.7332e-01,  3.7883e-01,\n",
            "          3.2034e-01,  2.6842e-01,  1.9814e-01, -9.5620e-02],\n",
            "        [ 3.9304e-01, -5.1156e-01,  4.2870e-01,  5.0502e-01,  2.9715e-01,\n",
            "         -6.9844e-02, -9.3309e-02,  2.2403e-01,  4.6360e-02,  3.3394e-01,\n",
            "          4.2919e-01,  5.0804e-01, -5.6759e-02, -9.8490e-01,  4.5132e-01,\n",
            "          2.2860e-01,  3.1474e-01, -1.1710e-01, -1.6885e-01],\n",
            "        [-6.1671e-01, -2.0288e-01, -2.4053e-01,  6.5422e-01,  2.1056e-02,\n",
            "         -1.5042e-01, -2.2486e-01,  4.1748e-01,  7.3001e-02, -8.8990e-02,\n",
            "          1.1113e+00,  1.3783e-01,  1.0826e-01,  2.0346e-01,  6.9203e-01,\n",
            "         -5.5785e-02, -1.5296e-01, -6.6236e-01, -7.4570e-01],\n",
            "        [ 1.3224e-01, -1.6566e-01, -4.7636e-02,  4.4810e-01,  6.5454e-01,\n",
            "         -5.2672e-02,  2.4961e-01, -8.6938e-02,  1.3807e-01,  8.6303e-02,\n",
            "          2.6784e-01,  1.5644e-01, -3.6256e-01, -2.3103e-01,  2.4783e-01,\n",
            "          6.8122e-01, -1.0747e-01, -2.6253e-01,  4.7515e-01],\n",
            "        [-5.3544e-01, -7.8414e-02, -1.1272e-01,  6.7622e-02,  6.4159e-01,\n",
            "          1.4771e-01, -1.6760e-01,  2.5326e-01, -2.6834e-02,  4.4996e-01,\n",
            "         -3.4222e-02,  7.7660e-01,  4.7829e-01,  6.9316e-02,  5.2040e-01,\n",
            "          6.9582e-01,  2.9801e-01, -2.7189e-01,  6.9757e-01],\n",
            "        [ 8.3879e-02,  9.0757e-02,  5.8083e-01, -3.0467e-01, -5.2652e-02,\n",
            "         -1.2154e-01,  7.0120e-01,  1.5384e-01,  2.0498e-01,  2.6095e-01,\n",
            "          3.3244e-02,  2.3309e-01, -2.2987e-01,  3.0508e-01,  4.4997e-01,\n",
            "          5.9976e-01,  6.1915e-01, -4.3512e-02, -2.9689e-02],\n",
            "        [-4.0441e-01, -3.7508e-01,  1.3825e-01, -5.1834e-01,  9.7986e-01,\n",
            "         -3.7840e-01,  2.2105e-01,  1.2311e-01,  1.3126e-01,  6.8022e-02,\n",
            "         -2.1226e-01,  3.0069e-01, -1.9945e-01,  8.9840e-02,  3.4796e-01,\n",
            "          3.7636e-01, -2.7840e-01, -2.7887e-01,  3.8288e-01],\n",
            "        [ 5.9173e-02, -5.2405e-01, -9.0185e-02,  3.1611e-02,  3.8273e-01,\n",
            "         -2.6288e-01, -1.6780e-01, -2.4889e-01,  9.6669e-02,  4.8326e-01,\n",
            "          1.1998e-01,  5.3054e-01,  8.7229e-03, -6.6981e-01, -2.2453e-03,\n",
            "          2.9354e-01,  4.6182e-01,  4.4457e-03, -2.3458e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-1.7773e-01, -1.1172e-01,  4.9180e-02,  6.4227e-02,  1.2305e-01,\n",
            "         -6.5792e-02,  4.5488e-01,  7.6025e-02,  6.7417e-02,  2.1463e-01,\n",
            "          1.2401e-01,  3.1672e-01, -2.9935e-01, -9.5573e-02,  3.4457e-03,\n",
            "          1.7923e-01,  1.4061e-01,  8.4218e-02,  2.0585e-01],\n",
            "        [-1.0768e-01, -4.7685e-01,  3.6829e-01,  3.8196e-01,  5.3531e-01,\n",
            "          6.1887e-01, -8.4928e-02,  4.5661e-02, -1.5124e-01,  3.1608e-01,\n",
            "          2.2105e-01,  2.9349e-01, -1.0912e-02, -8.1713e-03, -3.2926e-01,\n",
            "          6.5057e-01,  2.0605e-01,  2.2995e-02, -1.6329e-01],\n",
            "        [-8.9920e-02, -3.8274e-01, -5.8123e-02, -6.1800e-01,  1.6240e-01,\n",
            "         -2.3925e-01, -1.8140e-01, -1.2837e-01,  2.5751e-01,  1.3005e-01,\n",
            "          1.9323e-01, -1.5425e-01, -4.7966e-02, -1.7008e-02,  5.0232e-01,\n",
            "          3.5510e-01,  1.7569e-01,  2.4079e-01,  1.3096e-01],\n",
            "        [ 6.6500e-02, -3.0874e-01, -1.3619e-01, -1.4795e-01,  3.1349e-01,\n",
            "         -1.4362e-01, -1.4378e-01,  4.1018e-01,  1.0825e-01, -2.5288e-01,\n",
            "          1.1997e-01,  7.5726e-02, -2.5829e-01, -4.4766e-01,  4.6161e-02,\n",
            "          4.2691e-01, -3.0195e-02, -3.2583e-01, -1.9406e-01],\n",
            "        [ 3.8780e-02, -1.5983e-01,  2.4931e-01, -2.7531e-01,  1.5980e-01,\n",
            "         -2.5160e-01,  2.6203e-01, -2.1317e-01,  1.3524e-01,  3.3365e-01,\n",
            "          2.9949e-03, -1.6237e-01, -1.6795e-01,  1.8969e-01,  7.1662e-01,\n",
            "          2.8239e-01,  2.4299e-01, -1.0387e-02,  1.7736e-01],\n",
            "        [-8.2498e-01, -3.3134e-02, -1.4583e-01, -4.6558e-02,  6.4533e-01,\n",
            "         -1.4780e-01,  2.4768e-01,  4.9132e-01, -1.6789e-01,  6.7627e-01,\n",
            "         -1.5309e-01,  7.5426e-01,  7.9017e-02,  3.4310e-01, -4.8216e-01,\n",
            "          4.3157e-01, -4.9703e-01, -9.4043e-02,  2.7237e-01],\n",
            "        [ 2.2431e-01, -1.1679e-01,  3.6945e-01, -2.7619e-01,  6.8971e-01,\n",
            "          9.8583e-02,  5.5081e-01, -1.2206e-01,  6.2343e-01,  5.2961e-02,\n",
            "         -1.2427e-01, -5.7509e-01,  9.4137e-02, -1.6672e-01,  1.9053e-01,\n",
            "          7.9522e-01,  1.3896e-01, -7.0973e-01, -5.9862e-01],\n",
            "        [-6.5103e-02, -2.2256e-02,  7.3170e-02,  1.5508e-02,  3.9090e-01,\n",
            "          3.2939e-01,  2.8652e-01, -4.5400e-01, -4.7076e-01,  6.8200e-01,\n",
            "          8.3452e-01, -2.9854e-02,  1.2211e-01,  2.6550e-01, -5.3070e-01,\n",
            "          5.3694e-01, -2.6978e-02,  1.7853e-01,  1.2770e-01],\n",
            "        [-3.7796e-01, -1.9395e-01,  3.7937e-01,  4.3510e-01,  5.1220e-01,\n",
            "         -4.9777e-03, -4.0464e-01,  4.0846e-01, -1.6023e-01,  2.2411e-01,\n",
            "         -1.7889e-01,  3.2323e-01,  1.7299e-01,  7.9511e-02,  5.1419e-01,\n",
            "          3.8786e-01,  4.5642e-01, -8.8761e-01,  2.0019e-01],\n",
            "        [-4.8441e-01, -1.0774e-01, -9.9484e-02, -9.0925e-02,  6.7354e-01,\n",
            "         -2.2223e-02,  4.8205e-01,  3.0967e-01,  7.2175e-01, -2.0948e-01,\n",
            "         -3.4146e-01,  6.5082e-01,  1.3781e-01, -5.7393e-01,  1.2619e-01,\n",
            "          5.3494e-01, -7.0960e-02, -4.5486e-02,  5.4033e-02],\n",
            "        [-6.1015e-02, -3.9225e-01,  8.3792e-02,  3.5096e-01,  7.5205e-01,\n",
            "          1.1367e-01, -4.2677e-02,  2.0617e-01, -2.5906e-02,  5.0377e-01,\n",
            "         -2.9905e-01,  6.6252e-01,  2.1340e-01, -4.6002e-01,  1.5222e-01,\n",
            "         -6.6618e-02, -8.8458e-02, -4.3643e-01,  4.9534e-01],\n",
            "        [ 1.7481e-01, -4.0116e-01,  3.3351e-01, -2.1367e-01,  4.3169e-01,\n",
            "         -2.4912e-01,  6.4766e-01,  3.5127e-01,  2.8927e-01, -1.4282e-01,\n",
            "         -1.0539e-01,  1.0870e-01, -3.1099e-01, -1.6795e-01, -3.6078e-02,\n",
            "          4.2846e-01,  5.4848e-02, -3.6002e-01, -5.0217e-02],\n",
            "        [ 1.1910e-01, -2.2649e-01,  1.2448e-01,  1.5730e-01,  3.3143e-01,\n",
            "         -4.0119e-01,  1.1056e-01, -6.0100e-01, -2.1229e-01,  2.8334e-01,\n",
            "         -2.4725e-01,  3.2535e-01,  4.3661e-02, -1.4705e-01,  1.0015e-01,\n",
            "          1.1639e-01, -7.7355e-02, -2.7424e-01, -9.1814e-02],\n",
            "        [-1.9692e-01, -3.1713e-01,  2.6445e-01, -3.1356e-01,  4.9514e-01,\n",
            "         -3.7523e-01,  1.0931e-01, -1.5130e-01,  5.9906e-01,  2.0302e-01,\n",
            "         -2.3784e-01,  5.3041e-01, -1.2021e-01, -1.0722e-01, -1.4159e-01,\n",
            "          2.8402e-01,  3.4034e-01, -1.7453e-01,  8.2924e-03],\n",
            "        [-1.3998e-01, -1.2217e-01,  4.4528e-01,  2.2324e-01,  7.0951e-01,\n",
            "         -1.1312e-01,  6.0103e-01, -1.1243e-01, -6.2707e-02,  4.5706e-01,\n",
            "          2.6745e-01,  3.3641e-01, -5.0970e-01,  1.5649e-01,  2.7837e-01,\n",
            "          4.9410e-01, -1.4748e-01, -6.7535e-01, -4.0703e-01],\n",
            "        [ 1.3900e-01, -2.3224e-01,  8.8565e-02, -1.8861e-01,  5.5945e-01,\n",
            "         -1.7457e-01,  2.6821e-01,  6.1211e-02,  4.3160e-01,  1.6905e-01,\n",
            "          5.1007e-01,  4.1136e-01, -3.4171e-01, -1.1180e-01,  5.0421e-01,\n",
            "          4.8535e-01,  1.5128e-01,  4.2666e-01, -1.1166e-01],\n",
            "        [-1.6963e-01, -6.2409e-01, -3.2088e-01,  2.5167e-01,  1.1886e-01,\n",
            "         -3.3423e-01,  1.1575e-03,  3.7882e-01,  9.6666e-02,  3.1158e-01,\n",
            "          1.7412e-02,  2.3959e-01, -2.8674e-01,  4.7610e-01,  7.0076e-01,\n",
            "          1.6645e-01,  2.8007e-01,  1.2047e-01,  1.1977e-01],\n",
            "        [-3.6462e-01, -9.8748e-01,  2.2193e-01,  3.7888e-01,  5.4668e-01,\n",
            "         -1.4742e-01,  1.7223e-01, -1.9735e-01,  1.6391e-01,  1.9300e-01,\n",
            "          1.0248e-01,  2.8602e-01,  3.0135e-01, -1.7888e-01,  4.4140e-01,\n",
            "          1.4957e-01,  3.9748e-02, -3.7377e-01,  2.3804e-01],\n",
            "        [-1.4264e-01, -3.0097e-01, -2.4636e-01,  9.1324e-01,  4.3037e-01,\n",
            "         -3.0601e-01,  6.4211e-01,  1.3739e-01,  3.8468e-01,  2.6304e-01,\n",
            "         -4.0075e-01,  1.9018e-01, -9.8778e-01, -2.2366e-01,  5.5799e-02,\n",
            "          4.5533e-01,  3.5935e-01, -1.3683e-01, -4.9120e-01],\n",
            "        [ 2.8714e-02, -6.4808e-01,  2.1152e-01, -2.4239e-01,  6.8418e-01,\n",
            "         -1.4386e-01,  2.8977e-01, -5.5457e-01,  2.9830e-01,  2.5730e-01,\n",
            "         -1.6580e-01,  7.5605e-01, -1.5794e-01, -3.5035e-01,  5.8571e-02,\n",
            "          5.9329e-01,  6.9310e-01, -8.8395e-02,  7.2258e-02],\n",
            "        [-1.2991e-01, -5.8753e-01,  4.6174e-01, -1.3789e-01,  6.4229e-01,\n",
            "          4.4802e-02, -1.9834e-01,  3.3294e-01,  5.4217e-01,  1.4264e-01,\n",
            "         -2.5069e-01,  5.7111e-01, -2.1304e-01, -1.1948e-01,  4.4087e-01,\n",
            "          1.8503e-01,  5.8469e-01, -3.0165e-01,  4.4627e-02],\n",
            "        [-1.2608e-01, -3.3655e-01,  1.7258e-02, -3.9253e-01,  1.4861e-01,\n",
            "         -3.0389e-01,  2.7929e-01, -2.2499e-01, -5.0800e-02,  2.9959e-01,\n",
            "          8.1568e-02,  1.4758e-01,  1.4335e-01, -6.1900e-01,  5.5040e-01,\n",
            "          4.4908e-01,  1.7953e-01, -7.8425e-02,  2.4325e-01],\n",
            "        [-6.0454e-02, -6.2922e-01, -1.4162e-01,  6.4638e-02,  8.0826e-01,\n",
            "         -3.5774e-01, -8.1330e-02,  2.3236e-01, -1.4042e-01,  3.1699e-01,\n",
            "          3.8729e-01,  4.5937e-01,  1.0219e-01,  4.7810e-02,  4.5949e-01,\n",
            "         -6.3247e-03, -1.2247e-01,  2.0857e-01, -3.2303e-01],\n",
            "        [-3.1741e-01, -3.2747e-01,  5.1611e-01, -8.5880e-03,  4.0849e-01,\n",
            "          7.0064e-02,  4.8723e-01, -2.3154e-01,  7.8030e-02,  3.1319e-02,\n",
            "          3.9160e-01,  7.1417e-02,  1.6555e-01, -4.7444e-01,  8.0678e-01,\n",
            "          5.0877e-01,  4.7120e-01, -6.4296e-03,  2.3982e-01],\n",
            "        [-6.8770e-02, -1.4971e-01,  1.4219e-01, -7.6428e-02,  4.3417e-01,\n",
            "         -3.2273e-01,  3.5839e-01,  1.0222e-02,  2.2010e-02,  1.9315e-01,\n",
            "          2.6768e-01,  1.8080e-01, -1.2678e-01, -3.5943e-01, -1.1525e-01,\n",
            "          1.2353e-02,  7.7956e-02, -1.3806e-01,  6.4985e-02],\n",
            "        [-4.6923e-01, -4.3214e-01, -1.3760e-01,  1.2681e-01,  6.3623e-01,\n",
            "         -2.5913e-01, -7.9563e-02,  1.6645e-02,  4.3206e-02,  7.3231e-01,\n",
            "          2.5739e-01,  5.2305e-03, -6.0647e-02,  3.3406e-02,  8.3288e-02,\n",
            "          4.7518e-01,  4.0953e-01, -5.0233e-01,  3.3673e-02],\n",
            "        [-9.6864e-02, -8.0509e-02,  7.1740e-02,  4.1290e-01,  5.2980e-01,\n",
            "         -1.3303e-01, -5.1733e-02,  2.8135e-01, -2.0286e-01,  2.5573e-01,\n",
            "          2.3346e-01,  4.0096e-01, -1.0205e-01, -1.5723e-01,  1.6115e-01,\n",
            "          3.9783e-01, -5.3714e-03, -3.0228e-01, -1.8280e-01],\n",
            "        [ 1.0551e-02,  1.7771e-02, -1.0489e-01, -8.7392e-02,  6.4950e-03,\n",
            "         -8.7594e-02,  1.4645e-01, -3.5511e-02,  3.7393e-01,  4.5813e-01,\n",
            "         -2.1101e-01,  1.8057e-01,  3.5752e-01, -2.9249e-01,  1.0542e-01,\n",
            "          1.8360e-01, -5.2763e-01,  1.0352e-01,  1.9068e-02],\n",
            "        [-4.1374e-01, -4.9207e-01, -3.2544e-01, -8.6684e-02,  3.2735e-01,\n",
            "          6.0168e-02, -1.9945e-01,  7.2794e-02, -2.0579e-01,  1.8881e-01,\n",
            "          6.4762e-02,  4.0106e-01,  3.5172e-02,  1.5853e-02,  4.2748e-01,\n",
            "          5.7298e-01, -3.7662e-02, -1.4915e-01, -1.3809e-01],\n",
            "        [-9.2678e-01, -1.4228e-01, -8.8847e-02, -2.0258e-01,  4.1772e-01,\n",
            "          1.3276e-01, -3.4887e-01, -1.1647e-01,  6.6491e-01,  1.4030e-01,\n",
            "         -2.0901e-02,  8.0946e-01, -1.7939e-01, -6.2692e-01,  1.6760e-01,\n",
            "          1.2622e-01,  1.1980e-01,  9.4535e-02, -2.8986e-01],\n",
            "        [ 6.8269e-02, -7.0187e-01,  1.5149e-02, -6.3203e-04,  2.9823e-01,\n",
            "         -2.2460e-01,  1.1874e-01,  1.4149e-02, -1.1154e-01,  1.5129e-01,\n",
            "         -5.2498e-01,  8.7364e-02, -2.8912e-01, -2.0939e-01,  1.0535e-01,\n",
            "         -9.4530e-03,  3.4106e-02,  5.9313e-02,  1.8629e-01],\n",
            "        [-4.5774e-01,  7.6467e-02, -8.2724e-02,  3.3624e-01,  5.4981e-01,\n",
            "          1.6429e-01, -2.1063e-01,  8.3472e-02, -2.5174e-02, -3.4156e-02,\n",
            "          2.9206e-01,  5.9823e-01,  3.8061e-02, -1.5609e-01,  2.8910e-02,\n",
            "          5.3166e-01, -1.2771e-01, -1.1719e+00,  1.1811e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-3.5856e-01, -1.1630e-01,  2.1284e-01,  2.6103e-02,  6.2253e-01,\n",
            "         -1.2879e-01,  1.3601e-01,  6.4521e-03,  3.6817e-01, -3.1489e-01,\n",
            "          3.3635e-01,  4.4586e-01, -1.6488e-01, -1.5459e-01,  9.7782e-02,\n",
            "          3.9838e-01, -1.8520e-01, -7.8045e-02,  3.3325e-01],\n",
            "        [-3.4241e-01, -7.3201e-01,  4.5332e-01,  1.6792e-01,  2.4377e-01,\n",
            "         -3.6792e-01,  2.0205e-01, -1.9477e-01,  6.3422e-01,  1.6829e-01,\n",
            "         -1.7633e-01,  6.3745e-04,  5.7130e-03, -4.0395e-02,  9.1388e-01,\n",
            "          5.6395e-01,  1.3007e-01, -5.3820e-01,  7.0074e-02],\n",
            "        [-4.6597e-01,  9.9048e-02,  3.5243e-01,  1.1723e-01,  7.8300e-01,\n",
            "         -1.8939e-01, -1.6134e-02, -5.7822e-02,  6.0944e-01,  2.3620e-01,\n",
            "          9.8198e-02,  6.4781e-01, -1.7852e-02,  1.2767e-01, -7.6896e-02,\n",
            "          5.8196e-02,  5.7738e-01, -9.3496e-01, -2.3190e-01],\n",
            "        [-6.7598e-02, -3.4675e-01, -1.4806e-01,  5.9833e-02,  4.9695e-01,\n",
            "         -5.4786e-01, -1.2197e-01, -1.1692e-01, -8.5860e-02, -1.6418e-01,\n",
            "         -2.5037e-01,  3.7567e-01, -8.3937e-02, -3.1592e-01,  3.9203e-01,\n",
            "          1.5723e-01,  4.5455e-01, -1.1399e-01,  7.7266e-02],\n",
            "        [-3.6411e-01, -7.5798e-01,  1.2282e-01, -1.5118e-01,  6.7674e-01,\n",
            "         -4.6960e-01,  4.5427e-02,  2.5842e-01,  2.1634e-01,  7.4250e-01,\n",
            "         -4.7504e-01,  8.9503e-01, -6.0079e-01, -3.5196e-01,  4.0360e-01,\n",
            "          3.9169e-01, -3.9931e-02, -1.9047e-01,  1.6760e-01],\n",
            "        [-8.4495e-02, -2.1160e-01,  1.2136e-01,  1.0098e-01,  5.2023e-01,\n",
            "         -3.4061e-01,  4.4817e-01, -5.3887e-01,  2.3197e-02,  8.6053e-02,\n",
            "         -2.4122e-01,  4.0769e-01, -5.2668e-02,  8.6286e-02,  2.3251e-01,\n",
            "          5.6151e-01,  1.3432e-01, -2.5951e-01, -4.1566e-01],\n",
            "        [-5.2248e-02, -5.4438e-01,  2.0014e-01, -8.9206e-02,  6.0005e-01,\n",
            "          8.2182e-03,  2.8564e-01,  3.3095e-01,  1.7460e-01,  3.2670e-01,\n",
            "         -4.7401e-01,  2.8418e-01,  1.9509e-01, -1.8271e-01,  5.9579e-01,\n",
            "          6.2545e-01,  4.2421e-02, -2.0717e-02, -1.5186e-01],\n",
            "        [-2.1001e-03, -1.5373e-01,  1.3867e-01,  1.2426e-01,  9.8921e-01,\n",
            "         -2.5229e-01, -8.7564e-03,  8.5616e-02, -9.4045e-02,  1.3841e-01,\n",
            "          1.2668e-01,  1.4469e-02, -2.2550e-01, -2.7024e-01,  7.0558e-02,\n",
            "          5.0945e-01,  2.0205e-01,  1.7063e-02,  1.1535e-01],\n",
            "        [-4.7946e-01, -2.9320e-01,  1.4048e-01, -1.6449e-01,  2.8189e-01,\n",
            "         -3.0185e-01,  5.9326e-01,  1.0974e-01, -2.8271e-01,  2.1044e-01,\n",
            "         -5.5578e-01,  1.9888e-01, -2.9902e-01, -6.4412e-01,  4.3745e-01,\n",
            "          4.7968e-01,  6.4785e-01,  3.8549e-01, -2.2020e-01],\n",
            "        [-1.4868e-01, -1.1327e-01, -3.9470e-02, -7.1885e-02,  4.4855e-01,\n",
            "         -1.3220e-01,  3.8215e-01, -5.5542e-01,  4.7323e-01,  1.3244e-01,\n",
            "          5.4288e-02,  2.4956e-01, -1.7336e-02, -1.0001e-01,  5.9057e-03,\n",
            "          3.7361e-02,  3.2869e-01, -2.9174e-01, -8.9634e-02],\n",
            "        [-2.7628e-01, -3.8525e-01, -2.5294e-01,  2.8169e-01,  2.4883e-01,\n",
            "         -6.1196e-01,  3.6163e-01,  2.3254e-01,  3.4363e-01,  2.4109e-01,\n",
            "          5.8741e-03,  1.9389e-01,  3.6424e-01,  2.0945e-01,  3.4247e-01,\n",
            "          1.0504e+00,  4.6304e-01, -9.1552e-02,  2.6553e-01],\n",
            "        [-3.6992e-01, -3.7822e-01,  3.1564e-01, -6.0918e-02,  6.0973e-01,\n",
            "         -2.8432e-01,  4.2276e-01, -1.9357e-01,  2.5391e-01, -7.0402e-03,\n",
            "          7.2171e-02,  5.8892e-01,  8.7399e-02, -9.4763e-02,  6.1704e-01,\n",
            "         -1.3619e-01, -1.5082e-01, -2.6994e-01, -1.9316e-01],\n",
            "        [-9.7394e-02, -2.0952e-01,  2.2341e-01,  3.5918e-01,  6.5021e-01,\n",
            "          2.0164e-01,  3.3834e-01, -3.7895e-01,  5.2843e-01, -4.4503e-02,\n",
            "         -5.9824e-01,  4.7673e-01, -7.0410e-01, -4.0435e-01,  5.3506e-01,\n",
            "          1.7438e-01,  4.9896e-01,  1.3387e-01,  2.1853e-01],\n",
            "        [ 2.6411e-01, -6.0623e-01,  5.6592e-01, -3.0867e-02,  2.0390e-01,\n",
            "          3.7296e-01,  2.9259e-01, -1.6256e-01,  3.8473e-01,  5.5810e-01,\n",
            "          3.8579e-01,  4.1389e-01, -5.7737e-01, -1.2327e-01, -4.8757e-01,\n",
            "          4.3705e-01,  2.4565e-01, -1.7205e-01, -3.8391e-01],\n",
            "        [-2.8620e-01, -3.7011e-01, -6.9886e-02,  2.3642e-01,  1.6010e-01,\n",
            "          4.2158e-01,  1.1475e-01, -2.1799e-01,  3.3912e-01,  5.4134e-01,\n",
            "          1.7674e-01,  8.8879e-01, -4.1881e-01, -4.8728e-02, -2.6763e-01,\n",
            "          6.1446e-01, -7.5309e-02,  2.1316e-01, -6.4728e-02],\n",
            "        [-1.9545e-02, -5.3479e-01,  4.8208e-01,  4.4100e-01,  7.0264e-01,\n",
            "         -4.1810e-01, -4.8339e-01, -3.2985e-02,  9.7556e-02,  6.2306e-02,\n",
            "         -1.1815e-01,  9.5363e-01, -2.5277e-02,  2.9761e-01,  1.2316e-01,\n",
            "          7.9487e-01,  4.1944e-01, -3.0371e-02, -8.0123e-02],\n",
            "        [-5.8277e-01, -2.7839e-01, -2.2233e-01,  9.9042e-02,  5.7626e-01,\n",
            "         -2.9967e-01,  1.1648e-01,  1.8888e-01,  5.3456e-01,  5.9242e-02,\n",
            "         -4.6710e-01,  2.8115e-01, -4.4512e-01, -3.1842e-01,  1.4596e-01,\n",
            "          2.6997e-01, -1.1710e-01, -3.5970e-01, -1.7727e-01],\n",
            "        [-9.4027e-02, -8.8146e-02,  1.8275e-01, -1.3622e-02,  5.7172e-01,\n",
            "         -1.0861e-01,  1.9692e-01,  1.1746e-01, -5.2624e-02, -3.2754e-03,\n",
            "          5.1890e-01,  6.6646e-02, -1.9126e-01, -6.8351e-01,  5.0670e-01,\n",
            "          3.9492e-01,  2.3229e-01, -2.8781e-01, -2.2284e-01],\n",
            "        [-6.9083e-01, -2.7658e-01, -5.6340e-03, -1.7389e-01,  3.1111e-01,\n",
            "         -1.8301e-01,  4.3855e-01, -7.6543e-02, -1.4249e-01,  4.9514e-01,\n",
            "         -2.2989e-01,  7.0939e-01, -2.1622e-01,  4.5335e-02,  2.5339e-01,\n",
            "          1.9160e-02, -7.5338e-02, -8.7437e-02,  1.1618e-01],\n",
            "        [-4.6675e-01, -5.2623e-01,  2.8810e-01,  1.1513e-01,  6.8887e-01,\n",
            "         -5.1182e-01, -2.0618e-01, -1.3720e-01,  4.5383e-01,  5.4629e-02,\n",
            "          3.2131e-01, -9.7646e-02, -5.0038e-01, -3.0796e-01,  5.5331e-02,\n",
            "          8.3817e-01, -3.0365e-01,  2.8289e-01, -3.8281e-01],\n",
            "        [-5.2568e-01, -2.1296e-03,  1.7130e-01, -2.2964e-01,  3.7284e-01,\n",
            "         -1.7835e-01, -2.3224e-01,  2.4895e-01,  3.6203e-02,  2.1572e-01,\n",
            "          6.7118e-01,  2.9586e-01, -2.3864e-01, -1.9769e-01,  2.3135e-02,\n",
            "          7.3375e-02, -4.6042e-01, -4.4491e-01,  9.7149e-02],\n",
            "        [-2.4769e-01, -1.8546e-01, -1.3849e-01, -1.3829e-01,  5.4286e-01,\n",
            "         -1.1639e-01, -9.1394e-02, -9.6864e-02,  6.9252e-01,  3.1549e-01,\n",
            "          1.3377e-01,  1.3507e-01, -2.0701e-01, -2.0791e-01,  3.6776e-01,\n",
            "          7.6131e-01, -1.1919e-01, -7.2252e-01, -9.4462e-02],\n",
            "        [-3.1736e-01, -1.7835e-01,  1.1418e-01, -1.0670e-01,  6.7338e-01,\n",
            "          5.3603e-02,  1.4282e-01,  7.9509e-01,  4.0383e-01,  2.4870e-01,\n",
            "          4.9035e-02,  4.3821e-01, -6.2425e-02, -1.7495e-01,  2.1757e-01,\n",
            "          1.0377e-01, -2.4301e-01, -5.9203e-01, -1.5878e-01],\n",
            "        [ 2.6820e-01, -1.6299e-01,  1.3035e-01, -5.1252e-01,  9.6572e-01,\n",
            "         -2.4062e-01,  2.4238e-01, -2.3515e-01, -1.2751e-01,  3.8625e-01,\n",
            "          2.7541e-01, -3.3256e-02, -1.9064e-01,  4.2483e-02,  9.3088e-02,\n",
            "          4.2226e-01, -6.2682e-02, -4.4737e-01,  9.9201e-02],\n",
            "        [ 2.2838e-01, -5.6301e-01,  2.0992e-01,  1.3431e-01,  4.5561e-01,\n",
            "         -4.1457e-01,  1.5568e-02,  5.0927e-02,  4.4469e-01,  2.8077e-01,\n",
            "          4.6454e-01,  8.8267e-01, -2.9664e-01,  1.3826e-01,  4.9404e-01,\n",
            "          5.5687e-01,  2.3842e-01,  2.9524e-01,  3.9489e-01],\n",
            "        [-2.3580e-01, -1.5051e-01, -4.4253e-01, -1.0058e-01,  3.9892e-01,\n",
            "          1.9438e-01,  1.8670e-01,  5.3565e-01,  7.3720e-02,  1.2496e-01,\n",
            "         -2.1005e-01,  5.8862e-01, -1.4417e-01, -8.8860e-02, -4.7307e-02,\n",
            "          3.6550e-01,  2.4032e-02, -4.1805e-01,  9.6254e-02],\n",
            "        [-2.6855e-01, -3.1167e-01, -4.8504e-02,  5.3525e-01,  6.0003e-01,\n",
            "          2.3920e-01,  1.5444e-02,  2.3025e-02,  1.1764e-02,  2.3893e-01,\n",
            "         -9.8874e-02,  2.2093e-01, -1.6907e-01,  6.9047e-02,  3.5781e-01,\n",
            "         -2.8774e-02, -2.1430e-02, -1.2545e-01,  1.8529e-01],\n",
            "        [-3.3295e-01, -1.4521e-01,  7.8928e-02,  9.9826e-02,  4.5463e-01,\n",
            "         -4.1478e-01,  1.5376e-01,  3.0361e-01,  4.2365e-01, -2.3697e-01,\n",
            "          1.8448e-02,  6.3317e-01,  3.3599e-01, -3.4545e-02,  1.9890e-01,\n",
            "          3.3916e-01, -7.8028e-02,  1.0559e-01, -4.6746e-04],\n",
            "        [-4.3787e-01, -3.0171e-01, -3.3253e-01,  3.5325e-01,  3.8597e-01,\n",
            "          4.4200e-02, -3.4773e-01,  6.7588e-02, -1.1946e-01,  5.4194e-01,\n",
            "          1.4234e-01,  4.0925e-01,  4.2999e-01, -8.8302e-02,  3.5051e-01,\n",
            "         -7.6529e-03,  1.8148e-01, -2.8391e-01, -1.0878e-01],\n",
            "        [-1.3407e-01, -2.6318e-01,  3.1565e-01, -3.3204e-01,  6.9163e-01,\n",
            "         -2.0866e-01,  2.4827e-01,  8.3907e-03,  2.3417e-02,  7.5985e-02,\n",
            "          5.5742e-01,  2.9228e-01, -8.7415e-02, -1.8520e-01,  3.6672e-01,\n",
            "          2.8090e-01,  2.9262e-01,  9.1305e-03, -3.8010e-01],\n",
            "        [-1.5712e-01, -5.8495e-01,  2.1305e-01, -3.1851e-01,  8.6041e-01,\n",
            "         -1.2834e-01, -1.0011e-01, -8.6450e-02,  2.4492e-01,  2.1693e-01,\n",
            "         -1.0415e-02,  4.8821e-01, -2.0604e-01, -5.7232e-02,  2.6502e-01,\n",
            "          8.7779e-02,  3.4484e-01,  8.1969e-02,  1.4306e-01],\n",
            "        [ 5.3773e-02, -1.2999e-01, -3.8675e-02, -3.1121e-01,  4.7483e-01,\n",
            "         -3.7228e-01,  2.1797e-01, -3.1883e-01,  1.3066e-02,  1.2465e-01,\n",
            "          6.8985e-02,  1.6962e-01, -3.2755e-01, -7.3505e-02, -7.1037e-02,\n",
            "          1.9672e-01, -8.2880e-02, -2.7600e-01, -6.1384e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-1.4888e-01, -4.5616e-01, -1.0241e-01, -1.6258e-01,  3.9598e-01,\n",
            "         -2.5577e-01,  8.6409e-02,  3.7534e-01,  2.3939e-01,  4.2862e-02,\n",
            "          1.9033e-01,  5.7010e-01,  7.2158e-02, -1.4299e-01,  9.6657e-02,\n",
            "          1.7753e-01,  1.5189e-01, -3.2513e-01, -1.9086e-01],\n",
            "        [-2.4138e-01,  6.4344e-02,  9.1352e-01,  6.8707e-02,  8.2900e-01,\n",
            "         -1.4662e-01, -1.7328e-01, -2.6691e-01,  2.4126e-01,  6.3118e-03,\n",
            "          1.3813e-01,  1.0386e-01, -1.1180e-01, -3.0822e-01,  1.9421e-01,\n",
            "         -1.1237e-01, -5.5442e-02, -6.9470e-02, -1.3269e-01],\n",
            "        [ 1.4018e-02, -1.6563e-01,  9.5078e-02,  2.9321e-01,  2.9313e-01,\n",
            "         -1.7091e-01, -3.0084e-01, -1.7503e-01,  2.7857e-01,  4.8091e-01,\n",
            "         -2.7432e-01,  3.7750e-01,  9.4580e-02,  4.3563e-02,  2.1303e-01,\n",
            "          3.9036e-01,  2.9768e-01,  2.8473e-01, -6.4563e-03],\n",
            "        [-1.5678e-01, -4.3331e-01,  2.9145e-01, -1.4339e-01,  6.1745e-01,\n",
            "         -8.6482e-02,  2.1436e-01, -1.1045e-01,  3.2346e-01,  1.4030e-02,\n",
            "         -8.8679e-01,  5.1585e-01, -4.5317e-01, -1.2027e-01,  4.2544e-01,\n",
            "          3.4601e-02, -2.1344e-01, -1.9196e-01, -4.3304e-01],\n",
            "        [-6.7084e-02, -3.1990e-01,  3.5219e-02,  1.9920e-01,  4.9226e-01,\n",
            "         -5.4123e-01, -2.4661e-02, -8.1834e-02,  1.1618e-01,  2.3168e-01,\n",
            "         -1.7660e-01,  6.5825e-01, -5.9713e-01,  3.6667e-01, -6.2712e-02,\n",
            "          2.0150e-01,  1.8094e-01, -1.2602e-02, -8.0638e-02],\n",
            "        [-8.7439e-02, -3.8974e-01,  5.4036e-01, -5.6076e-01,  4.8472e-01,\n",
            "         -5.2741e-01,  1.5878e-01,  1.2000e-01,  1.3172e-01,  2.3204e-01,\n",
            "         -3.2809e-01,  2.2881e-01, -1.7572e-01, -1.2792e-01, -2.3904e-01,\n",
            "          1.3455e-01,  1.7996e-01,  1.1497e-01, -2.8566e-01],\n",
            "        [-4.7254e-01, -1.4701e-01,  2.3523e-01, -2.4469e-01,  1.7825e-01,\n",
            "         -1.4788e-02, -9.9118e-02,  5.6979e-02, -8.4757e-02,  3.0073e-01,\n",
            "          5.3432e-02,  1.0796e-01,  1.4154e-01, -2.2897e-01,  2.4877e-01,\n",
            "          2.8504e-01,  4.2511e-01, -3.5421e-01,  1.9318e-01],\n",
            "        [-3.8553e-01, -2.2879e-02,  2.5959e-01, -1.5867e-01,  3.5655e-01,\n",
            "          1.9301e-01,  5.1082e-01, -2.3090e-01,  5.1697e-02,  5.2855e-02,\n",
            "         -1.0242e-01,  6.5136e-02, -1.3987e-01, -2.3501e-01,  4.8334e-02,\n",
            "          2.0338e-01,  2.8320e-01, -1.8675e-01, -2.7907e-01],\n",
            "        [-2.1511e-01, -2.9614e-01,  2.2544e-01,  1.3888e-01, -2.1457e-02,\n",
            "         -4.4558e-04,  2.2863e-01, -2.1486e-01,  4.3293e-01,  7.3440e-02,\n",
            "         -1.6811e-01,  6.3073e-01,  5.5091e-01, -1.6129e-02,  5.9156e-01,\n",
            "          3.5195e-01,  1.8011e-01, -2.7930e-01,  2.5545e-02],\n",
            "        [ 1.2832e-01,  5.3967e-02,  3.5049e-01,  5.5678e-01,  7.6917e-01,\n",
            "         -3.1185e-01,  1.5280e-01, -3.4868e-01,  3.6349e-02,  3.1079e-01,\n",
            "         -1.7684e-01,  5.2941e-01,  7.1153e-02,  1.6823e-01, -2.2006e-01,\n",
            "          7.9927e-02,  1.5784e-01, -2.0389e-01,  1.6966e-01],\n",
            "        [-2.9331e-01, -2.6721e-01,  1.3824e-01,  2.5195e-01,  4.2788e-01,\n",
            "         -2.1643e-01,  1.6837e-01,  8.9680e-02,  3.1423e-01,  1.6524e-02,\n",
            "         -7.2887e-02,  5.9579e-01,  5.0540e-01, -2.4101e-01,  3.9219e-01,\n",
            "          5.3373e-01,  1.9661e-01, -4.1913e-01,  2.6135e-01],\n",
            "        [-3.6287e-01, -1.1764e-01, -1.5956e-01,  5.9674e-02,  1.0443e+00,\n",
            "         -3.9113e-01,  3.3566e-01, -2.9355e-01,  3.0148e-01,  3.4200e-02,\n",
            "          3.7790e-01,  3.4995e-01, -7.0781e-01, -6.1580e-01,  1.5047e-02,\n",
            "          7.7405e-01, -1.2439e-01, -3.2207e-01, -1.8579e-01],\n",
            "        [-4.9038e-01, -1.7637e-01,  4.8316e-01, -5.1489e-02,  6.8981e-01,\n",
            "         -7.6169e-01,  4.5178e-02, -3.0998e-01,  2.1463e-01,  4.8277e-01,\n",
            "         -5.4529e-01,  3.4136e-01,  6.0253e-03,  2.5939e-01,  3.1755e-01,\n",
            "          6.5495e-01, -9.6168e-02,  5.0740e-01,  2.6632e-01],\n",
            "        [ 1.8595e-01, -4.8784e-01,  2.6748e-01, -7.1563e-02,  9.9524e-01,\n",
            "          2.2886e-02,  6.2355e-01, -8.4632e-02,  3.9270e-01, -8.7934e-02,\n",
            "         -1.1473e-02,  8.3434e-01, -3.9223e-01,  3.1184e-02, -4.6721e-02,\n",
            "          4.5495e-01,  4.3015e-02, -4.5912e-01, -4.0984e-01],\n",
            "        [-4.9608e-01, -3.3930e-01,  4.8568e-01,  2.5585e-01,  2.4426e-01,\n",
            "         -3.4393e-01,  3.8754e-01,  2.4863e-01,  6.6364e-01,  3.3769e-01,\n",
            "         -8.9324e-02,  1.8650e-01, -1.5385e-01, -1.4257e-01,  3.4480e-01,\n",
            "          6.0488e-01,  1.0793e-01, -2.4621e-01,  2.6466e-01],\n",
            "        [-8.5479e-01, -4.9263e-01,  3.3345e-01, -1.1453e-01,  7.1272e-01,\n",
            "         -2.5055e-01,  4.7693e-02,  1.1964e-01,  5.3880e-01,  4.6363e-01,\n",
            "          3.5629e-01,  4.7265e-01, -6.0861e-01, -1.6696e-01,  4.2108e-01,\n",
            "          6.2242e-02,  4.0210e-02, -2.5317e-01, -1.6097e-01],\n",
            "        [ 8.9997e-03, -1.0651e+00, -1.0833e-01,  2.5199e-01,  1.0130e+00,\n",
            "          1.1004e-01,  3.8024e-01,  1.3846e-02,  6.5759e-01, -5.8076e-02,\n",
            "         -5.3441e-01,  1.9001e-01,  2.0365e-01, -1.0298e-01,  8.1866e-01,\n",
            "         -2.2792e-02,  5.7755e-02, -5.5975e-02, -4.7288e-01],\n",
            "        [-1.3310e-01, -1.1758e-01, -7.5784e-02, -3.7355e-01,  3.5942e-01,\n",
            "         -1.4877e-02, -2.8221e-02,  1.7356e-01, -1.2772e-01,  3.3327e-01,\n",
            "         -1.2566e-01,  7.6077e-01,  3.2026e-02, -7.9849e-03, -6.0680e-03,\n",
            "          3.3202e-01,  2.7860e-01,  5.6011e-03,  1.7965e-02],\n",
            "        [-3.4223e-01, -8.3817e-02, -1.8102e-01, -6.9332e-03,  5.9859e-01,\n",
            "          2.6695e-01,  1.5499e-02,  1.1569e-01,  3.0750e-01,  6.1300e-02,\n",
            "         -1.4415e-01,  3.8507e-01, -2.3659e-02, -2.2831e-01,  1.3208e-01,\n",
            "          4.1659e-01, -7.3753e-02, -1.3929e-01, -8.5025e-02],\n",
            "        [-4.0174e-02, -7.6891e-01,  1.2202e-01,  4.4693e-02, -8.5308e-02,\n",
            "         -1.7729e-01, -5.6633e-02,  9.3545e-02,  2.8624e-01,  2.1927e-01,\n",
            "          8.8386e-02,  6.6621e-01,  3.9602e-03, -4.8331e-01,  1.7732e-01,\n",
            "          6.4424e-01,  2.9289e-01, -3.6143e-01,  1.9978e-01],\n",
            "        [-4.9416e-01, -2.1293e-01,  1.0723e-01,  2.9580e-01,  3.1952e-01,\n",
            "         -6.0691e-02, -1.7823e-02, -6.9231e-01,  1.5182e-01, -1.2836e-02,\n",
            "         -1.3318e-02,  4.1929e-01, -2.3493e-01, -7.4101e-01, -9.8312e-02,\n",
            "          2.9884e-01, -1.2301e-01, -7.6072e-01, -3.0622e-01],\n",
            "        [-3.5692e-01, -2.0920e-01,  2.8793e-01, -9.1035e-02,  7.1964e-01,\n",
            "         -9.0092e-02, -6.0687e-03, -1.2005e-01, -1.8455e-01,  8.7547e-02,\n",
            "         -7.6212e-03,  3.2037e-01,  3.4709e-01, -3.9055e-01,  2.5599e-01,\n",
            "          2.9893e-01,  1.7152e-01,  2.1594e-01, -2.6824e-01],\n",
            "        [-3.8898e-01, -2.4722e-01,  4.0744e-01, -4.0474e-02,  6.2728e-01,\n",
            "         -2.2597e-01,  6.3765e-02, -5.3823e-01,  4.5885e-01,  1.2540e-01,\n",
            "          5.2815e-02,  5.4881e-01, -2.1172e-01, -3.1492e-01, -3.0189e-01,\n",
            "          7.8973e-01,  5.1030e-01,  3.8634e-01, -7.9793e-02],\n",
            "        [-8.7047e-02, -6.7228e-01,  5.4446e-01,  8.4836e-02,  8.1832e-01,\n",
            "         -1.4349e-01,  1.5923e-01,  2.1449e-02,  2.0488e-01,  2.0071e-01,\n",
            "         -2.2253e-01,  3.3067e-01, -2.4295e-01,  2.5664e-03, -1.6239e-02,\n",
            "          3.2012e-01,  2.5018e-03,  3.0197e-01, -3.3333e-02],\n",
            "        [-3.9719e-01, -9.0717e-02,  2.5149e-01,  3.6372e-01,  1.0705e+00,\n",
            "         -1.6126e-01,  2.7608e-01,  4.9734e-02,  3.4510e-01, -8.1434e-02,\n",
            "          9.9767e-02,  1.4068e-01, -6.9530e-01, -4.5322e-01,  2.1632e-01,\n",
            "          2.2628e-01, -1.3443e-01, -2.4946e-01, -2.1652e-01],\n",
            "        [-4.3712e-01, -1.0255e-01,  1.2151e-01,  7.9062e-02,  7.9750e-01,\n",
            "         -2.4018e-01,  2.7099e-01,  1.7432e-01,  3.8170e-01,  2.8031e-01,\n",
            "          1.3894e-01,  6.0491e-01, -1.7733e-01, -3.0108e-01, -4.1015e-01,\n",
            "          2.3611e-01,  2.4607e-01, -2.3175e-01, -3.1827e-01],\n",
            "        [-3.6254e-01, -3.1595e-01,  1.8469e-01,  2.8504e-02,  4.0079e-01,\n",
            "         -2.7768e-01,  3.0534e-01, -4.0631e-01,  3.2563e-01, -1.5143e-01,\n",
            "          1.6684e-01,  5.7668e-01, -1.7115e-02, -2.4854e-01,  3.6381e-01,\n",
            "          3.4547e-01,  1.7722e-01,  2.5124e-01, -3.0315e-01],\n",
            "        [-2.4501e-01, -2.8901e-02,  1.0605e-01,  1.5123e-01,  6.9214e-01,\n",
            "         -8.1538e-02, -8.0210e-03, -7.8595e-02, -5.2319e-02, -9.1225e-02,\n",
            "          5.1184e-02,  1.5835e-01,  1.3784e-01, -5.7340e-02,  2.6824e-01,\n",
            "          8.6733e-02,  7.8206e-02,  5.4415e-03, -4.8326e-01],\n",
            "        [ 2.0676e-02, -2.2767e-01, -4.3974e-02, -4.2250e-01,  4.7189e-02,\n",
            "          8.8328e-02,  1.5330e-03, -2.7065e-01,  3.6563e-02,  4.1859e-02,\n",
            "          1.5237e-01,  5.4582e-01, -4.8872e-02, -4.7364e-01,  3.0847e-01,\n",
            "          4.8971e-01,  2.9434e-01, -1.4244e-01, -1.2902e-01],\n",
            "        [-5.0907e-01, -3.4447e-01,  6.5974e-02,  2.0042e-01,  3.4236e-01,\n",
            "         -9.0023e-02,  1.1770e-01,  2.1369e-01,  5.8045e-01, -4.8819e-03,\n",
            "          1.9889e-01,  3.8422e-01, -4.7330e-01,  2.7111e-02,  2.4966e-01,\n",
            "          2.1679e-01,  3.8100e-01, -1.4060e-01, -3.9676e-01],\n",
            "        [-5.2709e-01, -7.2314e-01, -1.7900e-01,  1.7704e-02,  1.1226e+00,\n",
            "         -3.9337e-01, -1.4251e-01,  4.8385e-02,  3.2328e-01,  4.5761e-01,\n",
            "         -2.0724e-01,  7.1593e-01, -2.6224e-01,  1.1478e-01,  2.4021e-01,\n",
            "          3.5252e-01,  3.2069e-01,  4.6525e-01, -7.3827e-02],\n",
            "        [-3.9694e-02, -3.4273e-01,  4.4762e-01,  3.0417e-02,  4.1814e-01,\n",
            "         -3.1537e-01,  2.8701e-01, -2.5066e-02,  3.7840e-01, -1.3861e-01,\n",
            "         -4.3415e-01,  7.4572e-01,  2.6589e-01, -2.6191e-01, -9.0846e-02,\n",
            "          6.5488e-02,  4.2984e-01,  9.5469e-02,  2.1795e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-1.9785e-01, -9.1153e-02, -1.6339e-01,  3.0046e-01,  7.5121e-01,\n",
            "         -3.6274e-01,  2.4886e-01, -6.8255e-02,  6.4395e-01,  2.9441e-01,\n",
            "          5.8933e-02,  1.5783e-01, -2.5581e-01, -1.4468e-01,  3.5572e-01,\n",
            "          6.0189e-01,  1.2374e-01,  7.3630e-02, -4.7163e-01],\n",
            "        [-2.8667e-01, -1.4602e-02,  4.7575e-01, -8.3830e-02,  5.8525e-01,\n",
            "          8.3188e-02, -1.1555e-02,  2.3429e-01,  1.9106e-02,  8.3629e-02,\n",
            "         -6.5264e-03,  1.4209e-01, -5.0099e-01, -8.8976e-02,  3.5819e-01,\n",
            "          4.8182e-01,  6.4733e-01, -4.4602e-03, -3.1594e-01],\n",
            "        [ 2.5924e-01, -5.4501e-01, -1.4437e-02,  3.5731e-01,  6.0057e-01,\n",
            "         -1.0726e-01,  6.9514e-02, -1.9197e-01,  1.1253e-01,  1.0500e-01,\n",
            "          1.0243e-01,  3.1456e-02, -2.3937e-01, -4.3373e-01,  1.1655e-01,\n",
            "         -4.5876e-04,  1.0946e-01, -1.0050e-01,  3.8546e-02],\n",
            "        [-1.3402e-01, -3.5162e-03, -3.7707e-01, -8.7761e-03,  1.3238e+00,\n",
            "          3.9999e-01, -7.0066e-02, -6.9971e-02,  2.2151e-01, -3.2803e-01,\n",
            "          4.9034e-02,  3.7851e-01,  4.6906e-01,  1.8234e-02,  4.6054e-02,\n",
            "          1.9052e-01,  4.4030e-01,  1.0369e-01, -2.3555e-01],\n",
            "        [-7.6691e-02, -2.0892e-01,  4.8266e-01,  6.4873e-02,  9.0695e-01,\n",
            "         -3.5245e-01, -2.0542e-01, -7.7093e-02,  1.5761e-01,  2.4914e-01,\n",
            "          1.8628e-01,  3.9058e-01, -3.3603e-01, -1.6561e-01,  7.3031e-01,\n",
            "          8.1608e-01,  1.3095e-01, -3.5041e-01, -2.3255e-01],\n",
            "        [-1.4291e-01, -2.7019e-01,  2.4013e-01, -2.2365e-01,  5.5013e-01,\n",
            "         -2.3005e-01,  2.1387e-01, -3.7708e-01, -4.1219e-01,  2.3969e-01,\n",
            "          3.7598e-01,  3.5705e-01, -4.3064e-01, -3.0905e-01,  3.8346e-01,\n",
            "          4.2257e-01,  2.5193e-01, -7.7040e-02,  1.0253e-01],\n",
            "        [-2.1005e-01, -3.2509e-01,  6.0680e-02, -1.3197e-01,  1.0194e+00,\n",
            "         -1.3056e-01,  3.1205e-01, -2.1965e-02,  5.5071e-02,  1.4362e-01,\n",
            "         -4.3455e-01,  1.7152e-01, -5.1417e-01, -3.7558e-01,  9.6698e-02,\n",
            "          1.8135e-01,  4.6131e-01,  1.5439e-01, -3.9919e-01],\n",
            "        [-3.1512e-01, -2.8922e-01,  8.3480e-02,  5.7015e-02,  3.6564e-01,\n",
            "         -2.1829e-01,  9.0608e-02,  5.1723e-02,  4.2395e-02,  6.7112e-02,\n",
            "         -3.8261e-03,  4.7517e-01, -9.7621e-02, -3.4557e-01,  3.3712e-01,\n",
            "          3.8697e-01,  1.4139e-01,  4.1609e-04,  9.4851e-02],\n",
            "        [-9.3831e-01, -1.1688e-01,  5.2920e-01,  1.9474e-01,  6.4857e-01,\n",
            "          5.1371e-01,  9.5833e-02, -1.1129e-01, -4.8337e-02,  2.3850e-01,\n",
            "         -1.0362e+00,  5.0099e-01, -1.0254e+00, -4.5484e-01,  3.8898e-01,\n",
            "          8.3171e-01,  8.3123e-01, -2.9321e-01, -1.1140e-01],\n",
            "        [-1.4887e-01, -5.4041e-01,  1.9521e-01,  1.8394e-01,  6.7135e-01,\n",
            "          4.6828e-01,  4.3890e-01, -1.4681e-02,  9.0283e-01, -6.6715e-02,\n",
            "          3.0502e-01,  3.0792e-01,  5.8484e-02, -1.9961e-01,  2.5244e-02,\n",
            "          5.0135e-01, -2.6832e-01,  1.5638e-01,  1.8654e-01],\n",
            "        [-6.1390e-01, -1.4245e-01,  2.9417e-01,  4.7801e-02,  7.4052e-01,\n",
            "         -2.2916e-01,  7.4778e-02, -5.6418e-02, -3.6143e-01,  3.7389e-01,\n",
            "         -2.5057e-01,  4.1237e-01, -5.3961e-01, -2.1520e-01,  1.1665e-01,\n",
            "          4.8561e-01,  5.6686e-01, -2.6735e-01, -3.7910e-01],\n",
            "        [ 1.6853e-01, -2.8007e-01,  4.8823e-01,  4.8253e-01,  1.0197e+00,\n",
            "         -5.1772e-01, -6.0703e-01,  3.7618e-01,  3.4686e-01,  1.5460e-01,\n",
            "         -7.0129e-01,  3.6088e-01, -4.2233e-02,  1.3404e-01,  5.5435e-01,\n",
            "          1.8206e-01,  2.9092e-01, -3.5082e-01, -2.6556e-01],\n",
            "        [-3.3426e-01, -4.6422e-01, -2.1069e-01, -9.1646e-02,  7.4916e-01,\n",
            "          1.8705e-01, -5.8342e-01, -3.2326e-01,  7.3016e-01, -3.5147e-01,\n",
            "         -4.8823e-01,  3.7330e-01, -9.0475e-02, -4.1044e-01, -9.3357e-02,\n",
            "          6.8004e-01,  3.8976e-01, -1.2843e-01, -1.4348e-01],\n",
            "        [-4.9329e-01,  2.0721e-01,  2.9252e-01, -6.7771e-01,  5.1440e-01,\n",
            "         -5.5798e-02,  7.8025e-02, -2.5724e-01,  2.5452e-01, -7.8354e-02,\n",
            "         -9.7806e-02,  6.1784e-01, -3.3748e-01,  2.2973e-01,  2.3528e-01,\n",
            "         -6.8120e-02,  1.3042e-01,  3.8048e-01, -9.1483e-02],\n",
            "        [-2.8348e-01, -2.9284e-01, -3.1716e-02, -1.1937e-01,  8.6198e-01,\n",
            "          4.7113e-02,  3.8608e-02, -7.8581e-02,  3.7050e-01, -1.2526e-01,\n",
            "         -2.1110e-02,  6.3191e-01, -2.1580e-01, -1.8593e-01, -2.3870e-01,\n",
            "          4.8627e-01,  5.3341e-02, -6.9899e-02, -9.4717e-02],\n",
            "        [-3.4324e-01, -3.8696e-01,  3.0828e-01, -3.6071e-03,  6.1103e-01,\n",
            "         -7.2040e-02,  5.7834e-02,  6.2607e-02,  1.2693e-01,  2.4761e-01,\n",
            "         -3.5579e-01,  5.7669e-01,  6.0980e-02, -5.9004e-02,  3.3194e-01,\n",
            "          3.9335e-01, -1.4142e-01, -4.0691e-01,  7.7625e-02],\n",
            "        [-4.1659e-01,  3.2886e-01, -4.0124e-01, -3.6138e-01,  3.7629e-01,\n",
            "         -3.4166e-01,  2.5875e-02, -4.2917e-01,  3.5155e-01, -4.6365e-01,\n",
            "          3.0380e-01,  1.0222e+00,  3.3298e-02, -6.0190e-01,  1.1641e-01,\n",
            "          2.7844e-01,  1.6246e-01,  8.5013e-02, -7.2261e-02],\n",
            "        [ 3.0538e-01, -3.8831e-01,  4.0628e-02,  3.9106e-01,  2.2846e-01,\n",
            "         -2.3857e-02,  4.3671e-01, -1.7691e-01,  2.3920e-01, -1.3334e-01,\n",
            "         -1.8613e-01,  2.2489e-01, -1.0747e-01, -1.4198e-01,  1.7744e-01,\n",
            "          2.0994e-01,  1.6236e-01, -1.3173e-01, -1.2018e-01],\n",
            "        [-4.7633e-01, -6.1450e-01,  1.5959e-01,  6.6488e-02,  6.7000e-01,\n",
            "          4.2886e-01, -4.3294e-01, -4.6660e-01,  5.3321e-01, -2.2849e-01,\n",
            "          1.3679e-01,  1.1646e+00, -2.3126e-01, -3.7922e-01,  2.7342e-01,\n",
            "          6.9557e-01,  7.3071e-01, -3.5657e-01,  2.9326e-01],\n",
            "        [-2.0801e-01, -3.2360e-01, -7.2454e-02,  3.5803e-01,  1.0110e+00,\n",
            "         -2.0375e-01, -7.7450e-02, -1.4183e-01,  6.4446e-01, -1.4292e-01,\n",
            "          8.4985e-02,  5.5892e-01, -5.2355e-01, -2.1000e-01,  2.0532e-01,\n",
            "          8.9108e-01, -3.4166e-01, -7.2491e-02,  1.9709e-02],\n",
            "        [ 1.9196e-02, -3.4434e-01, -1.1219e-01,  2.3746e-01,  7.8543e-01,\n",
            "         -2.4853e-01, -4.2596e-01,  1.3239e-01,  4.6441e-01,  8.6720e-02,\n",
            "         -1.2412e-01,  4.3035e-01, -1.4745e-01, -7.7674e-01,  5.7264e-02,\n",
            "          2.8112e-01,  6.4899e-01, -2.8007e-01, -5.4981e-01],\n",
            "        [ 1.0664e-01, -8.1644e-01, -1.4561e-01,  5.4254e-01,  6.9493e-01,\n",
            "          1.0685e-01, -2.1323e-02,  1.8936e-01, -9.2392e-02,  2.2931e-02,\n",
            "         -7.5755e-01, -2.6046e-02,  1.7599e-01, -1.5809e-01, -9.5446e-02,\n",
            "          2.0831e-01,  9.4715e-02,  7.5018e-02, -3.7026e-01],\n",
            "        [-5.2244e-01, -2.5996e-01,  7.5067e-02, -8.8158e-02,  8.7271e-01,\n",
            "         -7.2297e-01,  3.4636e-03,  2.8141e-01, -4.1396e-02,  8.4224e-02,\n",
            "         -2.3793e-02,  3.7873e-01, -4.1645e-01, -2.3838e-01,  1.5478e-01,\n",
            "          5.9922e-01,  2.8699e-01,  8.0111e-02, -4.1496e-01],\n",
            "        [-1.3687e-01, -6.9702e-01,  1.9256e-01,  4.5797e-01,  3.5599e-01,\n",
            "         -5.8467e-01,  1.0915e-01, -1.8790e-01,  7.3832e-01, -1.9461e-01,\n",
            "         -4.6192e-01,  1.1928e+00,  2.2684e-01, -2.1031e-02,  4.3611e-01,\n",
            "         -5.0450e-02,  3.0366e-01,  3.8051e-01, -3.4685e-01],\n",
            "        [-8.7950e-01, -3.4237e-01, -1.2517e-01,  1.0296e-01,  1.6336e+00,\n",
            "         -5.1188e-01,  2.5249e-01, -2.1832e-02,  4.9835e-01,  3.3651e-01,\n",
            "         -4.1159e-01,  6.2746e-01, -4.1002e-02, -7.7105e-03, -1.9299e-01,\n",
            "          4.3990e-01,  1.4061e-01,  2.3875e-01,  2.3998e-01],\n",
            "        [-7.4058e-01,  6.5212e-02,  3.1031e-02,  1.1371e-01,  4.2163e-01,\n",
            "         -1.6565e-01,  3.7086e-01, -1.9328e-02,  4.1617e-01, -3.4949e-01,\n",
            "         -4.2250e-01,  6.4333e-01,  3.4280e-01, -1.1530e-01, -1.0261e-01,\n",
            "          6.2274e-01,  5.7371e-01, -6.9292e-03, -3.2255e-01],\n",
            "        [-3.8403e-01, -7.8589e-02, -1.1992e-01,  2.3592e-02,  2.5120e-01,\n",
            "          1.6360e-01,  8.2334e-02,  8.8614e-02,  5.2031e-01, -2.7446e-01,\n",
            "         -4.0033e-01,  6.6049e-01, -3.1539e-02, -1.6719e-01,  1.3284e-01,\n",
            "          4.1715e-01,  5.9187e-01, -1.6207e-01, -9.1519e-02],\n",
            "        [-2.5951e-01, -1.8263e-01,  1.2661e-01, -2.7296e-02,  7.6993e-01,\n",
            "         -2.7827e-01,  6.1887e-01, -4.1934e-01,  6.3435e-01,  1.0077e+00,\n",
            "          6.5000e-02,  4.0686e-01, -3.8173e-01, -3.4912e-01, -4.0380e-02,\n",
            "          1.4162e-01,  5.1236e-01, -1.5778e-01,  7.8652e-02],\n",
            "        [-8.8526e-02, -7.4768e-01, -1.4916e-01, -1.7078e-01,  5.3972e-01,\n",
            "          9.1296e-02,  2.5853e-01, -1.6208e-01,  6.9485e-02,  2.1040e-01,\n",
            "         -3.9800e-01,  1.5486e-01,  3.4060e-01, -2.0696e-01, -3.4143e-01,\n",
            "          9.7657e-02,  2.7860e-01, -3.2048e-01,  9.9911e-02],\n",
            "        [-6.7290e-01, -9.2635e-02,  5.5874e-01, -1.1019e-01,  1.0822e+00,\n",
            "          4.4552e-02, -1.0297e-01, -1.9691e-01,  5.4546e-01,  2.9810e-01,\n",
            "         -3.8031e-01,  4.5405e-01, -1.1779e-01, -3.3713e-01,  8.4358e-02,\n",
            "          6.4076e-01,  3.8432e-01, -1.1494e-01,  3.0191e-01],\n",
            "        [-2.0647e-01, -6.1222e-02,  2.6543e-01,  1.5234e-01,  8.3076e-01,\n",
            "          4.5382e-02,  1.5154e-01, -2.8509e-01,  4.8979e-01,  3.5763e-01,\n",
            "          1.2616e-02,  4.9865e-01, -4.2930e-01, -4.6926e-01,  1.4246e-01,\n",
            "         -3.9919e-02, -2.2738e-01, -4.9759e-01, -3.0954e-01],\n",
            "        [-5.3241e-01, -3.4106e-01,  4.9224e-01,  1.2866e-01,  4.9179e-01,\n",
            "         -1.0518e-01,  1.0525e-01,  1.8358e-01,  3.6419e-01, -1.4320e-01,\n",
            "         -4.0316e-01,  6.3826e-01, -4.6432e-01, -5.0081e-01,  3.6750e-01,\n",
            "         -1.3637e-01,  3.8808e-02,  4.1632e-01, -2.1925e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.1327,  0.1885, -0.2968, -0.5933,  0.0908,  0.1982, -0.0280, -0.2013,\n",
            "          0.6539,  0.1266, -0.2730,  0.3165, -0.0429, -0.0128,  0.1546,  0.2987,\n",
            "          0.2646, -0.3225, -0.5055],\n",
            "        [-0.5701, -0.5640,  0.3236,  0.2621,  1.1665, -0.2711, -0.3324, -0.0084,\n",
            "          0.4536,  0.3848, -0.2309,  0.5263,  0.2741,  0.3947,  0.2095, -0.0293,\n",
            "          0.6649, -0.0594,  0.3626],\n",
            "        [-0.1394, -0.2087,  0.1701, -0.3186,  1.2619,  0.1106,  0.5354,  0.1712,\n",
            "          0.2436,  0.1194, -0.0215,  0.1410, -0.1734, -0.1401,  0.2248, -0.0735,\n",
            "          0.5809,  0.2842, -0.0403],\n",
            "        [-0.3227, -0.2211,  0.0464,  0.1268,  0.7586, -0.1625, -0.1070,  0.0362,\n",
            "          0.6671,  0.4730, -0.1794,  0.4642, -0.0078, -0.3525, -0.0278,  0.5579,\n",
            "          0.5982, -0.0536, -0.3657],\n",
            "        [-0.1202, -0.2249,  0.1582,  0.2874,  0.6060,  0.0640,  0.0345, -0.1265,\n",
            "          0.6420,  0.0356, -0.2307, -0.1004, -0.1001, -0.2637, -0.1270,  0.0119,\n",
            "          0.2074, -0.1285,  0.0614],\n",
            "        [ 0.3308,  0.1003, -0.3104, -0.0932,  0.0839, -0.2785,  0.0060, -0.1288,\n",
            "          0.2132,  0.1835, -0.4045,  0.4536, -0.1938, -0.4649,  0.1402,  0.2722,\n",
            "          0.5353, -0.0224,  0.1583],\n",
            "        [-0.3233, -0.5915, -0.1260, -0.3062,  1.0176,  0.1281, -0.2898, -0.0244,\n",
            "          0.3287,  0.4576, -0.3742,  0.6254, -0.0884, -0.1837, -0.0059,  0.1691,\n",
            "          0.0715, -0.0296, -0.4820],\n",
            "        [-0.3245, -0.2037,  0.2198, -0.0286,  0.1396, -0.0050, -0.1044,  0.4526,\n",
            "          0.3892,  0.1473, -0.2837,  0.4800, -0.3519, -0.1504,  0.5129,  0.6584,\n",
            "          0.7008, -0.3559,  0.1527],\n",
            "        [-0.1061, -0.6638, -0.0031,  0.0227,  0.2209,  0.0265, -0.4282, -0.1755,\n",
            "          0.3513,  0.1952, -0.1045,  0.4750, -0.2954, -0.1471,  0.0187,  0.2272,\n",
            "          0.0899, -0.3176, -0.0473],\n",
            "        [-0.7236, -0.2859,  0.0308,  0.3057,  1.0524, -0.7069, -0.1993, -0.0927,\n",
            "         -0.0417, -0.3328,  0.0502,  0.6994, -0.2819, -0.5319, -0.1447,  0.8758,\n",
            "          0.4258, -0.0576, -0.3924],\n",
            "        [-0.4817,  0.0584,  0.5467, -0.3564,  0.1910, -0.3065,  0.1974,  0.1642,\n",
            "          0.5617,  0.2743, -0.5050,  0.6731, -0.1559, -0.2738,  0.0387,  0.1714,\n",
            "          0.4822, -0.3024, -0.2698],\n",
            "        [-0.4550, -0.8425,  0.0304,  0.2063,  0.5179, -0.2427, -0.5336, -0.1559,\n",
            "          0.2417,  0.0248, -0.5380,  0.7282, -0.2083, -0.0043,  0.1816,  0.4076,\n",
            "          0.3078,  0.2810, -0.4577],\n",
            "        [-0.1081,  0.3771, -0.1656, -0.3994,  0.7670,  0.0567, -0.1807, -0.0406,\n",
            "          0.2704,  0.1623,  0.0488,  0.6112, -0.7270,  0.5314, -0.0231,  0.1244,\n",
            "          0.4524, -0.1375, -0.4733],\n",
            "        [ 0.0635, -0.6003,  0.0802,  0.7149,  0.9289, -0.1872, -0.0210, -0.2257,\n",
            "          0.5286,  0.4102, -0.1635,  0.4567, -0.0857, -0.3437,  0.5300,  0.1336,\n",
            "          0.0815,  0.1669,  0.2365],\n",
            "        [-0.4149, -0.2045,  0.1588, -0.2933,  0.8702, -0.0757, -0.1920, -0.1305,\n",
            "          0.9317,  0.2386, -0.1708,  0.1298, -0.4628,  0.1537, -0.2340,  0.1729,\n",
            "          0.1808,  0.0908, -0.5164],\n",
            "        [-0.1987,  0.1121, -0.0523, -0.0129,  1.1020,  0.0977, -0.0509, -0.0438,\n",
            "          0.3821,  0.3688, -0.6671,  0.2417, -0.3887, -0.8158,  0.7066,  0.7154,\n",
            "          0.3367, -0.3869, -0.2687],\n",
            "        [-0.2138, -0.3977,  0.3257, -0.2292,  0.2101,  0.2430,  0.1032, -0.5538,\n",
            "          0.7509, -0.0249, -0.0078,  0.3027, -0.7169, -0.1839,  0.1660,  0.6480,\n",
            "          0.3150, -0.3496, -0.3935],\n",
            "        [-0.4873, -0.0321, -0.3327, -0.0124,  0.9714, -0.5843,  0.1246, -0.1114,\n",
            "          0.3113, -0.4082,  0.0679,  0.1306, -0.3631, -0.0287,  0.0961,  0.4733,\n",
            "          0.4342, -0.2998, -0.0565],\n",
            "        [-0.3740, -0.2579,  0.0735,  0.0094,  0.9240,  0.0712, -0.3630, -0.1238,\n",
            "          0.3904, -0.1124, -0.1962,  0.7741, -0.2046, -0.3467,  0.0387,  0.2471,\n",
            "          0.4986,  0.1701,  0.3251],\n",
            "        [-0.4564, -0.4819,  0.2914,  0.2673,  0.8414, -0.2153, -0.0235, -0.4967,\n",
            "          0.3066,  0.0909, -0.4299,  0.4798, -0.2481, -0.3558,  0.0253,  0.4156,\n",
            "          0.6000, -0.0284, -0.4132],\n",
            "        [-1.0367, -0.3387, -0.0862,  0.0304,  0.5177,  0.0116,  0.2084, -0.1388,\n",
            "          1.2974,  0.2203, -0.0704,  0.6269, -0.1826, -0.3543,  0.3975,  0.0600,\n",
            "         -0.1659, -0.0798,  0.1421],\n",
            "        [-0.1356, -0.3078, -0.0259,  0.4704,  0.4613,  0.1768,  0.2340, -0.0723,\n",
            "          0.9859, -0.1567, -0.1865,  0.2111,  0.7373, -0.2080,  0.1188,  0.2782,\n",
            "          0.5074,  0.2605, -0.3350],\n",
            "        [ 0.0399,  0.0049, -0.2609,  0.0922,  0.7215, -0.0907,  0.2752,  0.2551,\n",
            "         -0.0347, -0.1117, -0.4761,  0.5143, -0.2554, -0.0880,  0.2024,  0.0589,\n",
            "          0.2012,  0.0118, -0.2460],\n",
            "        [-0.7920, -0.2758,  0.2549, -0.2360,  0.8511,  0.0720, -0.1394, -0.1605,\n",
            "          0.7619, -0.1269,  0.2001,  0.6926, -0.3942, -0.0077,  0.2417,  0.2230,\n",
            "          0.5673,  0.0592, -0.2411],\n",
            "        [ 0.1277,  0.0155,  0.4089, -0.2944,  0.9264,  0.1503,  0.1315,  0.1169,\n",
            "          0.2950,  0.1213, -0.1411,  0.4267, -0.3519,  0.5371, -0.0899,  0.5576,\n",
            "          0.2518,  0.2715, -0.3189],\n",
            "        [-0.5830, -0.8135,  0.0395,  0.2082,  0.7444,  0.0669,  0.4613, -0.0660,\n",
            "          0.1872, -0.2548,  0.0496,  0.2567,  0.2247, -0.4431,  0.5914,  0.1188,\n",
            "          0.2963, -0.2536,  0.3120],\n",
            "        [-0.0512, -0.2360,  0.2270,  0.2431,  0.8345, -0.4671,  0.0303, -0.1005,\n",
            "          0.4074,  0.4691,  0.4104,  0.8872,  0.1374, -0.2557,  0.1583,  0.3050,\n",
            "          0.4266, -0.4331,  0.1540],\n",
            "        [-0.5102, -0.2661,  0.5136, -0.0740,  0.9486,  0.1025,  0.0742, -0.3964,\n",
            "          0.3272,  0.1207,  0.2256,  0.3088,  0.0461, -0.0179,  0.0876,  0.2391,\n",
            "          0.0180, -0.4440, -0.4195],\n",
            "        [-0.6000, -0.4396, -0.1441,  0.0065,  0.8182, -0.4923, -0.6752, -0.2212,\n",
            "          0.5065,  0.4069, -0.1258,  0.5708, -0.2983, -0.2570, -0.1624,  0.2823,\n",
            "          0.2336, -0.5629, -0.1416],\n",
            "        [-0.2112, -0.7451, -0.1712, -0.0047,  0.4243, -0.2428, -0.1106, -0.3744,\n",
            "         -0.1324,  0.0584, -0.2697,  0.5000, -0.2725, -0.5249,  0.6541,  0.5877,\n",
            "          0.4879, -0.3426, -0.6533],\n",
            "        [-0.5793, -0.0041,  0.1347, -0.1932,  0.5636,  0.1078,  0.0900,  0.1098,\n",
            "          0.2158,  0.0376,  0.2330,  0.3273, -0.2331, -0.4030,  0.0437,  0.1421,\n",
            "          0.1346,  0.2992, -0.1229],\n",
            "        [-0.4732, -0.4208,  0.0339,  0.0663,  0.7766, -0.0397, -0.7268, -0.9873,\n",
            "          0.8713, -0.0440, -0.2385,  0.9053,  0.0259, -0.3702, -0.0572,  0.8944,\n",
            "          0.2526, -0.1406, -0.7980]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-7.5111e-01,  1.8508e-01, -1.6957e-01,  1.0732e-01,  2.0325e+00,\n",
            "         -4.8819e-01,  3.6756e-02, -5.3914e-01, -2.1348e-02, -3.6586e-01,\n",
            "         -8.2422e-02,  1.0081e+00, -4.4722e-02, -8.0492e-01,  5.2272e-01,\n",
            "          6.5820e-01, -2.1863e-01,  4.4467e-01, -3.1603e-01],\n",
            "        [-3.7757e-01, -2.5550e-01,  2.4774e-01, -3.3833e-02,  1.2219e+00,\n",
            "         -2.5037e-01, -4.0753e-01, -7.4548e-02,  5.0585e-02, -1.6110e-01,\n",
            "         -7.9085e-01,  3.7964e-01, -3.3893e-01, -3.2892e-01,  4.3873e-01,\n",
            "          6.7722e-02,  3.3593e-01, -6.0812e-02, -3.1468e-01],\n",
            "        [-1.9096e-01, -5.2028e-02,  5.2763e-01,  8.4802e-03,  1.0520e+00,\n",
            "          2.6798e-01, -2.4911e-01,  1.4376e-01, -5.5954e-02, -1.1877e-01,\n",
            "          4.8829e-02,  5.7597e-01,  2.2344e-02, -1.6362e-01,  3.1401e-01,\n",
            "          4.8132e-02,  1.8329e-01, -3.1800e-01, -4.9785e-01],\n",
            "        [-3.7271e-01, -3.4359e-01, -1.5038e-01, -4.5552e-01,  9.8118e-01,\n",
            "          1.8179e-01,  7.2026e-02, -2.5513e-01,  7.9406e-02,  2.8960e-01,\n",
            "         -3.1972e-01,  2.4844e-01, -3.4662e-01,  1.9837e-01,  2.6670e-01,\n",
            "          5.2482e-02, -3.8438e-02, -1.1293e-01, -4.8747e-01],\n",
            "        [-9.8901e-02, -1.3473e-01,  2.9745e-02, -1.0241e-01,  8.3001e-01,\n",
            "          4.6439e-02,  1.6666e-01,  8.6876e-02,  3.6515e-01,  1.8027e-01,\n",
            "         -2.3157e-02,  4.0024e-01, -1.3151e-01, -9.5258e-02,  2.3833e-01,\n",
            "         -1.0402e-01,  3.9983e-01,  1.8064e-02, -1.4845e-01],\n",
            "        [-3.0210e-01, -2.7588e-01, -1.8983e-01, -1.7984e-01,  1.0558e+00,\n",
            "         -1.5143e-01,  9.7005e-01, -1.8993e-01,  4.2611e-01,  5.3130e-01,\n",
            "         -1.6926e-01,  7.1656e-01, -7.9770e-01, -7.7573e-01,  1.9581e-01,\n",
            "          5.1224e-01,  1.7328e-01,  1.0553e-01, -9.9888e-02],\n",
            "        [-6.3613e-01, -2.2482e-01,  2.3980e-01,  1.4236e-01,  5.1375e-01,\n",
            "         -5.2033e-01, -1.0523e-02, -5.9293e-01,  5.9560e-01, -7.1245e-02,\n",
            "          2.4076e-01,  2.2347e-01, -5.9008e-01, -4.7876e-01,  2.9878e-01,\n",
            "          1.3938e-01,  4.3055e-01,  1.0422e-01, -2.7008e-01],\n",
            "        [-1.7077e-01, -2.2379e-01,  1.2415e-02,  1.7285e-01,  1.0637e+00,\n",
            "          2.7201e-02, -1.2671e-01,  5.6116e-01,  2.2170e-01, -3.3781e-01,\n",
            "         -3.6022e-01,  3.7694e-01,  2.4552e-01, -3.3949e-01, -2.6773e-01,\n",
            "          5.7151e-01,  6.8609e-01,  5.1443e-02, -1.6818e-01],\n",
            "        [-1.8446e-01, -2.2800e-01,  1.1656e-01, -3.7227e-01,  5.4038e-01,\n",
            "         -9.7897e-02,  3.2510e-02,  2.1712e-01,  5.7670e-02,  2.9257e-01,\n",
            "         -2.5751e-01,  8.1988e-01, -2.6465e-01, -3.4129e-01,  2.1131e-01,\n",
            "         -3.9510e-02,  1.7701e-01,  1.9178e-01, -8.8610e-03],\n",
            "        [-1.1253e-01, -1.9998e-01, -3.5024e-01,  7.4862e-02,  7.1204e-01,\n",
            "         -4.1268e-01, -4.0250e-01, -3.1762e-01,  1.8871e-01,  2.8361e-01,\n",
            "         -4.4965e-01,  5.1781e-01, -2.3733e-01, -3.4014e-01,  2.6973e-01,\n",
            "          4.6079e-01,  3.1328e-01, -1.5825e-01, -4.7861e-01],\n",
            "        [-1.8200e-01, -5.4324e-01,  7.0728e-02, -2.3754e-01,  1.1579e+00,\n",
            "          1.9338e-01,  1.6762e-01,  2.1452e-03,  7.7424e-01,  2.0527e-01,\n",
            "         -3.0966e-01,  4.2762e-01, -1.0789e-01, -2.4629e-01,  2.7525e-01,\n",
            "         -1.2326e-01,  1.6936e-01,  1.4957e-01, -3.3995e-01],\n",
            "        [-4.2436e-01,  1.0551e-01, -1.8817e-01,  1.1322e-01,  9.2093e-01,\n",
            "          5.5273e-02,  5.3430e-03,  2.6225e-01,  6.2048e-01, -8.1492e-02,\n",
            "         -3.1313e-01,  7.8191e-01, -1.0502e-01, -6.2399e-01, -2.6662e-01,\n",
            "          9.0822e-02,  7.3351e-01,  3.5439e-02, -1.4225e-01],\n",
            "        [-8.0103e-01, -6.3905e-01,  6.4328e-01,  4.5442e-03,  1.0996e+00,\n",
            "         -2.4061e-01, -2.2659e-01, -4.6677e-01,  6.7925e-01,  6.5265e-02,\n",
            "          1.8965e-01,  5.4118e-01, -1.3427e-01, -5.6294e-01,  1.2124e-01,\n",
            "          2.3166e-01,  5.3808e-01,  5.1641e-02, -4.2135e-01],\n",
            "        [-1.4113e-01,  8.4464e-02,  4.9651e-01, -1.0014e-01,  7.9236e-01,\n",
            "         -1.4578e-01, -8.9398e-02, -1.2808e-01,  2.2417e-01,  9.9989e-02,\n",
            "         -1.8793e-01,  5.7143e-01, -4.0717e-01, -2.3664e-01,  1.5091e-01,\n",
            "          5.6567e-02, -1.8686e-01, -2.9860e-01, -3.7947e-01],\n",
            "        [-9.2122e-02,  1.2516e-01,  6.8090e-01,  3.7876e-01,  8.2357e-01,\n",
            "          1.8334e-01,  5.8427e-01,  2.3320e-02,  7.0417e-01, -1.0191e-01,\n",
            "         -2.5956e-01,  6.0426e-02,  2.8871e-01,  2.9801e-03,  1.1504e-01,\n",
            "          5.7170e-01,  5.1396e-01, -2.4080e-01, -3.0154e-01],\n",
            "        [-2.8060e-02, -4.5916e-01,  4.9121e-01,  2.7311e-02,  1.0573e+00,\n",
            "         -1.6761e-01,  1.7236e-01, -2.4350e-01,  2.9059e-01,  1.9576e-01,\n",
            "         -3.3557e-01,  6.9590e-01,  6.4608e-02, -2.4748e-01,  5.2751e-02,\n",
            "          5.0255e-01,  4.5882e-01, -1.6732e-01, -6.5274e-01],\n",
            "        [-7.4447e-01,  7.2875e-02,  3.9555e-01,  1.1546e-01,  6.5216e-01,\n",
            "         -6.9531e-02,  2.7840e-01, -3.1024e-01,  3.5442e-01, -5.1522e-01,\n",
            "         -1.9548e-01,  3.9128e-02, -3.7359e-01, -4.8380e-01,  1.9609e-01,\n",
            "          3.5165e-01,  7.5893e-02,  1.3231e-01, -1.2134e-02],\n",
            "        [-2.5063e-01, -3.2646e-01,  2.2888e-01,  1.4016e-01,  3.2696e-01,\n",
            "         -3.6541e-02, -2.0938e-01,  3.4806e-02,  1.3808e-01, -1.8858e-01,\n",
            "          9.0050e-02,  3.1403e-01, -3.7840e-02, -1.0617e-01,  1.3573e-01,\n",
            "          3.4416e-01,  4.4393e-01,  2.9870e-01, -7.3571e-02],\n",
            "        [-5.6914e-01, -6.9680e-01,  1.3259e-01,  1.8984e-01,  1.4795e+00,\n",
            "         -3.7091e-01, -3.5494e-01, -1.8350e-01,  4.7606e-01, -1.7027e-01,\n",
            "          1.1993e-01,  8.4644e-01,  9.9206e-02, -4.6869e-01, -6.5189e-02,\n",
            "          2.0045e-01,  4.4054e-01, -4.8991e-01, -8.6316e-02],\n",
            "        [-2.9968e-02, -2.2098e-01, -1.4290e-01,  3.7917e-02,  7.3240e-01,\n",
            "          2.7460e-02, -1.9160e-02,  3.7639e-01,  2.3979e-01, -3.5114e-02,\n",
            "         -7.4073e-02,  6.7364e-01, -5.7837e-03, -3.0236e-01,  4.2206e-01,\n",
            "          6.2220e-01,  4.5932e-01, -3.7335e-01, -1.9475e-01],\n",
            "        [-2.8755e-01, -9.0965e-02,  1.2162e-01, -5.0083e-02,  1.1292e+00,\n",
            "          8.7785e-02,  3.5069e-01, -1.2158e-01,  4.9695e-01,  1.4385e-01,\n",
            "          3.6741e-01,  3.6620e-01, -4.2522e-01, -4.0109e-01,  4.3483e-01,\n",
            "          4.3680e-01,  7.4305e-01,  7.9540e-02, -1.0013e-01],\n",
            "        [-2.0306e-01,  2.4643e-01,  1.6062e-01,  2.9026e-01,  5.2274e-01,\n",
            "         -2.5938e-01,  2.7732e-01,  2.2644e-02,  2.1290e-01, -7.2326e-02,\n",
            "          8.6066e-02,  8.9360e-01, -5.5607e-02, -4.8319e-02,  3.4036e-02,\n",
            "          2.5071e-01, -1.2461e-01,  9.5885e-02, -5.6330e-01],\n",
            "        [-7.2782e-01, -5.1384e-01,  1.0527e-02,  2.7186e-01,  9.5263e-01,\n",
            "         -2.9486e-01,  1.8069e-01, -3.8878e-01,  9.6483e-01, -1.3682e-01,\n",
            "         -1.7769e-01,  4.9650e-01, -4.9999e-02, -5.7645e-02,  4.7282e-01,\n",
            "          1.2785e-01,  3.6160e-01, -4.7300e-02, -1.7606e-01],\n",
            "        [-2.2118e-01, -3.3101e-01,  2.7426e-01,  8.8321e-03,  8.7177e-01,\n",
            "          1.7178e-01, -3.8411e-01, -1.6660e-01,  3.8977e-01, -1.3888e-02,\n",
            "         -6.4569e-01,  3.1570e-01, -8.5310e-01, -6.4743e-01, -7.1808e-02,\n",
            "          1.2160e-01, -2.0373e-01, -2.3820e-01, -1.8546e-01],\n",
            "        [ 6.3172e-02,  7.1856e-02,  7.1618e-02,  4.4546e-01,  6.1222e-01,\n",
            "         -2.8810e-01,  1.6228e-01, -1.1221e-01,  1.1507e-01, -2.2415e-01,\n",
            "         -2.3785e-01,  7.9388e-01, -5.1412e-01, -4.0719e-01, -1.1947e-01,\n",
            "          3.0036e-01,  3.0130e-01, -3.7284e-01, -3.9690e-01],\n",
            "        [-1.6688e-01, -4.5740e-01,  1.4650e-01, -2.0251e-01,  8.3683e-01,\n",
            "          4.6497e-01, -2.2923e-01,  2.4344e-01,  5.2979e-01, -3.1999e-01,\n",
            "         -3.1476e-01,  6.1144e-01, -1.6055e-01, -2.9751e-01,  3.5296e-01,\n",
            "         -3.5084e-01,  5.5390e-01, -1.5868e-01, -2.2031e-01],\n",
            "        [-5.6946e-01, -2.9589e-01,  2.0273e-02,  7.2591e-02,  7.6105e-01,\n",
            "         -3.2078e-01, -1.9254e-01, -1.6004e-01,  5.6461e-01,  6.4125e-01,\n",
            "         -2.3253e-01,  1.9417e-01, -1.1650e-01, -1.3784e-01, -2.1530e-01,\n",
            "          4.0873e-01,  1.8573e-01,  8.2532e-02,  1.1507e-01],\n",
            "        [-7.9729e-01, -5.7232e-01, -5.4196e-04,  1.5809e-01,  7.0372e-01,\n",
            "         -3.7428e-01,  5.5532e-01, -3.5896e-01,  5.1511e-01,  7.3161e-01,\n",
            "          1.2605e-01,  8.9172e-01, -6.6137e-01, -3.3054e-01, -3.1328e-02,\n",
            "          6.0362e-01,  6.4511e-01, -4.6205e-02, -1.0854e-01],\n",
            "        [-2.7976e-01, -3.7605e-01,  1.9927e-02,  4.3727e-01,  9.1191e-01,\n",
            "         -2.0848e-02,  3.6588e-01, -4.9399e-01,  8.7565e-01,  6.8982e-01,\n",
            "         -9.5782e-01,  7.4167e-01,  2.4845e-02,  2.9615e-01,  1.1646e-01,\n",
            "          1.5637e-01,  4.1161e-01, -4.0728e-01, -1.4832e-01],\n",
            "        [-6.7540e-01, -5.0361e-01,  2.7846e-01, -1.9824e-01,  9.1292e-01,\n",
            "         -6.2845e-01, -1.0021e-01, -2.6150e-01,  3.9671e-01,  2.1925e-01,\n",
            "          5.3417e-01,  8.1975e-01, -1.8777e-01, -2.6484e-01,  6.1873e-02,\n",
            "          4.5794e-01, -2.9837e-01, -3.0252e-01, -2.1082e-02],\n",
            "        [-4.1660e-01, -3.2104e-01,  2.6397e-01,  5.2924e-01,  7.2391e-01,\n",
            "          2.1780e-02, -1.2567e-01,  2.4468e-01,  5.2286e-01,  2.0444e-01,\n",
            "          1.2548e-01,  4.2413e-01,  5.0300e-02, -2.4879e-01, -1.0061e-01,\n",
            "         -1.0576e-01,  2.7878e-01,  1.3740e-01, -3.5259e-01],\n",
            "        [-6.0684e-01, -6.1379e-01,  2.2697e-01,  1.1008e-01,  8.6482e-01,\n",
            "          3.3383e-01, -8.2019e-02, -5.5370e-01,  3.6741e-01, -2.6814e-01,\n",
            "         -8.4004e-01,  2.7458e-01,  2.2790e-01, -3.3775e-01,  5.7067e-01,\n",
            "          7.7414e-01,  3.6472e-01, -9.9066e-02, -3.0211e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3082, -0.2185, -0.3712,  0.1471,  1.0963, -0.0864, -0.1177,  0.0058,\n",
            "          0.7034, -0.2114, -0.2570,  0.4597, -0.2170, -0.1358, -0.0484,  0.7995,\n",
            "         -0.0218,  0.2427, -0.1670],\n",
            "        [-0.4895, -0.6697, -0.2909, -0.1098,  1.9165, -0.1264,  0.0033, -0.0896,\n",
            "          0.3975, -0.1475, -0.2729,  0.9179, -0.0385, -0.5526,  0.0357,  0.3754,\n",
            "          0.1864, -0.1888,  0.0918],\n",
            "        [-0.4280, -0.4131, -0.0835,  0.0853,  1.1008,  0.1352, -0.2230, -0.6179,\n",
            "          0.8886, -0.0371, -0.1120,  0.6447, -0.6235, -0.4071, -0.0191,  0.6522,\n",
            "          0.4940, -0.3970, -0.4663],\n",
            "        [-0.0789, -0.2323, -0.5107,  0.2067,  0.6346,  0.1502, -0.0860,  0.1111,\n",
            "         -0.0147,  0.0865, -0.1458,  0.8137, -0.7183, -0.7181,  0.1512,  0.5993,\n",
            "          0.3022, -0.2827, -0.0530],\n",
            "        [-0.8246,  0.2144,  0.2038, -0.0925,  1.3207,  0.3525,  0.1104, -0.1468,\n",
            "          0.2828,  0.2088, -0.1598,  0.7930, -0.0815, -0.6416,  0.3694,  0.2058,\n",
            "          0.8060, -0.2694, -0.7182],\n",
            "        [-0.5941, -0.4365,  0.1464,  0.4786,  1.1316,  0.0093,  0.1691, -0.7257,\n",
            "          0.3494, -0.1827, -0.2781,  0.7949, -0.1981, -0.3173, -0.1192,  0.4917,\n",
            "          0.4932, -0.0717, -0.5266],\n",
            "        [-0.4648, -0.4460,  0.1098,  0.0147,  1.2080, -0.4642, -0.0803, -0.3798,\n",
            "          0.6424, -0.0485, -0.4304,  0.7129, -0.2116, -0.5050, -0.1528,  0.0450,\n",
            "          0.2283,  0.3356, -0.2504],\n",
            "        [-0.5509,  0.1561,  0.7256,  0.3443,  1.1775, -0.1263,  0.2685,  0.2415,\n",
            "          0.7229,  0.1766, -0.2212,  0.3644, -0.2785, -0.2737, -0.0706, -0.1832,\n",
            "          0.7751, -0.2783, -0.7445],\n",
            "        [-0.7454, -0.1546,  0.1764, -0.2561,  0.8936,  0.1134,  0.3744, -0.3926,\n",
            "          0.3851, -0.5166, -0.3712,  0.3578,  0.0967, -0.8192,  0.4847, -0.0180,\n",
            "          0.4033, -0.2860,  0.0589],\n",
            "        [-0.0557,  0.2713, -0.3067,  0.2051,  0.4808,  0.0839,  0.2126,  0.2075,\n",
            "          0.6448,  0.3776, -0.5573,  0.1788, -0.3592, -0.1142,  0.0283,  0.3132,\n",
            "          0.4170, -0.0848, -0.5416],\n",
            "        [-0.9981,  0.0686,  0.1745,  0.3663,  0.5246,  0.2673, -0.3851, -0.2707,\n",
            "          0.3305, -0.2453, -0.6120,  0.2506, -0.4196, -0.4367,  0.0484,  0.4887,\n",
            "         -0.0506, -0.2376, -0.5760],\n",
            "        [-0.3490, -0.1299, -0.0491,  0.1175,  1.0317, -0.4631,  0.2080, -0.5415,\n",
            "          1.2081,  0.0806, -0.3658,  0.4151, -0.6104, -0.6714,  0.3625,  0.0993,\n",
            "          0.6523,  0.0726, -0.2928],\n",
            "        [-0.4275, -0.4076,  0.2237, -0.1411,  0.4947, -0.1403,  0.1293, -0.3043,\n",
            "          0.5033, -0.0830, -0.3122,  0.8741, -0.5576, -0.5730, -0.1446,  0.0434,\n",
            "          0.3538, -0.0958, -0.4890],\n",
            "        [-0.5544, -0.6459,  0.2451,  0.2092,  1.2700, -0.2795,  0.5092, -0.2322,\n",
            "          0.6178, -0.6459, -0.5060,  0.7632, -0.3576, -0.2738, -0.1521,  0.3919,\n",
            "          0.2918, -0.1194, -0.1913],\n",
            "        [-0.3600,  0.0917,  0.0057,  0.3475,  0.7809, -0.7925, -0.2065, -0.0909,\n",
            "          0.2601, -0.1521, -0.4910,  0.2535, -0.6633,  0.0205,  0.1243,  0.4999,\n",
            "          0.2219,  0.0121, -0.1854],\n",
            "        [-0.2094, -0.3473,  0.1813, -0.4146,  1.0108, -0.1883, -0.0226, -0.1361,\n",
            "          0.3527, -0.1691,  0.0593,  0.5280,  0.3393, -0.1315,  0.5722,  0.2533,\n",
            "         -0.1036, -0.1771, -0.3469],\n",
            "        [-0.6360, -0.6070, -0.2685, -0.0354,  1.2936,  0.0771, -0.3060, -0.1786,\n",
            "          0.2351, -0.4619, -0.5455,  0.6111, -0.2261, -0.5141,  0.2693,  0.3721,\n",
            "          0.3345,  0.5558, -1.0637],\n",
            "        [-0.5625, -0.2598,  0.2139, -0.0119,  0.9948, -0.2972,  0.1996, -0.4593,\n",
            "          0.3517, -0.2676, -0.2359,  0.6898, -0.2547, -0.6333,  0.3439,  0.7547,\n",
            "          0.0796, -0.4687, -0.4487],\n",
            "        [-0.6766, -0.1167, -0.2847, -0.1517,  0.8494,  0.3646, -0.3724, -0.2587,\n",
            "          0.2681, -0.2747, -0.2621,  0.6110, -0.0845, -0.3493,  0.3680,  0.5021,\n",
            "          0.7135,  0.2385, -0.4326],\n",
            "        [-0.6307, -0.3470,  0.3060, -0.4818,  0.8300,  0.0360, -0.2118, -0.2752,\n",
            "          0.3400,  0.3416,  0.0262,  1.1438, -0.2056, -0.0811,  0.0034,  0.3956,\n",
            "          0.4013,  0.1417, -0.3579],\n",
            "        [-0.4736, -0.4150,  0.1311,  0.2482,  0.8893, -0.3595, -0.2209, -0.0205,\n",
            "          0.6465,  0.0978, -0.1274,  0.6681, -0.2067, -0.4853,  0.2254,  0.6106,\n",
            "          0.3218, -0.5360,  0.0506],\n",
            "        [-0.3416, -0.0867,  0.2292,  0.1056,  0.6228, -0.0364, -0.0881, -0.0187,\n",
            "          0.4299, -0.1462, -0.0658,  0.5524, -0.0647, -0.3407, -0.1930, -0.1327,\n",
            "          0.0531, -0.2448, -0.0041],\n",
            "        [-0.5503,  0.3130,  0.0747,  0.3174,  0.6975, -0.1504,  0.0316, -0.2328,\n",
            "          0.2637,  0.1156,  0.0716,  0.9378,  0.0689, -0.2538,  0.2200,  0.4931,\n",
            "          0.3856, -0.1076, -0.6679],\n",
            "        [-0.5313, -0.4937, -0.3118,  0.1238,  0.9057, -0.2316,  0.1736, -0.3130,\n",
            "          0.7074, -0.1708,  0.3638,  0.8171, -0.1456, -0.5132, -0.0181,  0.3926,\n",
            "          0.8707,  0.2217,  0.5713],\n",
            "        [-0.2387, -0.0616,  0.1402, -0.3823,  0.6592,  0.1053,  0.0978,  0.1779,\n",
            "          0.3399, -0.2394, -0.3551,  0.6589, -0.0900, -0.8433,  0.0449,  0.0185,\n",
            "          0.5805, -0.0454, -0.3837],\n",
            "        [-0.3878, -0.0634,  0.1351,  0.3407,  1.0002, -0.3291,  0.1518,  0.0457,\n",
            "          0.2587,  0.3722,  0.1827,  0.4800, -0.4573, -0.2446,  0.3631,  0.3162,\n",
            "          0.1620,  0.3225, -0.8173],\n",
            "        [ 0.0648,  0.3618, -0.2624,  0.1353,  0.8642, -0.0824, -0.3403, -0.3998,\n",
            "          0.3581, -0.2060, -0.0700,  0.9884, -0.0510, -0.3214, -0.0074,  0.0528,\n",
            "          0.1907, -0.0290, -0.2796],\n",
            "        [-0.5460,  0.0964,  0.0226,  0.3132,  0.8782, -0.1298, -0.5192, -0.4485,\n",
            "          0.5965, -0.3647, -0.3369,  0.8090, -0.5794, -0.3059,  0.5138, -0.1865,\n",
            "          0.5305, -0.4968, -0.5655],\n",
            "        [-0.4248,  0.0556,  0.4954,  0.3196,  0.0808,  0.1954, -0.0145,  0.2565,\n",
            "          0.1640,  0.2313,  0.0728,  0.3892,  0.2856, -0.1508, -0.1748,  0.5629,\n",
            "          0.0803, -0.1396, -0.0061],\n",
            "        [-0.3614, -0.2591, -0.0792,  0.2404,  1.0852, -0.7118, -0.4571, -0.2429,\n",
            "          0.6019, -0.2233,  0.4287,  1.0417, -0.5804, -0.0050,  0.9442,  0.5693,\n",
            "          0.4425, -0.2457, -0.5716],\n",
            "        [-0.3284, -0.7952,  0.3875,  0.3234,  1.2313, -0.0987, -0.3595, -0.2129,\n",
            "          0.8551, -0.4021, -0.3923,  0.5885, -0.6933, -1.0047, -0.1590,  0.7986,\n",
            "          0.1105, -0.1581, -0.2792],\n",
            "        [-0.4664, -0.4914,  0.0675, -0.2533,  0.7784, -0.2507,  0.4404, -0.9754,\n",
            "          0.3490,  0.1360, -0.0604,  0.2286, -0.4237, -0.2668, -0.1150,  0.1927,\n",
            "          0.6805, -0.1550, -0.2938]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-6.4885e-01,  4.0088e-02, -2.6842e-01,  5.3949e-01,  1.3841e+00,\n",
            "         -2.6057e-01,  1.3053e-01, -2.0042e-02,  3.7077e-01, -8.6273e-01,\n",
            "         -1.1598e-01,  7.3508e-01, -2.1152e-01, -4.4049e-01,  1.7495e-01,\n",
            "          2.2355e-01,  5.2815e-01,  3.8549e-01, -2.9881e-01],\n",
            "        [-2.2756e-01,  1.1357e-01,  2.5780e-02,  3.0879e-01,  1.5982e+00,\n",
            "          3.6044e-02,  8.0574e-02, -1.1316e+00,  2.5816e-01, -1.5750e-01,\n",
            "         -3.0475e-02,  9.8821e-01, -2.7372e-01,  8.8431e-02, -5.3563e-02,\n",
            "          1.8071e-01,  3.7917e-01,  7.7470e-02, -3.2855e-01],\n",
            "        [-1.8267e-01, -4.7413e-03,  1.3450e-01,  3.7145e-01,  8.7934e-01,\n",
            "         -3.6851e-02, -5.8440e-01,  1.0795e-01,  3.7103e-02,  1.2986e-02,\n",
            "         -1.1050e-01,  2.7658e-01, -3.3518e-01, -3.5369e-01,  2.6320e-01,\n",
            "          7.0307e-02,  6.4627e-01, -1.9930e-01, -1.4772e-01],\n",
            "        [-1.7786e-01, -6.1384e-01, -9.1253e-02,  1.8292e-01,  1.4810e+00,\n",
            "          2.6839e-01,  1.1665e-01, -6.0615e-01,  1.0005e+00,  2.4754e-01,\n",
            "         -7.4999e-01,  1.2249e+00, -2.0579e-02, -3.5849e-01, -6.3699e-02,\n",
            "          9.2793e-02,  7.3654e-02, -2.3875e-01, -5.4692e-01],\n",
            "        [-2.3567e-02, -5.6340e-03, -1.6639e-01, -2.7012e-01,  1.6198e+00,\n",
            "          4.8855e-01,  1.7981e-01, -2.1281e-01,  5.2188e-01, -1.7353e-01,\n",
            "         -6.0762e-01,  4.5056e-01, -1.0258e+00, -8.0129e-01,  6.4527e-01,\n",
            "          1.7153e-01,  6.6980e-01, -2.5257e-01, -6.2808e-01],\n",
            "        [-5.6849e-01, -9.6549e-02,  2.4891e-01, -5.0206e-01,  1.0751e+00,\n",
            "         -2.1452e-01, -1.0351e-01, -1.2436e-01,  2.8123e-01, -5.2460e-01,\n",
            "         -1.3223e-01,  9.1088e-01, -2.8766e-01, -5.4599e-01,  1.2213e-01,\n",
            "          2.7266e-01,  1.1575e-01,  2.4541e-01, -2.0029e-01],\n",
            "        [-4.8158e-01, -3.0329e-01, -7.1939e-03,  3.0021e-01,  1.4040e+00,\n",
            "          1.6330e-02,  1.1767e-01, -2.4838e-01,  4.3599e-01,  1.2988e-01,\n",
            "          1.6588e-01,  2.9523e-01, -5.9631e-01, -3.4883e-01,  6.3361e-02,\n",
            "          1.8728e-01,  4.4807e-01, -1.2113e-01, -1.0999e-01],\n",
            "        [-2.5020e-01, -5.0872e-02, -3.7475e-02, -1.2612e-01,  9.6605e-01,\n",
            "          8.8542e-02,  2.3165e-01, -5.3510e-01,  3.0405e-01, -5.2905e-01,\n",
            "         -1.7770e-01,  7.4769e-01, -2.4345e-01, -4.0047e-01, -5.6941e-02,\n",
            "          2.2840e-01,  3.0205e-01, -2.2564e-01, -2.4734e-01],\n",
            "        [-7.3810e-01, -5.8322e-01, -7.9709e-03, -4.2345e-01,  9.9519e-01,\n",
            "         -5.6619e-02, -6.2272e-01,  2.7963e-01,  6.2837e-02,  8.2490e-02,\n",
            "         -3.4492e-01,  9.7758e-01, -1.6412e-02, -3.5560e-01,  1.1566e-01,\n",
            "          5.4656e-01,  6.5311e-01,  2.6742e-01, -4.4884e-01],\n",
            "        [-8.5719e-01, -5.8062e-01, -2.9864e-01,  6.6839e-01,  1.6230e+00,\n",
            "          1.6138e-01, -2.8677e-01, -2.6429e-01,  1.0843e+00, -2.5748e-01,\n",
            "         -4.1468e-02,  8.6873e-01, -6.9091e-01, -5.0858e-01,  1.7862e-01,\n",
            "          1.0487e+00,  2.3730e-01,  6.3023e-02, -6.5040e-01],\n",
            "        [-4.0304e-01, -1.7891e-01, -2.2655e-01,  2.8742e-01,  1.3954e+00,\n",
            "         -9.9183e-02,  4.5800e-01,  3.0776e-01,  7.1626e-01,  4.1652e-02,\n",
            "         -3.3312e-01,  9.1972e-01,  2.3311e-01,  5.2075e-02,  2.3349e-01,\n",
            "          3.8630e-01,  6.6877e-01,  1.6545e-01, -5.2291e-01],\n",
            "        [-1.9049e-01, -3.9528e-01, -1.1242e-01,  1.7355e-01,  9.9210e-01,\n",
            "         -2.7426e-01, -1.1351e-01,  7.4003e-03,  5.6513e-01, -6.8340e-02,\n",
            "         -1.6471e-01,  5.4009e-01, -6.8700e-01, -7.8639e-01, -1.4371e-02,\n",
            "          5.5485e-01,  3.6723e-01,  3.9580e-02, -3.8021e-01],\n",
            "        [-8.3140e-01, -3.2783e-01,  1.5653e-02,  2.4351e-01,  8.9200e-01,\n",
            "         -2.5127e-02,  3.6777e-01,  3.3578e-01,  9.4972e-01, -2.7942e-01,\n",
            "         -5.1645e-01,  2.9662e-01,  1.8794e-01, -1.8545e-01, -1.3695e-01,\n",
            "          3.0517e-01,  3.4787e-01,  2.2843e-02, -7.5268e-02],\n",
            "        [-1.1712e-01, -9.1138e-01,  8.2648e-02,  1.0239e-01,  9.3852e-01,\n",
            "         -1.6172e-01,  1.0855e-01, -9.5216e-02,  2.5775e-01,  2.0556e-01,\n",
            "         -7.6033e-01,  8.5243e-01, -5.8577e-01, -3.5308e-01,  9.6862e-01,\n",
            "          3.6322e-01,  5.4913e-01, -2.2717e-01, -3.8960e-01],\n",
            "        [-3.0919e-01, -1.5180e-01, -4.2618e-01,  4.1476e-01,  8.6984e-01,\n",
            "         -1.0877e-01, -1.8439e-01, -2.7624e-01,  6.9904e-01, -2.4042e-01,\n",
            "         -2.7791e-01,  7.9134e-01, -4.1828e-01, -4.0805e-01, -4.0082e-02,\n",
            "          3.4798e-01, -8.8990e-02,  1.1259e-01, -4.3129e-01],\n",
            "        [-2.0097e-01, -3.9143e-01, -1.9725e-01, -5.6685e-02,  1.0121e+00,\n",
            "          3.6439e-02, -5.9709e-01, -9.3970e-02,  3.2832e-01, -6.2914e-01,\n",
            "         -3.6710e-01,  2.1758e-01, -4.0277e-01, -3.6028e-01,  3.9279e-01,\n",
            "          3.0719e-01,  2.8776e-01,  3.9174e-01, -3.8344e-01],\n",
            "        [-3.2454e-01, -2.3046e-01, -1.6559e-01,  6.5162e-01,  7.9504e-01,\n",
            "          8.6179e-03, -3.9533e-01, -4.5492e-01,  6.4468e-01,  1.1146e-01,\n",
            "         -3.2038e-01,  6.7705e-01, -2.5959e-01, -5.5321e-01,  3.7526e-01,\n",
            "          1.2169e-01,  7.1446e-01,  9.5544e-02, -2.4214e-01],\n",
            "        [-2.5111e-01, -4.6741e-01,  5.0362e-01, -2.6613e-01,  8.6795e-01,\n",
            "          2.7948e-01,  3.4666e-01,  1.6198e-01,  1.8051e-01, -5.9214e-01,\n",
            "         -2.0832e-01,  5.2749e-01, -4.1306e-01, -8.1182e-01,  2.3688e-01,\n",
            "          2.9673e-01,  4.8327e-01, -3.9101e-02, -3.6384e-01],\n",
            "        [-2.5969e-01,  4.4570e-02,  3.1703e-01,  3.1472e-01,  1.0315e+00,\n",
            "         -1.3628e-03, -4.4358e-02, -2.1263e-01,  4.4376e-01,  8.0481e-02,\n",
            "         -4.2009e-01,  9.0401e-01, -5.4831e-01, -5.6043e-01,  1.1821e-01,\n",
            "          6.1023e-01,  4.0976e-01,  1.0818e-01, -4.7806e-01],\n",
            "        [-3.7150e-01, -3.1081e-01, -1.5500e-01,  5.4564e-01,  9.9809e-01,\n",
            "         -2.9181e-01, -5.1334e-01, -1.5242e-01,  1.9508e-01, -3.3261e-01,\n",
            "         -6.7328e-02,  7.3666e-01, -1.1805e-01, -4.7943e-01, -4.3050e-03,\n",
            "          5.2921e-01,  5.6351e-01, -2.2754e-01, -2.8495e-03],\n",
            "        [-2.4037e-01, -3.1763e-02,  1.7254e-02,  6.8916e-01,  8.4794e-01,\n",
            "         -1.4143e-01,  3.7736e-02, -1.4793e-01,  4.7734e-01,  2.4700e-01,\n",
            "         -5.0844e-01,  7.0209e-01, -1.3879e-02, -4.5954e-01,  5.4600e-02,\n",
            "          4.0714e-01,  2.1171e-01,  3.2908e-01, -3.2413e-01],\n",
            "        [-4.0203e-01,  9.1376e-02,  2.9523e-01,  4.0736e-01,  9.1336e-01,\n",
            "         -4.6760e-01, -1.2910e-01, -4.5284e-01,  8.1592e-01, -2.4835e-01,\n",
            "         -7.4224e-02,  1.0568e+00, -3.4070e-01, -8.6966e-01,  1.1630e-01,\n",
            "          8.0495e-02,  9.5308e-01,  1.5458e-01, -2.6228e-01],\n",
            "        [-1.0794e-01,  1.1014e-01,  7.6122e-01, -9.4543e-02,  8.9054e-01,\n",
            "         -6.2996e-02, -3.0634e-02, -2.3565e-01,  3.8896e-01, -5.1565e-01,\n",
            "         -9.2272e-01,  7.9226e-01, -2.5815e-02, -1.0412e-02, -2.2254e-01,\n",
            "          1.2699e-01,  9.9145e-02,  2.5024e-01, -1.9348e-01],\n",
            "        [-3.1449e-01, -2.6683e-01,  2.3618e-02, -1.2965e-01,  1.0092e+00,\n",
            "         -1.0678e-01,  1.4515e-01,  1.0224e-02,  4.0057e-01, -3.0649e-01,\n",
            "         -1.7471e-01,  5.6088e-01, -8.4255e-03,  4.4045e-02,  5.7712e-02,\n",
            "         -7.7420e-02,  8.6741e-02,  2.7693e-01, -3.4997e-01],\n",
            "        [-4.2888e-02, -5.3821e-01, -6.1229e-02,  2.1375e-01,  1.3226e+00,\n",
            "          5.0762e-01, -1.2571e-01, -4.8973e-02,  2.0714e-01, -1.4395e-01,\n",
            "         -4.7882e-01,  9.2554e-01, -4.9909e-01, -4.8333e-01,  3.9230e-01,\n",
            "          5.3371e-01,  7.0691e-01, -1.8998e-01, -7.0263e-01],\n",
            "        [-4.5903e-01, -2.6423e-01,  2.1196e-01,  7.3428e-02,  1.3034e+00,\n",
            "         -1.1243e-01,  4.2995e-01, -2.1615e-01,  3.4975e-01, -5.7679e-01,\n",
            "         -2.1288e-01,  5.6542e-01, -5.1799e-01, -5.1182e-01,  9.7319e-02,\n",
            "          7.5021e-01,  3.8371e-01,  7.1779e-02, -3.0672e-01],\n",
            "        [-1.8317e-01, -3.4954e-01,  3.9304e-02,  4.5239e-01,  5.5045e-01,\n",
            "         -3.7746e-01,  3.9311e-01, -5.1410e-01,  8.7502e-01,  1.9601e-01,\n",
            "         -1.9261e-01,  8.3348e-01, -5.6098e-01, -8.2218e-01,  2.2272e-01,\n",
            "          1.0069e+00,  7.2686e-01, -3.7777e-01, -4.3200e-01],\n",
            "        [ 1.9238e-01, -9.2067e-02,  2.1108e-01,  2.5287e-01,  1.0667e+00,\n",
            "         -3.6989e-01, -3.3163e-01, -1.8545e-01,  6.1822e-01, -4.5955e-01,\n",
            "         -3.3373e-02,  9.5296e-01, -9.8756e-01, -3.7193e-01,  8.4480e-02,\n",
            "         -2.9580e-03, -7.3617e-02,  9.0253e-02, -8.2358e-01],\n",
            "        [-4.6919e-01, -5.1928e-01, -4.1096e-01,  2.9726e-01,  1.2560e+00,\n",
            "          1.6719e-01,  1.3941e-02, -2.0241e-01,  5.3037e-01, -3.5809e-01,\n",
            "         -3.5667e-01,  9.8674e-01, -8.0982e-01, -6.8810e-01,  4.9321e-01,\n",
            "          6.1878e-01,  4.1280e-01, -9.3315e-02, -4.1247e-01],\n",
            "        [-2.0170e-01, -3.1130e-01,  5.8946e-02,  1.4612e-01,  9.6936e-01,\n",
            "         -3.4453e-01,  3.0012e-01, -4.6672e-01,  8.1240e-01,  1.7438e-01,\n",
            "         -9.7466e-02,  1.1194e+00, -4.2573e-01, -4.0032e-01,  7.0256e-02,\n",
            "          3.7708e-01,  4.5242e-01, -1.8199e-01, -4.0533e-01],\n",
            "        [-4.2146e-01,  1.7431e-01,  5.1760e-02,  3.0814e-01,  1.2373e+00,\n",
            "         -2.1700e-01,  5.2305e-01, -2.1227e-01,  9.4500e-01,  1.2249e-01,\n",
            "          1.6994e-01,  5.0041e-01, -3.7668e-01, -9.0479e-01,  3.8316e-01,\n",
            "          5.0481e-01,  6.4766e-01,  9.9119e-02, -6.2155e-01],\n",
            "        [-4.4571e-01, -6.2539e-01,  4.6937e-02,  2.2901e-01,  1.0593e+00,\n",
            "         -4.2813e-01, -4.3180e-02, -2.4643e-01,  7.4304e-01, -1.9779e-01,\n",
            "         -2.8737e-01,  9.7919e-01, -1.0376e-01, -6.5055e-01, -9.8806e-02,\n",
            "          9.2866e-01,  9.4669e-01,  3.5169e-01,  3.4740e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-3.5057e-01,  3.3947e-01, -1.8906e-02,  3.3836e-01,  7.5248e-01,\n",
            "         -1.9888e-01,  1.2240e-01, -4.4519e-01,  5.0989e-01,  7.0928e-02,\n",
            "         -4.8135e-01,  7.4340e-01, -1.0700e-01, -4.5288e-01, -2.3588e-01,\n",
            "          4.7239e-01,  7.7689e-01, -1.1386e-01, -7.6383e-01],\n",
            "        [-3.3192e-01, -7.1760e-01,  2.2434e-01,  1.9748e-01,  1.0352e+00,\n",
            "          3.4643e-01, -9.4045e-02, -8.5207e-02,  5.4845e-01, -3.3690e-01,\n",
            "          1.1104e-01,  1.2080e+00,  1.1530e-01, -4.0705e-01, -2.3769e-01,\n",
            "          3.5991e-01,  5.0993e-01,  4.0465e-02, -2.9024e-01],\n",
            "        [-9.8772e-01, -3.1580e-01, -1.6128e-01,  2.9918e-01,  7.8598e-01,\n",
            "         -4.2017e-02,  5.2977e-01,  2.5943e-01,  4.7359e-01,  1.2138e-02,\n",
            "         -7.9456e-03,  1.2956e+00, -3.1531e-01, -4.2439e-01, -3.3010e-01,\n",
            "          3.3640e-01,  3.4751e-01, -3.7434e-01, -4.3478e-02],\n",
            "        [-4.1355e-01, -8.1061e-02,  4.2378e-01,  3.2386e-01,  1.5546e+00,\n",
            "         -3.7172e-01, -6.9887e-02, -2.8235e-01,  5.0328e-01, -7.7419e-03,\n",
            "         -2.3210e-01,  7.7989e-01,  5.9391e-02, -8.3019e-01, -3.4453e-01,\n",
            "          5.3616e-01, -2.7323e-01, -1.7361e-02, -4.6846e-01],\n",
            "        [-5.6311e-01, -1.7587e-01, -3.6376e-02,  3.0015e-01,  1.0974e+00,\n",
            "         -1.3689e-01,  1.7731e-01, -4.2881e-03,  7.4986e-01, -4.4600e-01,\n",
            "         -4.0637e-01,  6.1211e-01, -7.1592e-01, -6.9133e-01,  5.6364e-01,\n",
            "          2.4767e-01,  2.9643e-01,  2.1807e-01, -7.1728e-01],\n",
            "        [-1.5451e-01, -1.5010e-01, -3.9124e-01,  2.5795e-01,  8.1412e-01,\n",
            "         -2.8521e-01, -8.7552e-01, -1.4569e-01,  1.0840e+00,  7.7622e-02,\n",
            "          2.5571e-01,  1.0046e+00, -4.9814e-01, -5.6553e-01, -8.6331e-02,\n",
            "          3.9361e-01,  8.7816e-01,  1.8028e-01, -5.2336e-01],\n",
            "        [-9.9986e-01, -7.5022e-02, -2.6951e-01, -4.1465e-03,  1.1770e+00,\n",
            "         -5.3854e-01, -5.9707e-03, -7.0551e-01,  7.1170e-01, -8.3175e-01,\n",
            "         -3.0666e-01,  1.0893e+00,  2.2891e-01, -7.3653e-01, -1.3479e-01,\n",
            "          6.1374e-01,  1.9087e-01, -3.4460e-01, -3.3750e-02],\n",
            "        [-2.1193e-01, -4.4398e-01, -3.3180e-02, -5.0285e-02,  9.7975e-01,\n",
            "         -2.8215e-01, -1.3918e-01, -2.2466e-01,  7.3110e-01,  4.6993e-01,\n",
            "         -1.1978e-01,  5.6318e-01, -1.7782e-01, -2.0238e-01,  6.3232e-01,\n",
            "          1.8718e-01,  6.4683e-01, -1.5263e-01, -1.9029e-01],\n",
            "        [-8.1234e-01,  4.5817e-02,  1.6165e-01, -5.8691e-02,  1.4418e+00,\n",
            "          6.3568e-04,  4.2648e-01,  2.4919e-01,  7.9901e-01, -1.4467e-01,\n",
            "         -1.5555e-01,  7.3366e-01, -7.5246e-01, -4.4755e-01,  3.8833e-01,\n",
            "          8.7652e-01,  4.4984e-01, -6.3714e-03, -2.4931e-01],\n",
            "        [-1.0710e+00, -5.9779e-01,  6.2458e-02,  1.7825e-01,  1.7420e+00,\n",
            "          2.8413e-01, -6.0316e-01,  5.3433e-01,  5.3333e-01,  1.7084e-01,\n",
            "         -8.4463e-01,  9.2139e-01, -5.9962e-01, -7.5867e-01, -2.0649e-01,\n",
            "          5.5206e-01,  3.3919e-01,  3.3709e-01, -5.1053e-01],\n",
            "        [-2.9164e-01, -7.1657e-03, -1.3462e-01,  1.9876e-01,  1.1682e+00,\n",
            "         -1.1963e-01, -2.1597e-01, -5.3770e-01,  8.4494e-01,  9.7786e-02,\n",
            "         -8.8409e-01,  9.2007e-01, -2.2202e-01, -3.2540e-01,  2.2367e-01,\n",
            "          1.6039e-01,  3.0732e-01,  2.9998e-01, -2.4200e-01],\n",
            "        [-4.0272e-01,  1.2570e-01, -1.1646e-01, -2.2605e-01,  1.3518e+00,\n",
            "         -2.3999e-01, -1.6314e-01,  1.8330e-01,  9.1552e-01,  9.1673e-02,\n",
            "         -6.5855e-01,  9.4231e-01, -4.7149e-01, -7.8879e-01,  3.6959e-02,\n",
            "          5.9021e-01,  7.3653e-01, -8.6774e-02, -2.3789e-01],\n",
            "        [-5.9547e-01, -5.3586e-01,  4.7947e-01,  2.5212e-01,  7.1434e-01,\n",
            "          2.8368e-01,  3.3880e-02, -1.7436e-01,  4.9949e-01, -4.8925e-01,\n",
            "         -1.3772e-01,  1.0695e+00, -4.8935e-01, -4.7953e-01,  2.2839e-01,\n",
            "          3.8615e-01,  4.1562e-01,  3.9337e-01, -1.5281e-01],\n",
            "        [-5.4473e-02, -1.3445e-01, -1.1056e-01,  3.1937e-01,  4.1646e-01,\n",
            "          2.4538e-01,  5.2919e-01,  7.9064e-02,  2.2183e-01, -1.5536e-01,\n",
            "          3.6847e-02,  8.0931e-01,  9.5937e-02, -2.3528e-01,  2.5388e-01,\n",
            "          4.5498e-01,  3.8180e-01,  2.9948e-01, -2.5086e-01],\n",
            "        [-4.7993e-01, -4.6872e-01, -2.1928e-01, -1.0679e-01,  1.3006e+00,\n",
            "          4.8145e-02,  1.1348e-01, -3.5881e-01,  2.7973e-01, -3.7403e-01,\n",
            "          3.8840e-02,  4.2722e-01, -1.7557e-01, -6.7450e-01,  4.8102e-01,\n",
            "          3.2616e-01,  3.4716e-01, -4.7300e-01, -5.5768e-01],\n",
            "        [-9.1086e-01, -3.0600e-01, -1.4620e-01, -1.1336e-01,  9.4302e-01,\n",
            "         -4.7257e-01,  7.9627e-02, -3.0193e-01,  8.2081e-01, -3.2646e-01,\n",
            "          6.9189e-01,  1.3878e+00, -6.7976e-01, -4.9358e-01,  9.2744e-02,\n",
            "          6.1868e-01,  2.7296e-01,  5.6029e-01, -1.3778e-01],\n",
            "        [-1.0276e-01, -1.5402e-01,  3.2389e-01, -2.2735e-01,  6.4662e-01,\n",
            "         -3.5731e-01,  1.1095e-01, -2.0676e-01,  5.3026e-01,  2.0734e-01,\n",
            "          2.0048e-01,  6.2405e-01, -6.0332e-01, -3.2457e-01,  2.4672e-01,\n",
            "          5.7259e-01,  7.1434e-01,  5.2381e-02, -4.9895e-01],\n",
            "        [-3.7857e-01, -2.7826e-01,  2.8745e-01, -1.4439e-02,  7.7702e-01,\n",
            "         -3.9109e-02, -1.7162e-01, -2.6529e-01,  5.4575e-01,  1.8558e-02,\n",
            "         -9.1497e-02,  6.8740e-01,  8.3727e-02, -3.6300e-01, -1.8947e-02,\n",
            "          3.1179e-01,  3.6090e-01,  4.3596e-01, -2.0287e-01],\n",
            "        [-1.0493e+00, -3.4136e-01, -1.1648e-01,  2.7048e-01,  1.3044e+00,\n",
            "         -2.0592e-02,  6.9419e-02,  7.1899e-02,  5.2529e-01, -6.0522e-01,\n",
            "         -1.6921e-01,  9.7502e-01, -4.5995e-01, -8.0462e-01, -1.3866e-01,\n",
            "          5.2261e-01,  2.8827e-01,  3.5204e-01, -6.7439e-01],\n",
            "        [-4.9253e-01, -8.2477e-01, -1.4294e-01,  5.2506e-02,  1.0713e+00,\n",
            "          3.2217e-01,  1.4122e-01, -2.3284e-01,  8.7843e-01,  3.2829e-01,\n",
            "         -4.6621e-01,  1.0237e+00, -1.0277e-01, -5.5421e-01,  5.7232e-01,\n",
            "          6.1385e-01,  3.3064e-01,  1.9518e-01, -3.0844e-01],\n",
            "        [-4.9645e-01, -4.8258e-01, -1.5261e-01,  2.9089e-01,  1.1033e+00,\n",
            "          6.5146e-02,  2.9027e-03, -3.0099e-01,  1.8827e-01, -1.7704e-01,\n",
            "         -1.8828e-01,  4.6104e-01, -4.5887e-01, -4.7049e-02,  1.6963e-01,\n",
            "          4.2826e-01,  1.9999e-01,  3.1762e-01, -5.9955e-01],\n",
            "        [-6.3521e-01, -2.0206e-01, -4.0618e-02,  3.9988e-01,  2.1858e+00,\n",
            "         -5.2807e-01, -3.6231e-01, -4.4122e-02,  5.6264e-01, -6.2800e-01,\n",
            "         -6.6609e-01,  1.3146e+00, -6.1375e-01, -1.6312e-01, -4.1025e-01,\n",
            "          1.4676e-01,  1.5813e-01, -2.9031e-02, -5.4376e-01],\n",
            "        [ 3.2474e-02,  1.9604e-02, -2.5501e-01,  3.1166e-01,  9.8816e-01,\n",
            "          8.2306e-02,  1.5165e-01, -1.8833e-01,  4.3915e-01, -3.8800e-01,\n",
            "         -1.3244e-01,  4.2591e-01, -3.1926e-01, -4.9031e-01,  1.6782e-01,\n",
            "          2.3620e-01,  1.9530e-01, -1.3874e-01, -2.5352e-01],\n",
            "        [-5.8673e-01, -4.1464e-02, -9.9949e-02, -2.9431e-01,  1.3813e+00,\n",
            "         -4.6782e-01,  3.6073e-01, -2.0481e-01,  8.0770e-01,  8.4951e-02,\n",
            "         -3.0229e-01,  6.2923e-01, -4.6318e-01, -3.8932e-01,  8.8284e-02,\n",
            "          5.6921e-01,  5.0592e-01,  1.8740e-01, -6.1550e-01],\n",
            "        [-7.5555e-01, -1.8617e-01, -2.7650e-02,  1.6358e-01,  9.7374e-01,\n",
            "          2.8650e-01, -3.6330e-02, -6.6704e-01,  9.0176e-01, -2.9256e-01,\n",
            "         -7.1529e-01,  7.2416e-01, -5.2000e-01, -4.1815e-01,  7.2485e-01,\n",
            "          7.4547e-02, -1.3540e-01, -3.2896e-01, -2.5882e-01],\n",
            "        [-5.0445e-01,  5.7846e-02,  4.5157e-02,  1.1575e-01,  1.6425e+00,\n",
            "          2.2875e-02, -2.1388e-01, -4.6586e-02,  4.8578e-01, -2.7949e-01,\n",
            "          8.8153e-02,  6.4317e-01, -5.0960e-01, -6.9013e-01,  9.0606e-02,\n",
            "          1.0485e+00,  2.0502e-01, -2.5081e-01, -2.6815e-01],\n",
            "        [-5.2550e-01, -6.8489e-02,  2.9745e-01, -1.6450e-01,  1.2586e+00,\n",
            "          1.5946e-01,  2.1596e-01, -4.0870e-01,  3.3014e-01, -2.6791e-01,\n",
            "          4.9736e-01,  7.5333e-01, -5.9308e-01, -3.5058e-01, -1.3928e-02,\n",
            "          3.5487e-01,  2.9621e-01, -7.3459e-03, -1.3690e-01],\n",
            "        [-4.3487e-01, -3.0233e-01,  2.2400e-01, -4.5350e-01,  1.5835e+00,\n",
            "         -1.4814e-01,  3.2720e-02,  1.1322e-01,  9.7306e-01, -5.7182e-01,\n",
            "         -3.1042e-01,  1.0128e+00, -2.3674e-01, -2.7843e-01,  7.6837e-02,\n",
            "          5.6081e-01,  5.2570e-01,  1.4927e-01, -2.3109e-01],\n",
            "        [-1.1041e-01, -4.9494e-02,  2.1454e-01,  2.0967e-01,  1.3065e+00,\n",
            "          2.8221e-02, -2.7045e-01, -9.1625e-01,  3.1685e-01, -2.8942e-01,\n",
            "         -5.2350e-01,  8.4842e-01, -5.4644e-01, -5.5127e-01, -1.3271e-01,\n",
            "          3.3896e-01,  5.2088e-01, -1.0976e-01, -1.1541e-01],\n",
            "        [-7.1418e-01, -3.3020e-01, -2.0654e-02,  4.3449e-01,  1.0060e+00,\n",
            "         -2.9909e-01,  9.9991e-02,  2.6235e-02,  6.8295e-01,  8.4818e-02,\n",
            "         -4.8886e-01,  7.5117e-01, -1.9893e-01, -5.4577e-01,  2.0797e-02,\n",
            "          2.5220e-01,  2.8976e-01, -5.1798e-01, -3.7036e-01],\n",
            "        [-4.4886e-01, -3.1391e-01,  2.1949e-01,  9.2330e-02,  1.0096e+00,\n",
            "         -1.9266e-02,  2.2514e-01, -4.1737e-02,  4.8371e-01,  1.9704e-01,\n",
            "         -5.2801e-01,  3.9732e-01,  3.3282e-02, -5.0471e-01,  2.5714e-01,\n",
            "         -9.0545e-02,  2.6680e-01,  3.6054e-01, -2.7443e-01],\n",
            "        [-4.9543e-01,  1.0245e-01,  7.1914e-02, -1.0676e-01,  1.3146e+00,\n",
            "         -8.6589e-02, -4.6299e-01,  1.7505e-02,  5.0038e-01, -8.8840e-02,\n",
            "         -9.1536e-02,  1.0362e+00, -6.9253e-01, -7.2021e-01,  2.3038e-01,\n",
            "          3.8237e-01,  7.4452e-01, -1.5483e-01, -2.8671e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4734,  0.0075, -0.0626,  0.3706,  1.1486,  0.2547, -0.7966, -0.8420,\n",
            "          0.9632, -0.2305, -0.4592,  1.1484, -0.0957, -0.0684,  0.4778,  0.6692,\n",
            "          0.3852,  0.1643, -0.6902],\n",
            "        [-0.5647, -0.3229, -0.3161, -0.0793,  0.7592, -0.2024,  0.1624, -0.2371,\n",
            "          1.0943, -0.1717, -0.5014,  1.2384, -0.4778, -0.5361,  0.6004,  0.1218,\n",
            "          0.2650, -0.0539, -0.6267],\n",
            "        [-0.5699, -0.0552, -0.0820, -0.5170,  1.5456, -0.1942, -0.5665, -0.1643,\n",
            "          0.3992, -0.3991, -0.7688,  1.4465,  0.2104, -0.6505,  0.3638,  0.6444,\n",
            "          0.4532,  0.2393, -0.1538],\n",
            "        [-0.1533, -0.0752, -0.0081,  0.4419,  0.6263, -0.0515,  0.1528, -0.4164,\n",
            "          0.2125, -0.4155, -0.2419,  0.5153, -0.3356, -0.2526, -0.0829,  0.2834,\n",
            "          0.3168,  0.1388, -0.5047],\n",
            "        [-0.6260, -0.1845,  0.1271,  0.1142,  0.9756,  0.0432, -0.2130, -0.2745,\n",
            "          0.5309,  0.0676, -0.0899,  0.8610, -0.2235, -0.4050, -0.0144,  0.1040,\n",
            "          0.6024,  0.1514,  0.0958],\n",
            "        [-0.4416, -0.5104, -0.0877,  0.2878,  1.0853, -0.2450, -0.3864, -0.4651,\n",
            "          0.6180, -0.1188, -0.1171,  1.1034, -0.2704, -0.3306,  0.0334,  0.3049,\n",
            "          0.6666,  0.2552, -0.1886],\n",
            "        [-0.2981, -0.1133,  0.5341,  0.2982,  1.1100,  0.2694, -0.0903,  0.0832,\n",
            "          0.7480,  0.4704, -0.7940,  1.3365, -0.6293, -0.2900, -0.1362,  0.2440,\n",
            "          0.3394, -0.2673, -0.3425],\n",
            "        [-0.3283, -0.1802, -0.1303, -0.1204,  1.5063, -0.1178, -0.2499,  0.3026,\n",
            "          1.2754,  0.3137, -0.6132,  1.7489, -0.6995, -0.4893, -0.1629,  0.5695,\n",
            "          0.5996,  0.3945, -0.4833],\n",
            "        [-1.0657,  0.0567, -0.1276, -0.3037,  0.9869, -0.0990,  0.3137,  0.0613,\n",
            "          0.8757, -0.0752, -0.1408,  1.0441, -0.2619, -0.1417,  0.0242,  0.2423,\n",
            "          0.6475, -0.5372, -0.1950],\n",
            "        [-0.4614, -0.0458,  0.4213,  0.2751,  1.4379, -0.1626,  0.3708,  0.0993,\n",
            "          0.2276, -0.3154, -0.8253,  1.0191, -0.4076,  0.0473, -0.3150,  0.8003,\n",
            "          0.0937, -0.5041, -0.7873],\n",
            "        [ 0.1119, -0.4747, -0.2042,  0.1274,  0.7150, -0.2860,  0.0457, -0.1355,\n",
            "          0.4647, -0.2537, -0.1409,  0.6671, -0.5316, -0.0538,  0.0670,  0.3903,\n",
            "          0.1013, -0.0788, -0.1449],\n",
            "        [-0.9589,  0.0992,  0.2936,  0.5844,  1.2734, -0.1910,  0.0096, -0.4539,\n",
            "          0.5738, -0.3429, -0.6138,  0.5632, -0.4765, -0.3039,  0.2883,  0.6470,\n",
            "          0.5799,  0.3201, -0.3419],\n",
            "        [-0.1744, -0.2805, -0.1794,  0.2163,  1.1247,  0.1942, -0.1957, -0.1141,\n",
            "          0.7619, -0.5289,  0.1284,  0.3319, -0.3410, -0.4075,  0.3484,  0.3876,\n",
            "          0.5301,  0.3264, -0.4926],\n",
            "        [-0.0860, -0.0679,  0.1177,  0.6275,  0.8017, -0.3442, -0.0721, -0.3604,\n",
            "          0.9703, -0.4232, -0.2066,  0.8673, -0.4098, -0.5495,  0.1288,  0.4424,\n",
            "          0.3396,  0.1361, -0.5059],\n",
            "        [-0.3591, -0.2825, -0.1214, -0.0104,  1.1726, -0.0025, -0.0838,  0.0833,\n",
            "          1.1256, -0.0627, -0.5210,  0.7672, -0.7886, -0.6279,  0.7118,  0.5428,\n",
            "          0.1698,  0.4310, -0.3811],\n",
            "        [-0.3190, -0.3322,  0.0346,  0.2927,  0.9302, -0.4855, -0.1338, -0.2019,\n",
            "          1.0234, -0.1930, -0.3483,  1.1822, -0.6441, -0.6667, -0.0456, -0.0510,\n",
            "          0.5075, -0.0039, -0.6401],\n",
            "        [-0.2686, -0.3024,  0.4200,  0.0729,  0.9702,  0.2234,  0.0791, -0.0288,\n",
            "          0.6518,  0.1733, -0.4863,  0.9276, -0.3474, -0.1757,  0.1820,  0.4737,\n",
            "          0.1632, -0.5545, -0.6408],\n",
            "        [-0.2749,  0.1804,  0.2851, -0.0261,  0.9317,  0.2049,  0.2498,  0.1750,\n",
            "         -0.0555, -0.2493,  0.0293,  0.6898, -0.1440, -0.2193, -0.1043,  0.1956,\n",
            "          0.4120,  0.0565, -0.3931],\n",
            "        [-0.2790, -0.3360, -0.1623,  0.3046,  1.2696,  0.0570,  0.3599, -0.0169,\n",
            "          0.8050,  0.3266, -0.3830,  0.7759, -0.7878, -0.8014,  0.2671,  0.6202,\n",
            "          0.3596,  0.2438, -0.4763],\n",
            "        [-0.2577, -0.1678,  0.3911,  0.2074,  0.8701,  0.2057, -0.4579, -0.5536,\n",
            "          1.1406, -0.5966, -0.3569,  0.7102, -0.3975, -0.0762,  0.2047,  0.4759,\n",
            "          0.4070,  0.6912, -0.8166],\n",
            "        [-1.1899, -0.1739,  0.3008,  0.3514,  1.1379,  0.1815,  0.3534, -0.2054,\n",
            "          0.2755, -0.1916, -0.2236,  0.7229, -0.4644, -1.2233, -0.0098,  0.3237,\n",
            "          0.3812,  0.1621, -0.3540],\n",
            "        [-0.0457, -0.1866,  0.4029,  0.2355,  0.7317,  0.0273,  0.2864, -0.3939,\n",
            "          0.8347,  0.0866, -0.3171,  0.8893, -0.3395, -0.4264,  0.4140,  0.4768,\n",
            "          1.0302, -0.2376, -0.6128],\n",
            "        [-0.5156,  0.3255,  0.1378, -0.2415,  1.5331,  0.3163,  0.6359,  0.1296,\n",
            "          1.1871, -0.0495, -0.1160,  1.7913, -0.8497, -0.3592,  0.0155,  0.5063,\n",
            "          0.6227, -0.0869, -0.9640],\n",
            "        [-0.2774,  0.0895,  0.1381,  1.0498,  1.3550, -0.1894,  0.0848, -0.6488,\n",
            "          0.9082, -0.1956, -0.4646,  0.9565, -0.4452,  0.0494,  0.1801,  0.1426,\n",
            "          0.3919,  0.4955, -0.8110],\n",
            "        [-0.7049, -0.4048, -0.4341,  0.4773,  1.3887, -0.2556,  0.1491,  0.2885,\n",
            "          1.1767,  0.0518, -0.0229,  0.7564, -0.3587, -0.6913,  0.2390, -0.1045,\n",
            "          0.6153,  0.0022, -0.9688],\n",
            "        [-0.2963, -0.1108, -0.4377,  0.1314,  0.6637,  0.0378, -0.2147, -0.1979,\n",
            "          0.9390, -0.3131, -0.0420,  0.6722, -0.6809, -0.5788,  0.3878,  0.3323,\n",
            "          0.1653, -0.1565,  0.1060],\n",
            "        [-0.4375, -0.0938,  0.0504,  0.1476,  0.9346, -0.2818, -0.0647,  0.0862,\n",
            "          0.0846, -0.2118, -0.4602,  0.6596, -0.4348, -0.1107,  0.0198,  0.0254,\n",
            "          0.0176, -0.0858, -0.0344],\n",
            "        [-0.5469, -0.6356,  0.1935, -0.0259,  1.4574, -0.1088,  0.0074, -0.7369,\n",
            "          1.0625,  0.3465, -0.0773,  0.7434, -0.9194, -0.4420,  0.8444,  0.2071,\n",
            "          0.5182, -0.1275, -0.7457],\n",
            "        [-0.4804, -0.2686,  0.0776,  0.4114,  1.1125,  0.2538, -0.1487,  0.0498,\n",
            "          0.3095,  0.2149, -0.4720,  0.4773, -0.4245, -0.6209,  0.3878,  0.4720,\n",
            "          0.7840, -0.4338, -0.1178],\n",
            "        [-0.4471, -0.1558,  0.0399, -0.0080,  1.0258, -0.0825,  0.4437, -0.1563,\n",
            "          0.9557, -0.4322, -0.2968,  1.4015, -0.5837, -0.5744,  0.5835,  0.9662,\n",
            "          0.4146, -0.0269, -0.3596],\n",
            "        [-0.4950,  0.3377, -0.4369,  0.1225,  1.2840,  0.2079,  0.0195, -0.3068,\n",
            "          0.8882, -0.5333,  0.2391,  0.9251, -0.0439, -0.4399,  0.2209,  0.5317,\n",
            "          0.4585, -0.1621, -0.3686],\n",
            "        [ 0.1537, -0.0126,  0.0724,  0.6865,  1.2336, -0.7994,  0.1280, -0.2748,\n",
            "          0.8624, -0.3853, -0.0863,  0.8485, -0.4031, -0.6086,  0.2601,  0.9106,\n",
            "          0.6216,  0.5142, -0.6424]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-4.3515e-01, -6.5542e-02,  2.2620e-01,  3.1945e-01,  1.1116e+00,\n",
            "         -3.2962e-01,  2.4418e-01, -1.9345e-01,  4.1479e-01, -9.6837e-02,\n",
            "         -5.5648e-02,  8.4307e-01, -3.4853e-01, -7.0600e-01,  2.6610e-01,\n",
            "          3.9323e-01,  6.6212e-01, -7.7234e-02, -8.3090e-01],\n",
            "        [-1.2368e-01, -3.7602e-01,  8.0261e-02,  2.3215e-01,  1.4594e+00,\n",
            "         -1.4800e-02,  2.7426e-01,  1.7463e-01,  1.0263e+00, -2.1826e-01,\n",
            "         -4.0395e-01,  8.0212e-01,  3.9043e-02, -1.1619e+00,  3.7757e-01,\n",
            "          5.4149e-01,  4.1011e-01, -4.1881e-01, -4.4789e-01],\n",
            "        [-5.0978e-01,  6.2635e-02,  4.7302e-01,  4.4672e-02,  1.2404e+00,\n",
            "          2.3427e-01,  2.1085e-01, -5.5850e-01,  7.7114e-01, -6.6715e-02,\n",
            "         -2.2755e-01,  1.1691e+00, -6.9071e-01, -4.7598e-01, -1.0662e-01,\n",
            "          2.9345e-01,  6.7077e-01,  5.0622e-01, -8.2083e-01],\n",
            "        [-3.0838e-01, -2.6469e-01, -9.4159e-02, -2.5431e-01,  7.9690e-01,\n",
            "          1.6734e-01, -2.2236e-01, -8.8448e-01,  4.5248e-01, -3.5552e-01,\n",
            "          8.3010e-02,  1.1955e+00, -2.5380e-01, -6.7662e-01,  3.2217e-01,\n",
            "          2.8863e-01,  1.0462e+00, -2.3999e-01, -4.2155e-01],\n",
            "        [-7.0133e-01, -2.3731e-01,  1.3671e-01, -2.0670e-01,  1.6615e+00,\n",
            "          1.2251e-01, -2.1925e-02, -4.7682e-01,  9.9700e-01, -2.7237e-01,\n",
            "         -8.4493e-02,  1.2525e+00,  1.0121e-02, -6.4473e-01,  4.7299e-01,\n",
            "          7.5991e-01,  2.4522e-01, -1.8144e-01, -7.5585e-01],\n",
            "        [-6.6876e-01, -9.6876e-02, -2.6545e-01, -9.6288e-02,  1.0216e+00,\n",
            "          5.1397e-02,  1.2258e-01, -4.2062e-01,  9.9759e-01, -6.0290e-01,\n",
            "         -4.6394e-01,  1.1336e+00, -7.3347e-01, -6.5748e-01,  3.6438e-01,\n",
            "          2.9831e-01,  9.0489e-01,  5.9559e-02, -8.3116e-01],\n",
            "        [-2.0857e-01, -1.1655e-01, -1.3509e-01, -2.4700e-01,  1.2260e+00,\n",
            "          2.8551e-02, -9.6224e-02, -2.9574e-01,  6.4412e-01, -3.8488e-01,\n",
            "         -4.5713e-01,  8.6464e-01, -5.6507e-01, -9.1671e-01,  5.6814e-01,\n",
            "          1.5542e-01,  3.8485e-01,  3.4170e-01, -5.3060e-01],\n",
            "        [-3.1754e-02,  1.8345e-01,  5.1117e-01,  2.2890e-01,  1.1407e+00,\n",
            "          4.6093e-01,  2.3918e-01,  6.3761e-02,  3.4312e-01, -8.4686e-01,\n",
            "         -1.7212e-01,  4.4222e-01, -3.4670e-01, -6.7395e-01, -1.4222e-01,\n",
            "          5.1933e-01, -2.1680e-01,  2.6491e-01, -1.7540e-01],\n",
            "        [-4.6239e-01, -8.7214e-02, -1.4967e-01, -3.9292e-01,  9.3081e-01,\n",
            "          2.1252e-01, -1.5961e-01, -6.6940e-01,  1.1739e+00, -5.1920e-01,\n",
            "         -1.2461e-02,  1.2126e+00, -4.5144e-01, -8.7739e-01,  2.5538e-01,\n",
            "          4.1959e-01,  3.4031e-01,  2.2881e-01, -6.7196e-01],\n",
            "        [-6.9058e-01, -8.1479e-01, -5.8687e-02, -1.1989e-01,  1.3665e+00,\n",
            "         -1.6246e-01, -4.2917e-01, -1.5115e-01,  7.3859e-01,  4.9737e-02,\n",
            "         -1.9752e-03,  1.4572e+00, -8.3560e-01, -3.5927e-01,  7.1626e-01,\n",
            "          4.1294e-01,  5.2333e-01,  2.4026e-01, -5.9554e-01],\n",
            "        [-3.2357e-01, -2.8593e-01, -5.2850e-02, -1.3721e-01,  9.5928e-01,\n",
            "          2.3495e-03, -1.4275e-01, -1.4589e-01,  4.5480e-01, -3.0451e-02,\n",
            "         -1.3906e-01,  6.7280e-01, -2.9812e-01, -4.7936e-01,  5.0826e-02,\n",
            "          3.0156e-01,  4.0995e-01, -1.1700e-01, -6.5939e-02],\n",
            "        [-3.1919e-01,  3.5022e-01, -9.3010e-02,  5.8031e-01,  9.6313e-01,\n",
            "         -4.6201e-01, -3.0038e-01,  2.1400e-01,  8.5303e-01, -2.1562e-01,\n",
            "         -2.8900e-01,  6.0104e-01,  2.6440e-01, -9.7981e-01,  5.5729e-01,\n",
            "         -1.7189e-01,  4.7981e-01, -7.8451e-02, -5.1697e-01],\n",
            "        [-2.5362e-01, -5.0875e-01, -1.1799e-01, -2.2725e-01,  1.3300e+00,\n",
            "          3.5194e-01, -6.5439e-02, -2.3609e-02,  5.0776e-01, -6.9310e-01,\n",
            "         -5.8521e-01,  1.0533e+00, -6.1633e-01, -4.4781e-01, -2.7959e-01,\n",
            "         -8.4372e-03,  3.5655e-01,  1.4876e-02, -2.4465e-01],\n",
            "        [-3.8711e-01, -1.5597e-01,  1.2384e-01,  2.1746e-01,  9.8757e-01,\n",
            "          7.5252e-02, -2.4090e-01, -1.4852e-01,  7.2885e-01, -2.3720e-01,\n",
            "          9.4873e-02,  1.0436e+00, -1.1331e-01, -3.0869e-01, -2.2207e-03,\n",
            "          3.1133e-01,  4.0330e-01,  3.3670e-01, -1.2144e-01],\n",
            "        [-7.0769e-01, -3.0015e-01, -5.1140e-01,  9.8148e-02,  1.6121e+00,\n",
            "         -2.1356e-01, -1.0010e-02,  1.0599e-01,  9.4807e-01, -5.3213e-01,\n",
            "         -6.6999e-02,  9.0936e-01, -5.9376e-01, -5.3717e-01,  4.6420e-01,\n",
            "          7.9740e-01,  4.8139e-01,  5.9102e-02, -1.4579e-01],\n",
            "        [ 1.0746e-01, -7.9977e-02,  5.0589e-01,  3.4847e-02,  1.0321e+00,\n",
            "         -3.5864e-01, -1.8221e-01, -4.9359e-01,  8.6895e-01, -4.5922e-01,\n",
            "         -6.1335e-01,  8.7605e-01, -7.2759e-01, -6.8435e-01,  2.7961e-01,\n",
            "          4.4071e-01,  7.2880e-01,  1.2758e-01, -4.2246e-01],\n",
            "        [-8.2756e-01,  7.6448e-02, -1.5162e-01, -1.5385e-02,  1.4287e+00,\n",
            "         -1.1910e-01, -3.2533e-01,  1.0751e-01,  4.7182e-01, -6.8985e-01,\n",
            "         -8.3991e-01,  7.6720e-01, -6.3301e-01, -7.2512e-01,  5.5229e-01,\n",
            "          6.5618e-01,  6.1337e-01,  6.0751e-02, -1.0313e+00],\n",
            "        [-3.0881e-01, -1.0262e-01, -1.2228e-01, -3.6075e-01,  9.0350e-01,\n",
            "          6.5201e-02,  1.1884e-01,  2.3025e-01,  6.0150e-01, -2.3312e-01,\n",
            "         -2.7025e-01,  4.8686e-01,  8.0616e-02, -1.5639e-02,  2.7168e-01,\n",
            "          9.7240e-02,  3.4265e-01, -1.5405e-01, -4.5858e-01],\n",
            "        [-9.1310e-01,  1.0846e-01, -2.7307e-01, -3.7958e-01,  9.8439e-01,\n",
            "         -6.5357e-02, -2.0643e-01, -3.5682e-01,  9.5207e-01, -5.5220e-01,\n",
            "          4.8488e-02,  6.5083e-01,  4.8130e-02, -4.1101e-01,  9.0352e-01,\n",
            "         -1.4629e-01,  2.3586e-01, -9.4709e-02, -2.2119e-01],\n",
            "        [-8.2716e-01, -5.3944e-01, -1.9748e-01,  2.9122e-01,  9.6656e-01,\n",
            "          1.0036e-01,  2.8068e-01, -2.7840e-01,  8.5302e-01, -5.2580e-01,\n",
            "         -4.9793e-01,  1.3509e+00,  4.1418e-01, -8.9461e-01, -7.7517e-02,\n",
            "          2.7901e-01,  2.4807e-01, -6.6580e-02, -7.9490e-01],\n",
            "        [-4.9286e-01, -8.9827e-01,  8.3327e-02, -1.3693e-01,  1.6275e+00,\n",
            "          1.5231e-01,  6.0647e-01, -9.1164e-02,  1.0233e+00, -3.3726e-01,\n",
            "         -4.8069e-01,  3.2950e-01, -1.7798e-01, -4.3644e-01, -5.0479e-02,\n",
            "          3.0135e-01,  8.2362e-01, -2.8696e-01, -2.0501e-01],\n",
            "        [-5.2135e-01, -3.9201e-01,  1.6857e-01, -7.9125e-02,  1.0970e+00,\n",
            "         -2.0727e-01, -3.1158e-01, -3.2940e-01,  5.9655e-01,  1.9085e-02,\n",
            "         -4.3757e-01,  9.0872e-01, -3.9611e-01, -1.7651e-01, -1.8504e-01,\n",
            "          4.3203e-01,  4.6263e-01,  3.1176e-01, -4.0389e-01],\n",
            "        [-8.7032e-01, -2.0246e-01, -7.7990e-02, -1.4821e-02,  9.4199e-01,\n",
            "         -2.5282e-02, -2.3614e-01, -9.2032e-02,  1.0122e+00, -7.4796e-01,\n",
            "         -2.8979e-01,  7.7905e-01, -6.2155e-01, -7.5078e-01, -1.5175e-01,\n",
            "          2.5864e-01,  3.0305e-01,  3.6273e-01, -7.1420e-01],\n",
            "        [-8.8142e-01, -5.5673e-01,  2.0096e-01,  3.0236e-01,  1.7258e+00,\n",
            "         -3.2881e-01, -9.2063e-02, -3.9188e-01,  1.1019e+00, -6.8279e-01,\n",
            "         -3.9131e-01,  8.6399e-01,  1.8434e-01, -5.3422e-01,  2.9261e-01,\n",
            "          6.3470e-01,  7.5291e-01,  7.0712e-02, -9.7915e-01],\n",
            "        [-5.6105e-01, -3.3610e-01, -7.1374e-01,  3.0775e-01,  1.4362e+00,\n",
            "         -1.5899e-01, -8.1981e-03, -7.8555e-03,  1.0403e+00, -6.2325e-01,\n",
            "         -3.1796e-01,  1.1944e+00, -2.1164e-01, -6.7288e-01,  4.2363e-02,\n",
            "          5.2486e-01, -2.0230e-01, -5.1277e-02, -5.8285e-01],\n",
            "        [-5.8263e-01, -2.6523e-01, -1.0418e-01,  4.5468e-01,  1.0966e+00,\n",
            "         -1.8909e-01,  2.2363e-01, -5.0737e-01,  8.0628e-01, -6.6868e-01,\n",
            "         -1.9069e-01,  1.0460e+00, -8.0327e-01, -5.7443e-01, -1.6568e-02,\n",
            "          4.0135e-01,  4.9018e-01,  1.5588e-01, -6.1075e-01],\n",
            "        [-4.2448e-01, -6.9966e-02, -1.5368e-01,  2.8710e-01,  1.0225e+00,\n",
            "         -1.0812e-01, -4.5114e-01, -3.9685e-01,  7.5883e-01, -2.1504e-02,\n",
            "         -4.9856e-01,  8.8691e-01, -3.2252e-01, -4.7423e-01,  1.0142e-01,\n",
            "          2.4715e-01,  5.1948e-01,  8.2783e-03, -3.8704e-01],\n",
            "        [-1.4167e-01, -5.0581e-01,  3.4520e-01, -2.0085e-01,  1.4289e+00,\n",
            "         -1.8253e-01, -1.5509e-01,  3.7988e-02,  6.3234e-01, -3.3880e-01,\n",
            "         -9.7284e-01,  9.1809e-01, -7.8756e-01, -2.8777e-01, -4.3576e-01,\n",
            "          4.6391e-01,  6.7485e-01,  4.8747e-02, -1.1145e-01],\n",
            "        [-6.0463e-01, -4.1454e-01, -2.0972e-02, -6.1897e-02,  1.4147e+00,\n",
            "         -5.6428e-01,  3.5178e-01, -3.9342e-01,  1.2101e+00, -1.4026e-01,\n",
            "         -3.3636e-01,  1.3281e+00, -2.8448e-01, -5.6069e-01,  3.9453e-01,\n",
            "          3.0322e-01,  1.0241e+00, -1.4493e-01, -4.8193e-01],\n",
            "        [-4.0750e-01,  1.3403e-01,  1.0209e-01,  2.2663e-01,  1.9954e+00,\n",
            "          2.8960e-02,  7.5463e-02, -2.8494e-01,  8.8959e-01,  4.6360e-01,\n",
            "         -3.1103e-01,  9.5294e-01, -4.7913e-01, -4.0931e-01,  2.1207e-01,\n",
            "         -2.6371e-02,  1.8578e-01, -6.5973e-01, -7.1812e-01],\n",
            "        [-4.7285e-01, -2.4811e-01,  1.9846e-02,  3.4082e-01,  1.6155e+00,\n",
            "         -2.6889e-01,  4.9415e-01, -2.2943e-01,  9.7520e-01, -4.7098e-01,\n",
            "         -3.6669e-01,  1.2986e+00, -4.3684e-01, -9.0993e-01,  8.7782e-03,\n",
            "          8.9582e-01,  3.5796e-01, -6.1695e-01, -7.0578e-01],\n",
            "        [-4.6093e-01, -1.1729e-01, -1.2600e-01, -6.9671e-02,  8.0519e-01,\n",
            "         -5.2913e-01, -9.8720e-02,  2.3184e-01,  7.4591e-01, -1.5019e-01,\n",
            "         -3.7946e-01,  9.4178e-01, -1.0663e-01, -5.6764e-01,  2.6155e-01,\n",
            "          3.6069e-01,  2.0705e-01,  5.0625e-02, -5.1429e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-7.0658e-01, -1.3971e-01,  7.0761e-01,  1.1167e-01,  1.7005e+00,\n",
            "         -5.4187e-02, -2.6392e-01, -6.6765e-01,  1.0165e+00, -8.5385e-01,\n",
            "         -2.9173e-01,  5.2032e-01, -8.4699e-01, -6.6098e-01,  8.3567e-01,\n",
            "          8.9700e-01,  1.8797e-01, -8.4834e-02, -3.4729e-01],\n",
            "        [-3.2718e-01, -2.5388e-01,  3.5779e-01,  4.9106e-01,  1.1746e+00,\n",
            "          7.7090e-02,  1.4588e-01, -1.4287e-01,  5.5100e-01, -9.0281e-02,\n",
            "         -1.0250e-01,  9.4228e-01, -4.1381e-01, -4.7964e-01,  1.0487e-02,\n",
            "          5.0524e-01,  3.8491e-01, -3.8844e-01, -6.9326e-01],\n",
            "        [-1.7584e-01, -1.6493e-01,  2.7192e-02,  1.4472e-02,  1.0819e+00,\n",
            "         -5.9219e-02,  3.6056e-02, -6.0261e-01,  4.4159e-01, -4.0961e-01,\n",
            "         -6.8508e-02,  7.8502e-01, -1.0692e-01, -1.7122e-01,  7.2328e-02,\n",
            "         -2.2465e-01,  4.8622e-01,  2.1002e-01, -8.0022e-02],\n",
            "        [-8.2418e-01, -8.9443e-02,  2.1014e-01,  1.5098e-01,  8.6330e-01,\n",
            "          1.5504e-02,  1.8545e-01, -5.1223e-02,  9.3411e-01, -3.3070e-01,\n",
            "         -5.0477e-01,  1.1515e+00, -3.1454e-01, -4.9814e-01, -6.1344e-02,\n",
            "          3.0233e-01,  6.7016e-01, -4.0904e-01, -6.7948e-01],\n",
            "        [-9.0556e-01,  2.7924e-01,  7.3152e-02,  5.1743e-01,  1.6240e+00,\n",
            "          5.9803e-02,  1.1132e-02,  5.7697e-03,  1.4455e+00, -8.8136e-01,\n",
            "         -8.3239e-01,  1.6411e+00, -6.2515e-01, -1.0371e+00,  3.9303e-01,\n",
            "          7.1026e-01,  4.4141e-01, -1.0706e-01, -5.7286e-01],\n",
            "        [-1.4280e-01, -4.9659e-02, -9.0695e-02, -9.0942e-02,  7.5509e-01,\n",
            "         -2.0365e-01, -1.7930e-01, -2.0458e-01,  3.0112e-01, -7.0194e-02,\n",
            "          1.3223e-02,  5.9425e-01, -2.7685e-02, -3.9100e-01,  1.4106e-01,\n",
            "          3.9489e-01,  6.0689e-01, -5.5923e-02,  8.0685e-02],\n",
            "        [-8.3912e-01, -5.9390e-01,  1.3134e-02,  3.8470e-01,  1.2341e+00,\n",
            "         -9.3986e-02, -3.6598e-01, -3.0804e-01,  5.2009e-01, -4.6580e-01,\n",
            "         -5.2106e-01,  1.2986e+00, -6.7189e-01, -9.3998e-01,  3.7341e-01,\n",
            "         -1.5739e-01,  1.0309e+00,  5.1861e-01, -9.4243e-01],\n",
            "        [-4.6126e-01, -1.7066e-01, -5.6267e-02,  1.1313e-01,  9.0733e-01,\n",
            "          9.8632e-02,  7.9881e-02, -2.7526e-01,  1.1719e+00, -3.2917e-01,\n",
            "         -2.7254e-01,  7.8124e-01, -6.4613e-01, -4.6789e-01, -7.4567e-02,\n",
            "          3.3287e-01, -8.8691e-02, -1.9300e-01, -2.9862e-01],\n",
            "        [-5.6245e-01,  1.8140e-01,  1.5486e-01,  3.4843e-01,  1.6825e+00,\n",
            "         -1.2093e-01, -1.0146e-01,  1.5340e-01,  1.3335e+00, -2.4984e-01,\n",
            "         -3.1354e-01,  9.6353e-01, -3.0563e-01, -4.5664e-01,  6.9893e-01,\n",
            "          2.3059e-01,  3.5936e-01, -2.1569e-02, -7.8182e-01],\n",
            "        [-4.6449e-01,  5.7168e-02,  5.7849e-02,  3.7375e-01,  1.2364e+00,\n",
            "         -9.3318e-02, -6.3234e-03, -1.0233e-01,  6.3516e-01, -3.2292e-01,\n",
            "         -4.2194e-01,  1.3012e+00, -3.9799e-01, -1.0570e+00, -1.1780e-01,\n",
            "          1.8984e-01,  4.1283e-01, -1.8395e-01, -5.9853e-01],\n",
            "        [-7.8820e-01, -4.3073e-02,  5.0700e-01,  5.1805e-01,  9.9556e-01,\n",
            "          6.5902e-02,  6.4380e-01, -4.2345e-01,  9.7487e-01, -4.1876e-01,\n",
            "         -2.6909e-01,  1.0730e+00, -1.1431e+00, -8.6527e-01,  4.0131e-01,\n",
            "          2.0149e-01,  3.0526e-01,  2.1902e-01, -5.1994e-01],\n",
            "        [-4.1128e-01, -2.1345e-01,  8.4368e-02,  4.1978e-01,  7.7785e-01,\n",
            "          3.1276e-01,  1.7442e-01, -8.7245e-02,  5.5739e-01, -4.7925e-01,\n",
            "         -1.3019e+00,  1.2725e+00, -5.3143e-01, -9.2836e-01,  2.7605e-01,\n",
            "          5.3406e-01,  8.5726e-02,  2.6855e-01, -5.5360e-01],\n",
            "        [-2.9726e-01, -4.6159e-01, -2.1633e-01,  1.3615e-01,  1.7250e+00,\n",
            "         -7.8426e-02, -2.2726e-02,  2.3868e-02,  1.0238e+00, -4.3835e-01,\n",
            "         -4.2551e-01,  8.7793e-01, -4.6349e-01, -4.1552e-01,  3.3121e-01,\n",
            "         -3.4667e-01,  1.9653e-01,  3.4155e-01, -4.3627e-01],\n",
            "        [-4.1788e-01, -3.0955e-01, -2.6146e-01, -8.6882e-02,  9.4880e-01,\n",
            "          3.1482e-01,  1.9141e-01, -5.0657e-01,  4.7117e-01, -5.1703e-01,\n",
            "         -3.6046e-01,  6.6864e-01, -1.0337e+00, -2.5912e-01, -1.5632e-02,\n",
            "          1.9122e-01,  2.3790e-01, -2.1355e-01, -1.0182e+00],\n",
            "        [-9.4219e-01, -1.6838e-01,  4.4218e-01,  4.3326e-01,  1.3283e+00,\n",
            "         -4.8511e-01,  2.6559e-01, -2.8107e-01,  8.7956e-01, -7.0911e-01,\n",
            "         -7.1202e-01,  9.0781e-01, -2.6793e-01, -8.7234e-01,  2.8424e-01,\n",
            "          6.8851e-02,  1.0211e+00,  2.5770e-01, -2.6532e-01],\n",
            "        [-5.7655e-01, -4.2166e-01,  8.0122e-02,  4.6739e-01,  1.6028e+00,\n",
            "          9.5184e-03, -4.3359e-01, -4.4413e-01,  9.6957e-01, -2.3139e-01,\n",
            "         -6.9134e-01,  1.1826e+00, -4.2253e-02, -6.9650e-01, -6.4290e-01,\n",
            "          5.0912e-01,  7.9365e-01, -6.0274e-02, -2.3833e-01],\n",
            "        [-8.6995e-01, -4.9961e-01,  5.9873e-01, -8.7270e-02,  1.7313e+00,\n",
            "          4.2232e-02,  3.5454e-01, -6.8947e-01,  7.8154e-01, -4.6531e-01,\n",
            "         -1.2713e-01,  1.4748e+00, -5.4809e-01, -7.7298e-01,  2.6742e-01,\n",
            "          3.2713e-01,  3.3500e-01, -3.6505e-01, -8.4650e-01],\n",
            "        [-4.3121e-01, -5.8467e-01, -2.0245e-01,  3.0671e-01,  1.5039e+00,\n",
            "          6.2199e-02, -1.5253e-01, -5.7736e-01,  8.4319e-01, -3.4259e-01,\n",
            "         -1.0415e+00,  1.3984e+00, -8.7141e-01, -1.0187e-01, -2.9458e-02,\n",
            "          8.4458e-01,  8.6473e-01, -2.1860e-01, -1.1967e+00],\n",
            "        [-1.5754e-01, -4.4284e-02, -1.8811e-01,  5.5159e-01,  8.4418e-01,\n",
            "         -6.8834e-02, -3.9637e-02,  2.1166e-03,  7.2582e-01, -8.7296e-03,\n",
            "         -3.7219e-01,  8.7766e-01,  1.5107e-01, -4.3045e-01, -5.6767e-02,\n",
            "          2.2413e-01,  2.4286e-01, -1.0317e-01, -4.1023e-01],\n",
            "        [-5.1421e-01, -5.8254e-01, -2.9982e-01,  2.7874e-01,  1.3858e+00,\n",
            "          2.7311e-01, -3.5374e-01,  1.7901e-01,  1.3464e+00, -4.4110e-01,\n",
            "         -6.3059e-01,  1.2655e+00, -2.4182e-01, -8.2784e-01,  8.5667e-01,\n",
            "          6.8978e-01,  7.8217e-01,  1.0038e-01, -5.2764e-01],\n",
            "        [-7.4020e-01, -7.5758e-02,  8.0945e-02,  3.5143e-01,  1.4963e+00,\n",
            "          1.2061e-01,  1.2500e-01, -2.5242e-02,  6.3245e-01, -3.5236e-01,\n",
            "         -5.3904e-01,  9.4333e-01, -2.8696e-01, -1.4053e-01,  6.9848e-01,\n",
            "          5.3035e-01,  4.8094e-01,  5.6344e-01, -5.7194e-01],\n",
            "        [-3.8307e-01, -4.6650e-02,  3.7253e-01,  2.3179e-01,  1.5719e+00,\n",
            "          8.3870e-02, -1.0955e-01, -4.7218e-01,  6.8769e-01, -9.7978e-01,\n",
            "         -6.6858e-01,  1.4764e+00, -7.7086e-01, -1.3071e-01,  1.7774e-01,\n",
            "          3.0727e-01,  3.9486e-01,  5.4068e-01, -2.7268e-01],\n",
            "        [-8.9768e-01, -2.3519e-02,  5.1792e-01,  5.0947e-01,  1.1399e+00,\n",
            "         -3.0923e-01,  5.1127e-02, -4.4477e-03,  6.1352e-01, -2.5059e-01,\n",
            "         -3.7323e-01,  9.3939e-01, -5.7928e-01, -6.6119e-01,  4.7269e-01,\n",
            "          1.0800e-01,  9.0992e-01,  4.3219e-01, -3.5129e-01],\n",
            "        [-5.9199e-01, -2.7434e-01, -4.2343e-01,  6.5333e-01,  1.2356e+00,\n",
            "         -1.7421e-01,  1.6359e-01, -5.8578e-01,  1.0070e+00, -1.0725e-01,\n",
            "         -5.1196e-01,  1.2544e+00, -8.2316e-01, -4.1408e-01,  1.6674e-01,\n",
            "          4.0512e-01,  5.0411e-01, -2.5839e-02, -1.1162e+00],\n",
            "        [-9.5340e-01,  1.0043e-01, -2.8221e-01,  2.4725e-01,  1.1291e+00,\n",
            "         -2.7490e-01,  1.3397e-01, -5.4058e-01,  1.0783e+00, -2.7855e-01,\n",
            "         -2.2730e-01,  8.2989e-01, -7.5259e-01, -3.8780e-01,  6.7967e-01,\n",
            "          3.2224e-01,  1.9311e-01, -1.5764e-01, -1.5129e+00],\n",
            "        [-2.1721e-01, -1.8945e-01,  7.2208e-02, -1.9006e-01,  9.4516e-01,\n",
            "         -2.1073e-01,  5.4333e-02, -9.8310e-02,  6.9004e-01, -2.2675e-01,\n",
            "          9.0347e-02,  5.2474e-01, -1.3647e-01, -1.9563e-01,  2.2192e-01,\n",
            "          3.2744e-01,  3.7047e-01,  1.5587e-04, -4.8243e-01],\n",
            "        [-3.2710e-01, -4.2727e-02,  6.5236e-02,  1.5642e-01,  9.7349e-01,\n",
            "          6.1371e-02,  4.2307e-01, -1.1533e-01,  3.7688e-01, -3.7292e-01,\n",
            "         -7.0336e-01,  8.6844e-01, -6.4166e-01, -3.6540e-01,  7.5773e-01,\n",
            "          4.5736e-01,  2.5469e-01, -1.6605e-01, -3.9420e-01],\n",
            "        [-8.5414e-01,  4.9388e-02, -4.5534e-01,  7.3860e-02,  9.7410e-01,\n",
            "          3.5017e-01, -3.2485e-01, -5.0807e-01,  6.4870e-01, -5.0344e-01,\n",
            "         -8.7936e-01,  9.1653e-01, -3.9119e-01, -4.6732e-01,  1.7579e-01,\n",
            "          3.0971e-01,  5.6375e-01,  3.3704e-01, -5.7373e-01],\n",
            "        [-6.5638e-01, -1.8307e-01,  5.1168e-01,  9.7393e-02,  1.3512e+00,\n",
            "         -2.0078e-01, -1.5453e-02, -2.8241e-01,  1.0757e+00, -2.5733e-01,\n",
            "         -3.2890e-01,  8.8146e-01, -5.7073e-01, -3.3166e-01, -1.8198e-01,\n",
            "          4.2784e-01,  6.2335e-01,  3.7489e-01, -6.4880e-01],\n",
            "        [-7.3086e-01, -1.2526e-01, -1.7577e-01,  1.6564e-01,  1.4626e+00,\n",
            "          1.7983e-01, -9.8869e-02, -2.2291e-01,  1.1409e+00, -2.6348e-01,\n",
            "         -4.1252e-01,  1.1450e+00, -3.1936e-01, -6.9470e-01, -2.8671e-02,\n",
            "          1.9277e-01,  7.4849e-01, -4.3653e-02, -5.2101e-01],\n",
            "        [-8.4253e-01,  3.9736e-03,  3.4781e-01,  3.0648e-01,  1.3058e+00,\n",
            "         -3.0837e-01,  8.5036e-02, -1.8761e-01,  5.2136e-01, -5.0720e-01,\n",
            "         -1.9229e-01,  9.2068e-01, -6.1932e-01,  1.3091e-01, -7.6030e-02,\n",
            "          5.4407e-02,  3.5741e-01, -5.2952e-03, -3.5922e-01],\n",
            "        [-4.6422e-01, -1.9662e-01, -2.4232e-01,  2.2117e-01,  1.0775e+00,\n",
            "          1.0652e-01, -7.2957e-02,  7.4609e-02,  9.1699e-01, -3.7612e-01,\n",
            "         -6.6156e-01,  1.6375e+00, -8.3987e-01, -8.0595e-01,  1.2899e-01,\n",
            "          3.2943e-01,  3.0203e-01,  2.8861e-01, -2.3492e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-1.1964, -0.2019,  0.0689,  0.4290,  1.5590,  0.1415, -0.1693, -0.7504,\n",
            "          1.3395, -0.8855, -0.6102,  1.2250, -0.5607, -0.8688,  0.0428,  0.4757,\n",
            "          0.9453,  0.2294, -0.5691],\n",
            "        [-0.5203, -0.3375, -0.6015,  0.0067,  1.1851,  0.2220, -0.0353, -0.2938,\n",
            "          1.1272, -0.8214, -0.6166,  0.7231, -0.1720, -0.2788,  0.0724,  0.5578,\n",
            "          0.2649, -0.0311, -0.5229],\n",
            "        [-0.4381, -0.2803,  0.1111, -0.2774,  1.2614,  0.0158,  0.1956, -0.0304,\n",
            "          0.9534, -0.6449, -0.7858,  0.3798, -0.2456, -0.4796,  0.2507, -0.0791,\n",
            "          0.0994,  0.1920, -0.7868],\n",
            "        [-0.6649,  0.0066, -0.0121,  0.2575,  1.1918,  0.2829,  0.3290, -0.3980,\n",
            "          0.7317, -0.2388, -0.6012,  1.2543,  0.0099, -0.6394, -0.0144,  0.6066,\n",
            "          0.4581, -0.1528, -0.4322],\n",
            "        [-0.3161, -0.1614,  0.1162, -0.1617,  0.6744, -0.2916, -0.3629,  0.0143,\n",
            "          0.6279,  0.1932, -0.3544,  1.0216, -0.6827, -0.4153,  0.2142, -0.0538,\n",
            "          0.9321,  0.1892, -0.6430],\n",
            "        [-0.1296, -0.3797, -0.0630,  0.3242,  0.8285,  0.4513,  0.2160,  0.0532,\n",
            "          0.8579, -0.4626, -0.0746,  1.2559, -0.4812, -0.5297,  0.5826,  0.4137,\n",
            "          0.5907, -0.0339, -0.4230],\n",
            "        [-0.4968,  0.1550,  0.2183,  0.2065,  1.6316,  0.2436, -0.0088, -0.1594,\n",
            "          0.8063, -0.9469, -0.3948,  0.9573, -0.8298, -0.5859,  0.0767,  0.1242,\n",
            "          0.5658,  0.0221, -0.5605],\n",
            "        [-0.2446, -0.5000,  0.3327,  0.5022,  0.9657, -0.1200, -0.2961,  0.1611,\n",
            "          1.2176, -0.3039, -0.4957,  0.7088,  0.1085, -0.1939,  0.2797, -0.0839,\n",
            "          0.4159,  0.1503, -0.2875],\n",
            "        [-0.3457,  0.2247,  0.0680,  0.1528,  1.4923,  0.0794, -0.0316, -0.0852,\n",
            "          1.5730, -0.5526, -0.6235,  1.3201, -0.5696, -0.9990,  0.1817,  0.3408,\n",
            "          0.5144,  0.5611, -0.5120],\n",
            "        [-0.5520, -0.5938, -0.8050,  0.5773,  1.2774, -0.3831, -0.5364, -0.4677,\n",
            "          1.3575, -0.3327, -0.1313,  0.9142, -0.5653, -0.6827,  0.3903,  0.2501,\n",
            "          0.2306, -0.0621, -0.7936],\n",
            "        [-0.5662, -0.4861, -0.2332,  0.4366,  1.1384, -0.1352, -0.2506, -0.1590,\n",
            "          0.7511, -0.4507, -0.4410,  1.0158, -0.3734, -0.4821,  0.2011,  0.5324,\n",
            "          0.9131, -0.1550, -0.5437],\n",
            "        [-0.2241,  0.0806,  0.3816,  0.3819,  1.4047,  0.1034,  0.2252, -0.2172,\n",
            "          0.8029, -0.6715, -0.8411,  1.2207, -0.2620, -1.1533,  0.1307,  0.0905,\n",
            "          0.8852,  0.3086, -0.1503],\n",
            "        [-0.3302,  0.0487, -0.3386, -0.1393,  1.0411, -0.0900, -0.1524, -0.2633,\n",
            "          0.5512, -0.5321, -0.5160,  1.1747, -0.3785, -0.4882, -0.0053,  0.4308,\n",
            "          0.4435,  0.1893, -0.4895],\n",
            "        [-0.9157, -0.2677,  0.2026,  0.0145,  1.3551,  0.5866, -0.2269, -0.5728,\n",
            "          0.5674, -0.9111, -0.1203,  1.0809, -0.4861, -0.5996,  0.5962, -0.1418,\n",
            "          0.2750, -0.1275, -0.3885],\n",
            "        [-0.5653,  0.0266, -0.4113,  0.1671,  0.9794, -0.2647, -0.2845,  0.4702,\n",
            "          0.2808, -0.0598, -0.4656,  1.5434, -0.5255, -0.5071, -0.5390,  0.0283,\n",
            "          0.6255,  0.3506, -0.1160],\n",
            "        [-0.4989, -0.3252,  0.4868,  0.6776,  1.7411, -0.1625,  0.0517, -0.2981,\n",
            "          0.8699, -0.8400, -0.3554,  1.3953, -0.4467, -1.1158,  0.1964,  0.6056,\n",
            "          1.1127, -0.2693, -0.8217],\n",
            "        [-0.6369, -0.3294,  0.3843, -0.1200,  1.5068, -0.2998,  0.2672, -0.8532,\n",
            "          0.8554, -0.4388, -0.6498,  0.9380, -0.3891, -0.4045,  0.1171,  0.4786,\n",
            "          0.1859,  0.2511, -0.5144],\n",
            "        [-0.5735,  0.0853,  0.2771, -0.0454,  1.1318,  0.1052,  0.4910, -0.2698,\n",
            "          0.8487, -0.2008, -0.5066,  1.2828, -0.6790, -0.6398,  0.5479,  0.3267,\n",
            "          1.0297,  0.3414, -1.2754],\n",
            "        [-0.1220, -0.2189,  0.0023,  0.6387,  1.3407,  0.0452,  0.1220,  0.0123,\n",
            "          1.0181, -0.4871, -0.3543,  1.3455, -0.2017, -0.4771,  0.1351,  0.3178,\n",
            "          0.3512, -0.0186, -0.9155],\n",
            "        [-0.5320,  0.2683, -0.3866, -0.0736,  1.3819, -0.1342,  0.1585, -0.0488,\n",
            "          0.9003, -0.3671, -0.2274,  0.6264, -0.5475, -0.6926,  0.6255,  0.4184,\n",
            "          0.9182, -0.1465, -0.9199],\n",
            "        [-0.1412,  0.0102,  0.0209,  0.2798,  1.1764, -0.0043, -0.0363,  0.0108,\n",
            "          0.7283, -0.8415,  0.0627,  0.8153, -0.3260, -0.7392,  0.0736,  0.2027,\n",
            "          0.2940,  0.2424, -0.4433],\n",
            "        [-0.8709, -0.3328, -0.1432, -0.0806,  1.7203, -0.1367, -0.2696,  0.8479,\n",
            "          1.4576, -0.7205, -0.7258,  0.7355, -0.1300, -0.5557,  0.0411,  0.7720,\n",
            "          0.4635,  0.7459, -0.3986],\n",
            "        [-0.1271, -0.5237,  0.0182,  0.0566,  1.1292,  0.0809, -0.0219, -0.3997,\n",
            "          1.2862, -0.4013, -0.1123,  1.1910, -0.5122, -0.8677,  0.3798,  0.5788,\n",
            "          0.7719,  0.4416, -0.5684],\n",
            "        [-0.5585,  0.0720,  0.2411,  0.3578,  1.6609, -0.0618, -0.1431,  0.2423,\n",
            "          1.6365, -0.8619, -0.7190,  1.7247, -0.5849, -0.3277,  0.7722,  0.2619,\n",
            "          0.3683,  0.2183, -0.9665],\n",
            "        [-0.1390, -0.2420, -0.0088,  0.1942,  1.0335, -0.1451, -0.1120, -0.1528,\n",
            "          0.5870, -0.3452, -0.0802,  1.0867, -0.5170, -0.4779,  0.1343,  0.4300,\n",
            "          0.3562, -0.1599, -0.5229],\n",
            "        [ 0.1205, -0.1219, -0.0026,  0.3398,  1.3730, -0.2572, -0.1713,  0.0722,\n",
            "          0.7439, -0.5108, -0.7257,  0.8611, -0.7257, -0.5077,  0.1588,  0.1413,\n",
            "          1.1555, -0.1149, -0.5305],\n",
            "        [-0.6978, -0.0709,  0.0356,  0.3031,  1.3493, -0.1844, -0.6462,  0.1166,\n",
            "          1.0900, -0.2817, -0.6879,  1.5666, -0.7282, -0.6724, -0.0861,  0.4555,\n",
            "          0.6155,  0.0161, -0.3567],\n",
            "        [-0.3052, -0.1574, -0.2819,  0.0621,  1.1503,  0.1915, -0.0365,  0.0700,\n",
            "          1.1654, -0.7046, -0.8317,  0.7533, -0.2655, -0.8299,  0.2557,  0.1210,\n",
            "          0.4516,  0.2012, -0.4865],\n",
            "        [-0.4425, -0.1960, -0.0431,  0.3067,  1.3350, -0.3701, -0.5575, -0.4746,\n",
            "          0.9081, -0.5127, -0.9400,  0.8236,  0.0232, -0.6618,  0.0851,  0.0210,\n",
            "          0.2684, -0.3680, -0.4683],\n",
            "        [-0.1443, -0.3391, -0.0735,  0.5041,  1.1659,  0.0766, -0.2292, -0.3084,\n",
            "          1.0300,  0.0133, -0.9077,  1.1300, -0.4001, -0.2784, -0.0050,  0.3756,\n",
            "          0.7246,  0.1219, -0.4691],\n",
            "        [-0.4372, -0.1828, -0.1687, -0.0843,  1.8124, -0.2562, -0.1064, -0.0754,\n",
            "          1.0163, -0.0084, -0.4097,  1.9962,  0.0593, -0.3341,  0.4953,  0.0430,\n",
            "          0.6252,  0.2451, -0.3750],\n",
            "        [-0.1049, -0.4918, -0.0746,  0.1521,  1.3677, -0.4973,  0.0161, -0.4407,\n",
            "          1.3835, -0.6999, -0.7076,  0.4862, -0.7444, -1.0133,  0.2494,  0.2577,\n",
            "          0.6084,  0.1321, -0.6198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3432,  0.1339, -0.0283,  0.3556,  1.4153,  0.0580, -0.0563, -0.2113,\n",
            "          0.8244, -0.2949, -0.5512,  0.8203, -0.2147, -0.6212,  0.1294,  0.7596,\n",
            "          1.0250,  0.2376, -0.5707],\n",
            "        [-0.7016, -0.1010,  0.3405,  0.2791,  1.9151,  0.0399,  0.0195,  0.2573,\n",
            "          1.0123, -0.3732, -1.1441,  1.2902, -0.7902, -0.9132,  0.1995,  0.1947,\n",
            "          0.9765, -0.1394, -0.9827],\n",
            "        [-0.3373, -0.5831, -0.3706, -0.1137,  1.3691, -0.0361,  0.1932, -0.1390,\n",
            "          0.6983, -0.2945, -0.7900,  1.1110, -0.5785, -0.5237, -0.0270,  0.4397,\n",
            "          0.7821,  0.1659,  0.1206],\n",
            "        [-0.3699, -0.1285, -0.0254,  0.4477,  1.0128,  0.1107,  0.1624, -0.6660,\n",
            "          1.5347, -0.1772, -0.5958,  0.9519, -0.1309, -0.6684,  0.5424, -0.1289,\n",
            "          0.8887, -0.2275, -1.0740],\n",
            "        [-0.1379, -0.4748,  0.4569,  0.5706,  1.3021,  0.3115, -0.4399,  0.1531,\n",
            "          0.9561, -1.0714, -0.5035,  1.1735, -0.8702, -0.6447,  0.3021,  0.6352,\n",
            "          0.8233,  0.2193, -0.3724],\n",
            "        [-1.1527, -0.4851,  0.4977,  0.6524,  1.0744, -0.2346,  0.1071, -0.1965,\n",
            "          0.8295, -0.3561, -0.6312,  1.1535, -0.0349, -1.2523,  0.4610,  0.4230,\n",
            "          0.7112, -0.0962, -0.2184],\n",
            "        [-0.3768, -0.0258,  0.0139, -0.0216,  1.2341, -0.1610, -0.2043, -0.3616,\n",
            "          0.9681, -0.5927, -0.3421,  0.8471, -0.2737, -0.7154,  0.0859,  0.3924,\n",
            "          0.2440,  0.1894, -0.3854],\n",
            "        [-0.0715,  0.0267,  0.3932,  0.0953,  0.9358, -0.0069, -0.1401,  0.1569,\n",
            "          0.7080, -0.0433,  0.0196,  0.6802, -0.4766, -0.9774, -0.1602, -0.0343,\n",
            "          0.4524, -0.0993, -0.4135],\n",
            "        [-0.8129, -0.0550,  0.2851,  0.5089,  1.6178,  0.1817, -0.1289,  0.0167,\n",
            "          1.1893, -0.3655, -0.7728,  1.5907, -0.6468, -0.8278, -0.4016,  0.5028,\n",
            "          1.1940,  0.4537, -1.1766],\n",
            "        [-0.3261, -0.2248,  0.2103,  0.1571,  1.3185, -0.1999, -0.1011,  0.2958,\n",
            "          0.6962, -0.6032, -0.2382,  0.7374, -0.2637, -0.8123, -0.2352,  0.4465,\n",
            "          0.0820, -0.0379, -0.2123],\n",
            "        [-0.7604, -0.3061,  0.3398, -0.0308,  0.9996, -0.0341, -0.1968,  0.0360,\n",
            "          1.0646, -0.4217, -0.2698,  0.7380, -0.0771, -0.1577,  0.1179,  0.1428,\n",
            "          0.7857, -0.0314, -0.6086],\n",
            "        [-0.4879, -0.0279,  0.2342,  0.3532,  1.3953,  0.5385,  0.1407, -0.1983,\n",
            "          0.9233, -0.4567, -0.6114,  0.8247, -0.5056, -0.7829,  0.0292,  0.7919,\n",
            "          0.1836,  0.2371, -0.4963],\n",
            "        [-0.5124, -0.3999, -0.1833, -0.2522,  1.3080,  0.4782,  0.2736, -0.4716,\n",
            "          1.6250, -0.5968, -0.6830,  0.8562, -0.5110, -0.8635,  0.1498,  0.4234,\n",
            "          0.7164, -0.1797, -0.8779],\n",
            "        [-0.5733, -0.1009,  0.2647,  0.1846,  0.7581,  0.0063,  0.1460, -0.1497,\n",
            "          1.0333, -0.8774,  0.0088,  0.9310, -0.5595, -0.7698,  0.5622,  0.1964,\n",
            "          0.4758,  0.3659, -0.3557],\n",
            "        [-0.5182, -0.0831,  0.2165,  0.3978,  1.6813, -0.2919, -0.0836, -0.2828,\n",
            "          1.0508, -0.2589, -0.1466,  0.3600, -0.3610, -0.2214,  0.3782,  0.5069,\n",
            "          0.2314,  0.0938, -0.7736],\n",
            "        [-0.5901, -0.0130,  0.3134, -0.0125,  1.2109, -0.1397, -0.1215, -0.4845,\n",
            "          1.5684, -0.7596, -0.4666,  1.3210, -0.2761, -0.6819,  0.2186,  0.1934,\n",
            "          1.1121,  0.1506, -0.4330],\n",
            "        [-0.4298, -0.0206,  0.3624,  0.1040,  1.3110,  0.3134, -0.0647, -0.0416,\n",
            "          0.8636, -0.5857, -0.2457,  1.0314, -0.1398, -0.4084,  0.2268,  0.3348,\n",
            "          0.4257,  0.4060, -0.3270],\n",
            "        [-0.9262, -0.0735,  0.1976,  0.1741,  1.7253, -0.3472, -0.5324, -0.3698,\n",
            "          1.4489, -0.8077, -0.4871,  1.4304, -0.1030, -0.7583,  0.3967,  0.1976,\n",
            "          0.3815, -0.4268, -0.6904],\n",
            "        [-0.5996, -0.4447,  0.8178, -0.2181,  1.8147, -0.4186,  0.2845, -0.7662,\n",
            "          1.0350, -0.7042, -0.3969,  1.1276, -0.6511, -0.9410,  0.8138,  0.1048,\n",
            "          0.9493, -0.0530, -0.7521],\n",
            "        [-0.6672, -0.4750, -0.0611,  0.9634,  1.6955, -0.4763, -0.2532, -0.3577,\n",
            "          1.3505, -0.3483, -0.8240,  0.7613, -0.9069, -0.8944,  0.1980,  0.4168,\n",
            "          0.2303,  0.2438, -0.8891],\n",
            "        [-0.4618, -0.2305, -0.0693,  0.1479,  1.6879, -0.2022,  0.3297,  0.1056,\n",
            "          0.5649, -0.3004, -0.4905,  1.3810, -0.2929, -1.0431,  0.3373,  0.4824,\n",
            "          0.7116, -0.6704, -0.5687],\n",
            "        [-0.5977, -0.2309, -0.1228, -0.0107,  1.1706, -0.3264, -0.0425, -0.2170,\n",
            "          1.2885, -0.6984, -0.9618,  0.9122, -0.2993, -0.6983,  0.0644, -0.0097,\n",
            "          0.7626,  0.0845, -0.4663],\n",
            "        [-0.4342,  0.1146,  0.1827,  0.1471,  1.3335,  0.2168, -0.1662, -0.3499,\n",
            "          0.8245, -0.4488, -0.8367,  0.7024, -0.3086, -0.6699,  0.2978,  0.4320,\n",
            "          0.3517, -0.2883, -0.2495],\n",
            "        [-0.4205, -0.0759,  0.0520,  0.0027,  1.0933, -0.2204, -0.1846,  0.0088,\n",
            "          0.4513, -0.2199, -0.6705,  0.7174, -0.1375, -0.4287,  0.2232,  0.0184,\n",
            "          0.4898,  0.2880, -0.3994],\n",
            "        [-0.7258, -0.2438, -0.0030,  0.0341,  1.1940, -0.0920, -0.1030,  0.0553,\n",
            "          0.5728, -0.0499, -0.6473,  0.9042,  0.0621, -0.2972,  0.2394,  0.4104,\n",
            "          0.5455, -0.1118, -0.5787],\n",
            "        [-1.1815, -0.0785, -0.1611,  0.3973,  1.5629,  0.2067, -0.7041, -0.3871,\n",
            "          1.1749, -0.7376, -0.6206,  0.8416, -1.2151, -0.8760, -0.0283,  0.3354,\n",
            "          0.2594,  0.4517, -0.8254],\n",
            "        [-1.1022, -0.2419, -0.4132,  0.1666,  1.5375,  0.1180,  0.4567, -0.3266,\n",
            "          1.2768, -0.1806, -0.0697,  1.5403, -0.3236, -0.6622,  0.4187,  0.0642,\n",
            "          0.2742,  0.7947, -0.4373],\n",
            "        [-0.3646, -0.4831,  0.3624, -0.0453,  1.6854, -0.1373,  0.0983,  0.2690,\n",
            "          0.9938, -0.6048, -0.4201,  1.0362, -1.0524, -0.5606,  0.3538,  0.1925,\n",
            "          0.2483,  0.0752, -0.7825],\n",
            "        [-0.8248, -0.1908, -0.2562, -0.3124,  1.0297, -0.5982, -0.5109, -0.5325,\n",
            "          1.3597, -0.4009, -0.4283,  1.4078, -0.6656, -1.1551,  0.0783,  0.4359,\n",
            "          0.5627,  0.0610, -0.5147],\n",
            "        [-0.7352, -0.0249, -0.0138,  0.1015,  1.0517, -0.1141, -0.2219,  0.0273,\n",
            "          0.7154, -0.5997, -0.3793,  1.3019, -0.3122, -0.4527,  0.2425,  0.3205,\n",
            "          0.8424,  0.5681, -0.7436],\n",
            "        [-0.8788, -0.0301, -0.3266,  0.4761,  0.8360, -0.5592,  0.0073,  0.1355,\n",
            "          0.6210, -0.5045, -0.5013,  1.1534, -0.4288, -0.3050,  0.0968,  0.3154,\n",
            "          0.2049, -0.0165, -0.6102],\n",
            "        [-1.1058,  0.0440, -0.2982,  0.6297,  1.4540,  0.1396, -0.1375,  0.2883,\n",
            "          1.0864, -0.3270, -0.9342,  0.5813, -1.0884, -0.3705,  0.4568, -0.3580,\n",
            "          0.4993,  0.2391, -0.5172]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-4.1856e-01,  9.5283e-03,  6.7431e-02,  6.5805e-01,  1.7921e+00,\n",
            "          2.7850e-01,  1.7366e-01, -1.3348e-01,  1.6036e+00, -5.8351e-01,\n",
            "         -8.4956e-01,  5.3963e-01, -4.3661e-01, -1.3085e+00,  2.0354e-01,\n",
            "          1.5912e-01,  7.9847e-01,  3.6967e-01, -6.4315e-01],\n",
            "        [-5.2067e-01,  5.8645e-02, -1.2075e-01,  1.4880e-01,  1.4416e+00,\n",
            "         -4.5005e-01, -3.3519e-01, -2.0435e-01,  1.0126e+00, -4.3210e-01,\n",
            "         -4.1293e-01,  1.2242e+00, -8.9360e-01, -7.1564e-01,  3.6736e-02,\n",
            "          8.8411e-02,  7.6648e-01,  2.6359e-01, -2.6469e-01],\n",
            "        [-4.9211e-01,  2.9020e-02, -2.0206e-01,  9.9943e-02,  5.5455e-01,\n",
            "         -2.5167e-01,  9.3284e-02, -3.3825e-02,  1.4617e+00, -9.1550e-01,\n",
            "         -1.7996e-01,  1.3029e+00, -6.5129e-02, -8.0167e-01, -1.6587e-01,\n",
            "          3.1482e-01,  3.1717e-01,  1.1464e-01, -7.4901e-01],\n",
            "        [-6.8450e-01, -1.1843e-02,  4.9603e-02,  7.9545e-02,  9.1690e-01,\n",
            "         -2.5798e-01, -1.2584e-01,  4.7934e-01,  7.8087e-01, -6.2787e-01,\n",
            "         -3.9699e-01,  1.4261e+00, -8.2908e-01, -6.0865e-01,  6.5341e-01,\n",
            "          1.7432e-01,  4.8090e-01, -1.5486e-01, -6.7164e-01],\n",
            "        [-7.4347e-01, -1.8012e-02,  3.8071e-01, -1.8824e-01,  1.4101e+00,\n",
            "         -1.4468e-01,  1.3229e-02, -2.7284e-01,  1.4145e+00,  1.0206e-03,\n",
            "         -4.8823e-01,  1.1727e+00, -9.0138e-01, -1.2178e+00,  3.2390e-01,\n",
            "          3.0653e-01,  5.8044e-01, -4.4818e-02, -6.9718e-01],\n",
            "        [-3.5192e-01, -1.7981e-01,  1.1086e-01,  3.3974e-01,  9.1259e-01,\n",
            "         -3.0968e-01, -2.8249e-01,  4.7300e-02,  1.2544e+00, -2.0230e-01,\n",
            "         -7.8057e-01,  1.6883e+00, -7.4413e-01, -4.8308e-01,  3.1429e-01,\n",
            "          5.1738e-01,  4.1673e-01,  3.3214e-02, -7.9333e-01],\n",
            "        [-6.8854e-01, -7.0196e-02, -3.6124e-02,  6.6992e-01,  1.5149e+00,\n",
            "          1.7045e-03, -3.5726e-01, -2.9226e-01,  1.1587e+00, -4.8846e-01,\n",
            "         -5.3181e-02,  1.2888e+00, -6.5470e-01, -5.9898e-01,  3.3860e-01,\n",
            "          3.4008e-01,  7.0690e-01,  4.3806e-01, -8.0238e-01],\n",
            "        [-3.9330e-01,  1.2754e-01,  2.4863e-01,  6.8729e-01,  9.4451e-01,\n",
            "          2.6667e-01,  3.6253e-02, -2.7835e-01,  1.1128e+00, -3.9045e-01,\n",
            "         -4.8816e-01,  1.0387e+00, -8.7696e-01, -5.9804e-01,  2.4427e-01,\n",
            "          1.2862e-01,  4.9355e-01, -4.6354e-02, -6.6068e-01],\n",
            "        [-3.7981e-01,  2.3376e-01, -1.2901e-01, -5.4068e-02,  1.3676e+00,\n",
            "         -3.3511e-01, -1.4328e-01, -2.1439e-02,  9.8209e-01, -8.7975e-01,\n",
            "         -4.9237e-01,  9.6209e-01, -6.4718e-01, -8.6932e-01,  4.7492e-01,\n",
            "          9.5929e-02,  5.3299e-01, -2.8028e-02, -5.7437e-01],\n",
            "        [-5.1777e-01, -4.9856e-01, -3.5731e-01,  2.8035e-01,  1.6026e+00,\n",
            "          1.0579e-01, -1.0015e-01,  4.2870e-01,  8.0049e-01, -6.2073e-01,\n",
            "         -4.6543e-01,  9.8773e-01, -6.8121e-01, -5.9144e-01,  2.4396e-01,\n",
            "          8.0907e-02,  4.4021e-01,  3.1320e-01, -2.0549e-01],\n",
            "        [-7.4326e-01, -3.2817e-01,  2.2716e-01, -1.9587e-01,  1.7688e+00,\n",
            "         -5.9777e-01,  3.5366e-01, -2.2911e-01,  1.6463e+00, -3.2731e-01,\n",
            "         -9.4046e-01,  1.6581e+00, -7.7261e-01, -7.7454e-01,  2.1200e-01,\n",
            "          3.4786e-01,  7.8001e-01,  2.3174e-02, -7.4462e-01],\n",
            "        [-3.4106e-01,  2.3276e-01,  1.0165e-01,  3.3212e-01,  1.5737e+00,\n",
            "          2.8920e-01,  1.5876e-02, -2.6060e-01,  9.0978e-01, -4.4372e-01,\n",
            "         -5.3022e-01,  9.3661e-01, -6.3721e-01, -5.5141e-01, -2.1212e-01,\n",
            "          4.5934e-01,  5.1627e-01, -2.0344e-01, -5.3455e-01],\n",
            "        [-4.3481e-01, -5.2234e-01, -4.7983e-02,  4.5790e-01,  9.7401e-01,\n",
            "         -3.4240e-01, -8.7256e-02, -5.0485e-02,  1.3657e+00, -8.3958e-01,\n",
            "         -6.5703e-01,  1.2673e+00, -7.1572e-01, -3.5320e-01, -8.6046e-02,\n",
            "         -3.5840e-02,  8.9820e-01,  4.0121e-01, -1.0966e+00],\n",
            "        [-2.8182e-01, -2.0970e-01,  2.0629e-01,  6.9070e-02,  1.3258e+00,\n",
            "         -4.1767e-01, -2.3662e-01,  2.2827e-01,  7.1670e-01, -2.7673e-01,\n",
            "         -5.2344e-01,  1.5024e+00, -6.2259e-01, -3.6380e-01,  6.1205e-01,\n",
            "          1.4826e-01,  3.0904e-01,  1.5479e-01, -8.7687e-01],\n",
            "        [-5.1928e-02, -1.7344e-01, -1.1704e-02, -1.8576e-01,  3.1939e-01,\n",
            "         -7.7625e-02,  3.0844e-01,  1.2980e-02,  5.8224e-01, -1.6521e-01,\n",
            "         -3.6066e-01,  2.9211e-01, -1.9994e-01, -4.3861e-01,  1.3387e-01,\n",
            "          3.0211e-02,  1.2377e-01,  1.7866e-01, -1.5551e-01],\n",
            "        [-4.4088e-01, -4.4504e-01, -2.4693e-02,  5.7321e-01,  1.3677e+00,\n",
            "          4.4266e-01,  5.4252e-02,  3.8528e-01,  1.5304e+00, -1.1360e+00,\n",
            "         -7.6721e-01,  1.4857e+00, -1.5444e-01, -9.4079e-01,  4.1389e-01,\n",
            "          1.6915e-01,  6.9444e-01,  1.4512e-01, -9.3294e-01],\n",
            "        [-5.1339e-01, -3.1339e-01,  3.4114e-01,  7.8661e-02,  1.5169e+00,\n",
            "          1.9994e-01, -5.3825e-01, -4.0833e-01,  1.2633e+00, -6.3616e-01,\n",
            "         -2.7706e-01,  1.2460e+00, -3.6505e-01, -9.6798e-01,  3.6649e-01,\n",
            "          3.5459e-01,  4.2647e-01,  1.4327e-01, -3.7964e-01],\n",
            "        [-8.0794e-01,  8.7937e-02,  2.1668e-01,  2.2151e-01,  1.1700e+00,\n",
            "         -2.0485e-02,  5.1138e-02,  8.7635e-02,  8.8984e-01, -4.5597e-01,\n",
            "         -7.3785e-01,  1.0512e+00, -3.5109e-01, -5.1815e-01,  2.9895e-01,\n",
            "         -2.3928e-02,  5.6705e-01,  2.8959e-01, -7.6009e-01],\n",
            "        [-8.3911e-01, -3.6495e-01,  4.1636e-01, -2.4094e-01,  1.2638e+00,\n",
            "         -1.9502e-01,  5.5908e-02,  3.5543e-01,  8.8571e-01, -8.7986e-01,\n",
            "         -4.7364e-01,  1.4283e+00, -5.9492e-01, -6.4174e-01,  1.4526e-01,\n",
            "          2.1656e-01,  8.6957e-01, -7.3778e-02, -4.6772e-01],\n",
            "        [-2.8647e-01, -5.6090e-01,  7.2205e-02,  3.8926e-02,  1.0685e+00,\n",
            "         -1.7757e-01, -3.0338e-01, -9.6977e-02,  8.0710e-01, -2.2137e-01,\n",
            "         -4.6970e-01,  1.3090e+00, -6.0722e-01, -9.3089e-01,  3.2888e-01,\n",
            "          4.7554e-01,  6.0156e-01,  5.4199e-01, -2.0316e-01],\n",
            "        [-6.5515e-01, -6.7070e-02, -2.1334e-01,  8.0383e-01,  2.0032e+00,\n",
            "         -4.5719e-01, -2.4185e-01,  3.6821e-01,  1.4765e+00, -4.4251e-01,\n",
            "         -3.9611e-01,  1.4791e+00, -5.2674e-01, -7.5295e-01,  4.6772e-01,\n",
            "          5.7117e-02,  4.3684e-01, -1.1484e-01, -3.9097e-01],\n",
            "        [-2.4696e-01,  8.1452e-03,  4.0799e-01,  3.4343e-01,  1.3315e+00,\n",
            "         -5.6477e-02,  8.9796e-02, -2.6011e-01,  7.6942e-01, -9.2844e-01,\n",
            "         -3.0987e-01,  8.5917e-01, -6.3935e-01, -8.2486e-01,  7.2057e-02,\n",
            "          1.5298e-01,  1.2577e-01,  1.0871e-01, -9.3222e-01],\n",
            "        [-6.4704e-01, -1.2549e-01,  2.9201e-01,  3.6863e-01,  1.2422e+00,\n",
            "         -9.6112e-02,  1.6004e-01,  2.4769e-01,  1.3371e+00, -1.2219e-01,\n",
            "         -1.0044e+00,  1.6475e+00, -6.3865e-01, -7.6900e-01,  2.0086e-02,\n",
            "          4.0000e-01,  1.0343e+00,  6.1064e-01, -6.5347e-01],\n",
            "        [-4.6400e-01, -5.8185e-02,  4.5598e-01,  3.6975e-01,  1.1348e+00,\n",
            "         -1.3648e-01, -1.1462e-01,  3.3361e-02,  1.0660e+00, -3.7137e-01,\n",
            "         -3.4737e-01,  1.1435e+00, -6.8631e-01, -8.4411e-01,  3.3408e-01,\n",
            "          2.0275e-01,  6.2887e-01, -3.2046e-01, -6.3568e-01],\n",
            "        [-2.2910e-01,  3.5338e-01,  1.9966e-01,  6.1394e-01,  1.3863e+00,\n",
            "         -2.4690e-01, -2.0264e-01, -5.0163e-01,  1.6622e+00, -5.3273e-01,\n",
            "         -8.8708e-01,  1.3000e+00, -5.6018e-01, -1.0948e+00,  3.1504e-02,\n",
            "          4.3919e-01,  4.8052e-01,  2.2843e-01, -8.2744e-01],\n",
            "        [-7.2749e-01, -1.4596e-01, -8.8535e-02, -2.7403e-01,  1.4721e+00,\n",
            "         -2.0038e-01, -3.3129e-01, -1.9507e-01,  1.2019e+00, -8.8534e-01,\n",
            "         -1.0789e+00,  1.5846e+00, -1.0479e+00, -1.0561e+00,  1.7343e-01,\n",
            "          5.3026e-02,  7.4938e-01, -2.9621e-02, -1.1505e+00],\n",
            "        [-2.6963e-01, -1.6431e-01,  1.7410e-01,  3.6952e-01,  1.0813e+00,\n",
            "         -2.6937e-01, -2.3107e-01, -3.7249e-01,  9.1767e-01, -9.2553e-02,\n",
            "         -5.8818e-01,  1.0416e+00, -3.2132e-01, -9.2709e-01,  3.0519e-01,\n",
            "          1.7694e-01,  2.1382e-01,  2.4899e-01, -7.2386e-01],\n",
            "        [-8.1364e-01, -7.1461e-01,  2.5342e-01, -7.9675e-02,  1.5567e+00,\n",
            "         -5.0519e-02, -1.8589e-01, -2.1671e-01,  1.0175e+00, -6.5222e-01,\n",
            "         -3.9014e-01,  1.5823e+00, -6.5808e-01, -5.2426e-01,  5.4882e-01,\n",
            "          2.2169e-01,  4.7119e-01,  3.0108e-01, -4.7089e-01],\n",
            "        [-8.0772e-01, -5.2680e-01, -1.0755e-01,  4.9653e-02,  1.9853e+00,\n",
            "         -1.7807e-01,  1.3146e-01, -4.9191e-01,  1.2080e+00, -1.0646e+00,\n",
            "         -6.5810e-01,  1.1738e+00, -6.1594e-01, -1.3579e+00,  6.1243e-01,\n",
            "          4.1545e-01, -4.2742e-02, -1.5081e-01, -6.0881e-01],\n",
            "        [-2.3819e-01,  1.3950e-01, -2.5050e-01,  3.3517e-01,  9.5658e-01,\n",
            "          8.1357e-02,  2.6367e-01, -2.2566e-01,  1.0323e+00, -4.4174e-01,\n",
            "         -2.0290e-01,  7.7311e-01, -5.1306e-01, -6.1674e-01,  4.4228e-01,\n",
            "          1.1863e-01,  6.0258e-01,  1.1508e-01, -5.5463e-01],\n",
            "        [-9.9104e-01,  2.5733e-01, -1.1369e-01,  7.2828e-02,  1.1453e+00,\n",
            "         -1.6801e-02,  3.2859e-01,  1.7145e-01,  7.3176e-01, -8.1533e-01,\n",
            "         -2.7142e-01,  1.2697e+00, -7.9586e-01, -8.7221e-01,  7.3813e-02,\n",
            "          1.1527e-02,  9.7781e-01, -3.8578e-01, -4.8594e-01],\n",
            "        [-5.5645e-01, -1.7103e-02, -1.6636e-01,  4.4563e-01,  1.3410e+00,\n",
            "         -2.0905e-01, -4.1726e-01, -3.7560e-01,  9.0307e-01, -3.2184e-01,\n",
            "         -3.4422e-01,  9.2715e-01, -8.6783e-01, -1.0695e+00, -1.0071e-01,\n",
            "          5.7244e-01,  4.6929e-01,  7.3211e-01, -7.4485e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-9.1789e-01, -1.3766e-01, -2.0363e-01,  4.2998e-01,  1.3057e+00,\n",
            "         -1.9963e-01, -1.2739e-01, -7.9969e-02,  8.8139e-01,  3.0621e-02,\n",
            "         -6.1576e-01,  1.4731e+00, -9.8067e-01, -8.8988e-01,  2.6352e-01,\n",
            "          1.9737e-01,  4.5548e-01,  6.0919e-02, -4.5084e-01],\n",
            "        [-3.4554e-01,  4.4333e-01,  1.9634e-01,  5.6303e-01,  1.4154e+00,\n",
            "         -2.7542e-01, -1.3144e-01,  3.2553e-01,  9.9668e-01, -8.1584e-01,\n",
            "         -3.1277e-01,  1.1740e+00, -7.7752e-01, -1.5162e+00,  2.3245e-01,\n",
            "          4.5926e-01,  9.2941e-01,  9.3449e-02, -7.2546e-01],\n",
            "        [-7.3963e-01,  1.5003e-02,  1.4927e-01, -2.0381e-01,  9.3009e-01,\n",
            "          1.0955e-02,  9.7100e-02, -2.0523e-01,  1.4261e+00, -4.0836e-01,\n",
            "         -9.4977e-02,  1.2151e+00, -3.7108e-01, -9.1604e-01,  2.3252e-01,\n",
            "         -1.6510e-01,  8.0014e-02,  4.6904e-02, -8.4628e-01],\n",
            "        [-6.3753e-01, -2.7766e-01,  5.1374e-02,  7.9989e-03,  1.2415e+00,\n",
            "          9.7237e-02, -7.3495e-02, -2.4662e-01,  9.2699e-01, -4.2072e-01,\n",
            "         -6.7553e-01,  1.3594e+00, -7.4875e-01, -7.6690e-01,  4.5010e-01,\n",
            "         -1.0754e-02,  5.8794e-01,  1.8980e-01, -7.3864e-01],\n",
            "        [-8.0504e-01, -6.9528e-01,  4.1312e-02,  1.0423e-01,  1.5885e+00,\n",
            "          1.8443e-01,  8.2444e-05, -3.2686e-01,  1.3748e+00, -1.0400e+00,\n",
            "         -1.2068e+00,  1.6027e+00, -8.0825e-01, -4.9552e-01,  5.7999e-02,\n",
            "          2.1013e-01,  1.0755e+00,  1.8954e-01, -5.7722e-01],\n",
            "        [-5.6309e-01, -2.8762e-01, -2.4116e-01,  3.6769e-01,  1.3244e+00,\n",
            "          3.8616e-01, -2.5837e-01, -1.5236e-01,  4.9393e-01, -6.0383e-01,\n",
            "         -1.6821e-01,  1.1881e+00, -4.1631e-01, -3.5515e-01,  1.8409e-01,\n",
            "         -2.2445e-01,  3.8530e-01, -2.2458e-01, -6.4766e-01],\n",
            "        [-6.6198e-01,  3.1358e-01, -1.9285e-01,  2.5798e-01,  1.5250e+00,\n",
            "         -4.4204e-01, -2.0753e-01,  1.2298e-01,  1.3238e+00, -2.2290e-01,\n",
            "         -6.1875e-01,  1.2348e+00, -2.8945e-01, -7.8747e-01,  2.3567e-01,\n",
            "          5.4955e-01,  4.8313e-01,  9.1082e-02, -6.6431e-01],\n",
            "        [-6.8765e-01, -3.1676e-01, -2.4882e-01,  5.9246e-01,  1.5198e+00,\n",
            "          2.5381e-01,  1.2978e-01,  3.9849e-02,  1.1817e+00, -7.8155e-01,\n",
            "         -6.5733e-01,  1.2851e+00, -8.5676e-01, -9.1379e-01,  3.3696e-01,\n",
            "         -1.7684e-01,  8.8705e-01,  2.4773e-01, -4.4805e-01],\n",
            "        [-5.0574e-01, -1.1189e-01,  2.0851e-01,  4.6617e-01,  1.5609e+00,\n",
            "         -1.9126e-01, -1.8230e-01,  6.4028e-03,  1.4920e+00, -5.5616e-01,\n",
            "         -1.2934e+00,  1.7913e+00, -5.8220e-01, -9.0269e-01,  1.2286e-01,\n",
            "          4.5590e-01,  9.4623e-01,  3.1524e-02, -6.5573e-01],\n",
            "        [-5.2788e-01, -3.2737e-01, -1.3594e-01,  1.4857e-01,  1.4439e+00,\n",
            "         -3.7111e-01,  1.3627e-01,  1.1157e-01,  1.1347e+00, -2.3465e-01,\n",
            "         -5.3242e-01,  9.8932e-01, -4.8174e-02, -6.8546e-01,  2.1396e-01,\n",
            "          1.9077e-01,  6.3105e-01, -3.7240e-01, -7.4596e-01],\n",
            "        [-3.9853e-01, -2.7488e-01, -4.2477e-02,  7.4677e-01,  1.7890e+00,\n",
            "          2.3906e-01, -5.9131e-01, -3.3757e-01,  1.0708e+00, -1.1885e+00,\n",
            "         -8.5111e-01,  1.1315e+00, -3.0561e-01, -7.8080e-01,  2.7372e-01,\n",
            "          4.5759e-01,  6.9364e-01, -1.1223e-01, -7.3242e-01],\n",
            "        [-8.9944e-01, -3.6468e-01,  9.1071e-02,  2.3484e-01,  1.7382e+00,\n",
            "         -5.3524e-02, -3.7903e-01, -6.2295e-02,  1.3287e+00, -8.2307e-01,\n",
            "         -5.9855e-01,  1.5452e+00, -4.3460e-01, -9.5962e-01,  7.7573e-01,\n",
            "          4.0896e-02,  1.0477e+00,  1.2281e-02, -7.3262e-01],\n",
            "        [-9.6450e-01, -4.4273e-01,  9.8368e-02,  5.2206e-01,  1.7751e+00,\n",
            "         -9.6745e-02, -3.7408e-02, -3.3807e-01,  1.4227e+00, -4.2337e-01,\n",
            "         -7.4309e-01,  1.8577e+00, -5.1364e-01, -7.5779e-01,  6.2977e-01,\n",
            "          6.5568e-01,  8.5656e-01,  5.3891e-01, -1.3180e+00],\n",
            "        [-7.1434e-01, -5.5131e-01, -2.9136e-01,  3.2989e-02,  1.2094e+00,\n",
            "          3.1664e-01,  2.0749e-01, -5.2066e-02,  1.2833e+00, -3.7697e-01,\n",
            "         -6.7402e-01,  1.3641e+00, -1.1132e+00, -1.0085e+00,  1.0049e-01,\n",
            "          1.0904e-01,  9.1578e-02, -1.6052e-01, -4.2984e-01],\n",
            "        [-1.9309e-01,  4.8825e-01,  3.3893e-01, -7.2374e-02,  1.2600e+00,\n",
            "          1.7884e-01, -3.9337e-01,  4.0804e-01,  1.3330e+00, -2.1874e-01,\n",
            "         -9.8293e-01,  1.9951e+00, -2.9200e-01, -8.4953e-01,  2.0708e-01,\n",
            "          1.2798e-01,  1.6022e-01,  2.0871e-01, -1.1143e+00],\n",
            "        [-4.6561e-01, -1.3133e-01,  4.1511e-01,  5.4923e-01,  9.4499e-01,\n",
            "         -3.1151e-01, -1.5714e-01, -4.9863e-02,  1.1362e+00, -8.3824e-01,\n",
            "         -3.3674e-01,  9.9671e-01, -3.7579e-01, -3.4669e-01,  3.7546e-01,\n",
            "          7.9246e-01,  1.0214e-01, -7.8264e-02, -2.2352e-01],\n",
            "        [-5.6488e-01, -2.8663e-01, -2.8120e-02,  4.6912e-01,  1.0779e+00,\n",
            "          1.0586e-01, -6.9320e-01,  2.0781e-02,  8.5769e-01, -5.6006e-01,\n",
            "         -6.5749e-01,  1.2215e+00, -6.1175e-01, -1.1636e+00,  3.5281e-01,\n",
            "          3.8210e-01,  5.8695e-01, -2.4342e-01, -7.6809e-01],\n",
            "        [-1.8515e-01, -4.6256e-01, -1.5332e-01,  9.8779e-02,  1.1844e+00,\n",
            "          9.7193e-02, -4.7093e-01,  4.4409e-02,  6.9738e-01, -1.8387e-01,\n",
            "         -5.1863e-01,  1.0995e+00, -2.7032e-01, -5.4050e-01, -6.8895e-02,\n",
            "         -2.4320e-05,  3.9043e-01, -8.2923e-02, -1.8199e-01],\n",
            "        [-6.2125e-01, -7.1422e-02,  1.0103e-01, -1.1899e-01,  1.2206e+00,\n",
            "         -2.5188e-02, -2.7832e-01,  2.4534e-01,  8.7404e-01, -6.4167e-01,\n",
            "         -6.2370e-01,  1.5350e+00, -1.2969e-01, -1.2785e+00,  6.1167e-01,\n",
            "          1.8892e-01,  1.1044e+00,  2.6288e-01, -4.8960e-01],\n",
            "        [-3.0801e-01,  1.2078e-01, -5.6473e-02,  5.0150e-01,  7.7471e-01,\n",
            "         -1.2259e-01,  6.8005e-02, -2.0589e-01,  1.1922e+00, -4.8064e-01,\n",
            "         -6.1084e-01,  1.0750e+00, -4.9426e-01, -7.6653e-01,  5.0491e-01,\n",
            "         -4.4358e-01,  8.1565e-01, -2.2444e-01, -1.2261e+00],\n",
            "        [-5.5479e-01, -6.1301e-02, -9.3356e-02, -1.6230e-01,  1.0264e+00,\n",
            "         -1.1470e-01,  2.8668e-01,  2.7788e-01,  1.7327e+00, -1.4267e-01,\n",
            "         -5.2119e-01,  1.4748e+00, -1.0620e+00, -5.9039e-01,  4.7833e-01,\n",
            "         -1.0016e-01,  8.3443e-01,  4.4079e-01, -4.4250e-01],\n",
            "        [-4.9666e-02,  2.4392e-02,  9.2879e-02, -9.1051e-02,  7.7011e-01,\n",
            "         -2.4544e-01,  4.4649e-02, -9.6852e-02,  1.6112e+00, -8.5399e-01,\n",
            "         -4.9774e-01,  8.5218e-01, -5.3113e-01, -3.0358e-01, -4.7287e-01,\n",
            "          2.1157e-01,  4.5422e-01, -3.0901e-01, -6.2520e-01],\n",
            "        [-4.3219e-01, -2.1846e-01,  3.8929e-01,  4.6034e-01,  1.0702e+00,\n",
            "         -4.0041e-01,  1.5661e-01,  1.7280e-02,  1.1779e+00, -6.3743e-01,\n",
            "         -7.6360e-01,  1.4688e+00, -4.0256e-01, -6.9238e-01,  2.9039e-01,\n",
            "          4.2864e-01,  6.0406e-01,  1.1232e-01, -6.9317e-01],\n",
            "        [-5.5075e-01, -1.8497e-01,  1.0593e-01,  4.9693e-01,  1.4452e+00,\n",
            "         -8.8934e-02, -1.9197e-01, -2.2775e-01,  1.0818e+00, -6.1072e-01,\n",
            "         -4.3942e-01,  1.2462e+00, -7.4687e-01, -4.8996e-01,  3.7260e-01,\n",
            "          3.8324e-01,  3.1079e-01,  2.5777e-01, -1.2616e+00],\n",
            "        [-6.8877e-02,  1.0218e-02,  4.4409e-01,  4.3396e-02,  1.2751e+00,\n",
            "         -1.5354e-01, -6.8050e-02,  1.4664e-01,  1.3203e+00, -5.4442e-01,\n",
            "         -5.2150e-01,  9.0345e-01, -5.4031e-01, -7.2820e-01,  4.0382e-01,\n",
            "          1.9937e-01,  4.6091e-01,  3.5246e-01, -2.5584e-01],\n",
            "        [-6.7163e-01, -1.1645e-01, -1.6060e-02,  1.7108e-01,  1.6389e+00,\n",
            "          3.9865e-03, -3.3816e-01, -6.1594e-02,  1.0638e+00, -8.0131e-01,\n",
            "         -4.1722e-01,  1.1499e+00, -4.9662e-01, -4.6853e-01,  4.1839e-01,\n",
            "          6.8259e-01,  5.4373e-01,  1.2181e-01, -9.5682e-01],\n",
            "        [-5.7809e-01, -4.5798e-01,  2.9748e-01,  2.5937e-01,  1.0810e+00,\n",
            "         -1.4389e-01,  2.8502e-02, -2.2818e-01,  9.3479e-01, -5.0151e-01,\n",
            "         -4.8100e-01,  1.3763e+00, -6.7004e-01, -8.3715e-01,  8.4613e-02,\n",
            "          3.6169e-01,  3.8447e-02, -3.4713e-02, -8.7631e-01],\n",
            "        [-1.2356e+00,  2.8388e-01,  3.2582e-01,  3.6668e-01,  2.2189e+00,\n",
            "         -7.7368e-02,  8.5100e-02, -2.6171e-01,  1.3842e+00, -8.8585e-01,\n",
            "         -7.1916e-01,  1.6910e+00, -7.1292e-01, -7.6839e-01,  2.1808e-01,\n",
            "          3.7185e-01,  5.5726e-01, -3.3181e-01, -6.8061e-01],\n",
            "        [-5.6775e-01, -9.3396e-01,  8.0198e-02,  1.2417e-02,  1.3304e+00,\n",
            "         -9.9949e-02, -3.4356e-01, -4.0657e-01,  1.5316e+00, -6.7308e-01,\n",
            "         -1.4606e+00,  2.1978e+00, -2.1621e-01, -1.1452e+00,  5.5945e-01,\n",
            "         -1.4888e-01,  1.0192e+00,  5.0264e-01, -8.0019e-01],\n",
            "        [-8.9324e-02,  2.0817e-01,  4.1562e-01,  1.4181e-01,  1.5484e+00,\n",
            "         -1.1343e-01, -1.7734e-02, -2.8799e-01,  1.1522e+00, -5.0072e-01,\n",
            "          2.0919e-01,  9.8007e-01, -7.7298e-01, -6.4274e-01,  1.6044e-01,\n",
            "          6.0747e-01,  6.0529e-01,  1.6689e-01, -5.7710e-01],\n",
            "        [-6.9519e-01, -4.3775e-01,  4.7666e-01,  2.5887e-01,  1.5239e+00,\n",
            "         -1.4653e-02, -1.0365e-01, -9.3365e-02,  9.7521e-01, -5.1651e-01,\n",
            "         -5.2229e-01,  1.3095e+00, -8.1437e-01, -3.3326e-01,  1.3397e-01,\n",
            "         -2.3328e-01,  5.0103e-01,  1.2429e-01, -7.4862e-01],\n",
            "        [-6.2031e-01, -4.8784e-01, -2.9817e-01,  4.7778e-01,  2.1389e+00,\n",
            "          3.2502e-01, -2.8820e-01, -2.2941e-01,  1.5962e+00, -7.5160e-01,\n",
            "         -6.4555e-01,  1.2960e+00, -1.2368e+00, -6.3790e-01,  4.3495e-01,\n",
            "          1.2096e-01,  5.9684e-01,  3.6574e-01, -8.3465e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train and evaluate\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_ft, hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdataloaders_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mis_inception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_ft\u001b[38;5;241m.\u001b[39mstate_dict(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[55], line 24\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[0;32m     21\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[0;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[1;32mIn[22], line 28\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     25\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 28\u001b[0m   image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\functional.py:167\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[0;32m    166\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[1;32m--> 167\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    170\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\PIL\\Image.py:721\u001b[0m, in \u001b[0;36mImage.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m--> 721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ArrayData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft,\n",
        "                             dataloaders_dict,\n",
        "                             criterion,\n",
        "                             optimizer_ft,\n",
        "                             num_epochs=num_epochs,\n",
        "                             is_inception=True)\n",
        "\n",
        "torch.save(model_ft.state_dict(),'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4ZKGtGrWCEfaRDBobEgeQJmtdJIFobi\n",
            "To: c:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\data\\aerial_data\\test_labels.npy\n",
            "100%|██████████| 38.9k/38.9k [00:00<00:00, 2.42MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-01C3LjzGSz7QGzvharc52yZRwEgMzni\n",
            "From (redirected): https://drive.google.com/uc?id=1-01C3LjzGSz7QGzvharc52yZRwEgMzni&confirm=t&uuid=f9c3ae1e-174b-4b63-bf67-abcafe428388\n",
            "To: c:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\data\\aerial_data\\test_images.npy\n",
            "100%|██████████| 170M/170M [00:21<00:00, 7.83MB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'../../data/aerial_data/test_images.npy'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download(r'https://drive.google.com/file/d/1-4ZKGtGrWCEfaRDBobEgeQJmtdJIFobi/view?usp=drive_link', r'../../data/aerial_data/test_labels.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1-01C3LjzGSz7QGzvharc52yZRwEgMzni/view?usp=drive_link', r'../../data/aerial_data/test_images.npy',fuzzy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\training\\aerial_data_training\n",
            "Test Categories: ['Abies_alba' 'Acer_pseudoplatanus' 'Alnus_spec.' 'Betula_spec.'\n",
            " 'Fagus_sylvatica' 'Fraxinus_excelsior' 'Larix_decidua' 'Larix_kaempferi'\n",
            " 'Picea_abies' 'Pinus_nigra' 'Pinus_strobus' 'Pinus_sylvestris'\n",
            " 'Populus_spec.' 'Prunus_spec.' 'Pseudotsuga_menziesii' 'Quercus_petraea'\n",
            " 'Quercus_robur' 'Quercus_rubra' 'Tilia_spec.']\n",
            "train Categories: ['Abies_alba' 'Acer_pseudoplatanus' 'Alnus_spec.' 'Betula_spec.'\n",
            " 'Fagus_sylvatica' 'Fraxinus_excelsior' 'Larix_decidua' 'Larix_kaempferi'\n",
            " 'Picea_abies' 'Pinus_nigra' 'Pinus_strobus' 'Pinus_sylvestris'\n",
            " 'Populus_spec.' 'Prunus_spec.' 'Pseudotsuga_menziesii' 'Quercus_petraea'\n",
            " 'Quercus_robur' 'Quercus_rubra' 'Tilia_spec.']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "print(os.getcwd())\n",
        "test_labels = np.load('../../data/aerial_data/test_labels.npy')\n",
        "test_images = np.load('../../data/aerial_data/test_images.npy')\n",
        "\n",
        "#converting numpy arrays into RGB PIL images, ignoring the IR channel for now\n",
        "test_images_pil = [Image.fromarray(image) for image in test_images[:,:,:,1:]]\n",
        "#creating one hot encoding labels from numpy arrays\n",
        "test_categories, test_categories_numeric = np.unique(test_labels, return_inverse=True)\n",
        "\n",
        "print(\"Test Categories:\", test_categories)\n",
        "print(\"train Categories:\", train_categories)\n",
        "\n",
        "test_dataset = CustomDataset(test_images_pil, test_categories_numeric, image_transform)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### evaluating on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\bench/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n",
            "tensor([[0.0092, 0.0080, 0.0172, 0.0185, 0.0044, 0.0088, 0.0402, 0.0240, 0.0252,\n",
            "         0.0050, 0.0097, 0.7580, 0.0029, 0.0022, 0.0453, 0.0034, 0.0117, 0.0039,\n",
            "         0.0025]], device='cuda:0')\n",
            "tensor([[0.0301, 0.1843, 0.1054, 0.0314, 0.1797, 0.1946, 0.0240, 0.0259, 0.0456,\n",
            "         0.0031, 0.0053, 0.0116, 0.0081, 0.0052, 0.0184, 0.0452, 0.0361, 0.0421,\n",
            "         0.0039]], device='cuda:0')\n",
            "tensor([[0.0078, 0.1980, 0.1182, 0.0922, 0.1456, 0.0834, 0.0081, 0.0063, 0.0350,\n",
            "         0.0018, 0.0016, 0.0242, 0.0013, 0.0026, 0.0076, 0.1408, 0.1049, 0.0198,\n",
            "         0.0007]], device='cuda:0')\n",
            "tensor([[0.0263, 0.1930, 0.1079, 0.0670, 0.0823, 0.1178, 0.0389, 0.0594, 0.0390,\n",
            "         0.0098, 0.0161, 0.0194, 0.0142, 0.0150, 0.0543, 0.0518, 0.0438, 0.0396,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0344, 0.1510, 0.0240, 0.0859, 0.2113, 0.1531, 0.0435, 0.0262, 0.0410,\n",
            "         0.0132, 0.0178, 0.0469, 0.0099, 0.0097, 0.0166, 0.0415, 0.0356, 0.0253,\n",
            "         0.0131]], device='cuda:0')\n",
            "tensor([[0.0240, 0.2633, 0.0558, 0.0739, 0.1590, 0.1150, 0.0216, 0.0269, 0.0549,\n",
            "         0.0049, 0.0095, 0.0180, 0.0131, 0.0093, 0.0280, 0.0715, 0.0291, 0.0185,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0092, 0.1435, 0.1628, 0.1111, 0.1786, 0.0892, 0.0220, 0.0195, 0.0533,\n",
            "         0.0032, 0.0055, 0.0341, 0.0125, 0.0053, 0.0172, 0.0360, 0.0520, 0.0392,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0191, 0.0504, 0.0238, 0.0327, 0.0674, 0.0470, 0.0473, 0.0190, 0.4465,\n",
            "         0.0056, 0.0104, 0.1357, 0.0032, 0.0038, 0.0496, 0.0131, 0.0097, 0.0119,\n",
            "         0.0039]], device='cuda:0')\n",
            "tensor([[0.0058, 0.0145, 0.0364, 0.0242, 0.0132, 0.0092, 0.0087, 0.0089, 0.0109,\n",
            "         0.0018, 0.0019, 0.8011, 0.0025, 0.0015, 0.0076, 0.0135, 0.0310, 0.0063,\n",
            "         0.0011]], device='cuda:0')\n",
            "tensor([[0.0320, 0.0529, 0.1001, 0.0245, 0.1137, 0.0701, 0.0320, 0.0762, 0.2051,\n",
            "         0.0075, 0.0179, 0.0391, 0.0228, 0.0071, 0.1133, 0.0305, 0.0411, 0.0104,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0217, 0.0537, 0.1469, 0.1391, 0.0822, 0.0307, 0.0211, 0.0249, 0.0920,\n",
            "         0.0116, 0.0061, 0.1246, 0.0063, 0.0053, 0.0322, 0.0694, 0.0882, 0.0406,\n",
            "         0.0035]], device='cuda:0')\n",
            "tensor([[0.0240, 0.0611, 0.0956, 0.1020, 0.0205, 0.1104, 0.0200, 0.0232, 0.0344,\n",
            "         0.0081, 0.0075, 0.0694, 0.0098, 0.0061, 0.0123, 0.1177, 0.1961, 0.0755,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0323, 0.1458, 0.0654, 0.0250, 0.2125, 0.0903, 0.0208, 0.0152, 0.0369,\n",
            "         0.0097, 0.0093, 0.0170, 0.0155, 0.0130, 0.0406, 0.0683, 0.1379, 0.0389,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0945, 0.0482, 0.0558, 0.0173, 0.0472, 0.0538, 0.0232, 0.1199, 0.1347,\n",
            "         0.0077, 0.0274, 0.0876, 0.0181, 0.0127, 0.1540, 0.0203, 0.0410, 0.0306,\n",
            "         0.0060]], device='cuda:0')\n",
            "tensor([[0.0062, 0.0551, 0.1135, 0.1405, 0.0179, 0.0342, 0.0083, 0.0083, 0.0204,\n",
            "         0.0056, 0.0025, 0.2611, 0.0088, 0.0041, 0.0134, 0.1119, 0.1651, 0.0206,\n",
            "         0.0026]], device='cuda:0')\n",
            "tensor([[0.0121, 0.1208, 0.0814, 0.0518, 0.0513, 0.2248, 0.0064, 0.0060, 0.0080,\n",
            "         0.0043, 0.0039, 0.0035, 0.0049, 0.0040, 0.0052, 0.1981, 0.1736, 0.0370,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0195, 0.0523, 0.0357, 0.0984, 0.0506, 0.0745, 0.0359, 0.0236, 0.1262,\n",
            "         0.0038, 0.0106, 0.3901, 0.0069, 0.0050, 0.0191, 0.0203, 0.0148, 0.0083,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0260, 0.0458, 0.0283, 0.0786, 0.0283, 0.0287, 0.1205, 0.0158, 0.1452,\n",
            "         0.0078, 0.0096, 0.3756, 0.0043, 0.0047, 0.0209, 0.0302, 0.0112, 0.0144,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0129, 0.1559, 0.1617, 0.0387, 0.0704, 0.1314, 0.0044, 0.0036, 0.0063,\n",
            "         0.0046, 0.0038, 0.0049, 0.0050, 0.0043, 0.0044, 0.2106, 0.1123, 0.0611,\n",
            "         0.0035]], device='cuda:0')\n",
            "tensor([[0.0502, 0.0421, 0.0787, 0.1089, 0.1239, 0.0580, 0.0283, 0.0285, 0.0451,\n",
            "         0.0099, 0.0184, 0.1104, 0.0239, 0.0095, 0.0568, 0.0295, 0.1127, 0.0550,\n",
            "         0.0102]], device='cuda:0')\n",
            "tensor([[0.0356, 0.0306, 0.0792, 0.0450, 0.0405, 0.1119, 0.0177, 0.0439, 0.0500,\n",
            "         0.0134, 0.0185, 0.1813, 0.0142, 0.0067, 0.0379, 0.0432, 0.1541, 0.0655,\n",
            "         0.0106]], device='cuda:0')\n",
            "tensor([[0.0188, 0.1905, 0.0537, 0.0280, 0.2739, 0.0639, 0.0172, 0.0157, 0.0391,\n",
            "         0.0051, 0.0092, 0.0345, 0.0150, 0.0109, 0.0208, 0.0583, 0.0993, 0.0387,\n",
            "         0.0073]], device='cuda:0')\n",
            "tensor([[0.0353, 0.1089, 0.0873, 0.0326, 0.0922, 0.1166, 0.0179, 0.0214, 0.0195,\n",
            "         0.0094, 0.0117, 0.0223, 0.0109, 0.0102, 0.0176, 0.1694, 0.1088, 0.1038,\n",
            "         0.0045]], device='cuda:0')\n",
            "tensor([[0.0437, 0.0847, 0.0485, 0.0351, 0.0490, 0.0905, 0.0736, 0.1489, 0.0851,\n",
            "         0.0134, 0.0547, 0.0393, 0.0168, 0.0086, 0.1144, 0.0257, 0.0468, 0.0162,\n",
            "         0.0049]], device='cuda:0')\n",
            "tensor([[0.0151, 0.0452, 0.1097, 0.0980, 0.0786, 0.0384, 0.1326, 0.0291, 0.2200,\n",
            "         0.0057, 0.0105, 0.1221, 0.0089, 0.0047, 0.0381, 0.0171, 0.0107, 0.0110,\n",
            "         0.0047]], device='cuda:0')\n",
            "tensor([[0.0231, 0.0203, 0.0235, 0.0560, 0.0347, 0.0316, 0.0298, 0.0816, 0.3013,\n",
            "         0.0086, 0.0279, 0.1081, 0.0087, 0.0042, 0.1969, 0.0112, 0.0155, 0.0101,\n",
            "         0.0070]], device='cuda:0')\n",
            "tensor([[0.0113, 0.0108, 0.0303, 0.0153, 0.0113, 0.0125, 0.0252, 0.0977, 0.5280,\n",
            "         0.0014, 0.0083, 0.0231, 0.0057, 0.0021, 0.2013, 0.0029, 0.0066, 0.0052,\n",
            "         0.0010]], device='cuda:0')\n",
            "tensor([[0.0155, 0.0895, 0.0666, 0.0522, 0.4134, 0.0518, 0.0437, 0.0211, 0.1085,\n",
            "         0.0031, 0.0079, 0.0469, 0.0130, 0.0044, 0.0176, 0.0223, 0.0128, 0.0077,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0131, 0.0105, 0.0633, 0.2299, 0.0527, 0.0188, 0.0150, 0.0046, 0.0630,\n",
            "         0.0023, 0.0025, 0.4964, 0.0030, 0.0010, 0.0045, 0.0077, 0.0078, 0.0025,\n",
            "         0.0012]], device='cuda:0')\n",
            "tensor([[0.0318, 0.0447, 0.1478, 0.1410, 0.0289, 0.0906, 0.0209, 0.0080, 0.0094,\n",
            "         0.0055, 0.0081, 0.1891, 0.0061, 0.0055, 0.0100, 0.1471, 0.0623, 0.0395,\n",
            "         0.0038]], device='cuda:0')\n",
            "tensor([[0.0184, 0.1519, 0.1502, 0.0551, 0.1014, 0.1067, 0.0340, 0.0302, 0.0443,\n",
            "         0.0069, 0.0077, 0.0431, 0.0147, 0.0101, 0.0236, 0.0339, 0.1111, 0.0481,\n",
            "         0.0087]], device='cuda:0')\n",
            "tensor([[0.0174, 0.0466, 0.0571, 0.0246, 0.0345, 0.0474, 0.0699, 0.0582, 0.2784,\n",
            "         0.0158, 0.0154, 0.0626, 0.0060, 0.0043, 0.0430, 0.0736, 0.0713, 0.0689,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0228, 0.0895, 0.0872, 0.0484, 0.0602, 0.1220, 0.0212, 0.0101, 0.0100,\n",
            "         0.0083, 0.0067, 0.0171, 0.0078, 0.0077, 0.0097, 0.1958, 0.1824, 0.0860,\n",
            "         0.0071]], device='cuda:0')\n",
            "tensor([[0.0101, 0.0642, 0.0800, 0.0292, 0.0665, 0.0235, 0.0079, 0.0071, 0.0170,\n",
            "         0.0121, 0.0025, 0.0238, 0.0056, 0.0085, 0.0119, 0.2347, 0.2238, 0.1658,\n",
            "         0.0058]], device='cuda:0')\n",
            "tensor([[0.0244, 0.0470, 0.0405, 0.0516, 0.1443, 0.0489, 0.0757, 0.0308, 0.0445,\n",
            "         0.0164, 0.0092, 0.1166, 0.0073, 0.0059, 0.0267, 0.2191, 0.0539, 0.0327,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0804, 0.0962, 0.0776, 0.0241, 0.0956, 0.0995, 0.0235, 0.0280, 0.0443,\n",
            "         0.0182, 0.0268, 0.0643, 0.0143, 0.0101, 0.0474, 0.0703, 0.1027, 0.0716,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0179, 0.1585, 0.0713, 0.0408, 0.3068, 0.0734, 0.0295, 0.0162, 0.0878,\n",
            "         0.0065, 0.0105, 0.0511, 0.0091, 0.0090, 0.0227, 0.0297, 0.0344, 0.0184,\n",
            "         0.0063]], device='cuda:0')\n",
            "tensor([[0.0213, 0.1399, 0.0869, 0.0342, 0.3588, 0.0621, 0.0327, 0.0219, 0.0519,\n",
            "         0.0049, 0.0079, 0.0129, 0.0072, 0.0053, 0.0223, 0.0431, 0.0542, 0.0274,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0316, 0.0267, 0.1107, 0.0933, 0.0360, 0.0180, 0.0439, 0.0447, 0.1753,\n",
            "         0.0169, 0.0116, 0.1041, 0.0038, 0.0063, 0.1029, 0.0534, 0.0695, 0.0466,\n",
            "         0.0046]], device='cuda:0')\n",
            "tensor([[0.0254, 0.1511, 0.0643, 0.0488, 0.1117, 0.1395, 0.0396, 0.0360, 0.0266,\n",
            "         0.0152, 0.0238, 0.1041, 0.0227, 0.0146, 0.0260, 0.0447, 0.0685, 0.0268,\n",
            "         0.0105]], device='cuda:0')\n",
            "tensor([[0.0209, 0.1459, 0.0576, 0.1489, 0.1973, 0.1111, 0.0233, 0.0115, 0.0709,\n",
            "         0.0050, 0.0078, 0.0576, 0.0053, 0.0061, 0.0083, 0.0599, 0.0266, 0.0315,\n",
            "         0.0045]], device='cuda:0')\n",
            "tensor([[0.0178, 0.0191, 0.0181, 0.0338, 0.0323, 0.0261, 0.0383, 0.0914, 0.3618,\n",
            "         0.0052, 0.0184, 0.1246, 0.0074, 0.0049, 0.1547, 0.0123, 0.0177, 0.0135,\n",
            "         0.0025]], device='cuda:0')\n",
            "tensor([[0.0066, 0.0695, 0.0121, 0.0507, 0.0235, 0.0479, 0.0286, 0.0152, 0.6137,\n",
            "         0.0042, 0.0053, 0.0341, 0.0041, 0.0036, 0.0076, 0.0308, 0.0294, 0.0105,\n",
            "         0.0026]], device='cuda:0')\n",
            "tensor([[0.0089, 0.0097, 0.0501, 0.0351, 0.0126, 0.0073, 0.0132, 0.0090, 0.0059,\n",
            "         0.0040, 0.0027, 0.7568, 0.0020, 0.0015, 0.0152, 0.0203, 0.0284, 0.0153,\n",
            "         0.0018]], device='cuda:0')\n",
            "tensor([[0.0127, 0.0521, 0.1995, 0.1299, 0.0995, 0.0251, 0.0248, 0.0149, 0.2871,\n",
            "         0.0026, 0.0054, 0.0660, 0.0042, 0.0048, 0.0231, 0.0158, 0.0182, 0.0115,\n",
            "         0.0027]], device='cuda:0')\n",
            "tensor([[0.0211, 0.0678, 0.0685, 0.0339, 0.0454, 0.0369, 0.0293, 0.0351, 0.1225,\n",
            "         0.0282, 0.0137, 0.0344, 0.0110, 0.0065, 0.0232, 0.0918, 0.2186, 0.1030,\n",
            "         0.0089]], device='cuda:0')\n",
            "tensor([[0.0206, 0.0596, 0.1140, 0.0795, 0.0505, 0.0383, 0.0120, 0.0250, 0.0683,\n",
            "         0.0125, 0.0081, 0.0481, 0.0093, 0.0113, 0.0402, 0.1473, 0.1041, 0.1452,\n",
            "         0.0060]], device='cuda:0')\n",
            "tensor([[0.0119, 0.0247, 0.0182, 0.0403, 0.0801, 0.0103, 0.0326, 0.0103, 0.5980,\n",
            "         0.0029, 0.0059, 0.1198, 0.0024, 0.0018, 0.0261, 0.0064, 0.0042, 0.0029,\n",
            "         0.0014]], device='cuda:0')\n",
            "tensor([[7.7190e-03, 1.7514e-03, 1.8017e-02, 2.1983e-02, 2.6192e-03, 2.8446e-03,\n",
            "         5.5015e-03, 5.0748e-03, 5.2324e-03, 1.2157e-03, 1.1460e-03, 8.9982e-01,\n",
            "         1.2447e-03, 4.8469e-04, 7.3838e-03, 5.9083e-03, 7.4200e-03, 3.8675e-03,\n",
            "         7.6309e-04]], device='cuda:0')\n",
            "tensor([[0.0146, 0.0578, 0.0709, 0.0878, 0.1022, 0.1145, 0.0291, 0.1041, 0.0558,\n",
            "         0.0046, 0.0146, 0.1626, 0.0269, 0.0096, 0.0539, 0.0186, 0.0434, 0.0237,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0081, 0.0071, 0.0465, 0.0464, 0.0120, 0.0189, 0.0121, 0.0262, 0.0454,\n",
            "         0.0020, 0.0070, 0.7264, 0.0033, 0.0015, 0.0154, 0.0035, 0.0134, 0.0035,\n",
            "         0.0014]], device='cuda:0')\n",
            "tensor([[0.0096, 0.3060, 0.1072, 0.0323, 0.1518, 0.1006, 0.0225, 0.0476, 0.0748,\n",
            "         0.0034, 0.0078, 0.0156, 0.0148, 0.0104, 0.0359, 0.0277, 0.0168, 0.0121,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0091, 0.0266, 0.0185, 0.0370, 0.0133, 0.0173, 0.0233, 0.0235, 0.3632,\n",
            "         0.0030, 0.0103, 0.3892, 0.0050, 0.0043, 0.0260, 0.0157, 0.0086, 0.0039,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0214, 0.1867, 0.0880, 0.0519, 0.3044, 0.0793, 0.0216, 0.0208, 0.0463,\n",
            "         0.0048, 0.0083, 0.0342, 0.0129, 0.0110, 0.0233, 0.0358, 0.0213, 0.0239,\n",
            "         0.0039]], device='cuda:0')\n",
            "tensor([[0.0399, 0.0302, 0.0335, 0.0934, 0.0154, 0.0548, 0.1275, 0.0796, 0.0697,\n",
            "         0.0268, 0.0712, 0.1789, 0.0180, 0.0084, 0.1046, 0.0183, 0.0145, 0.0104,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0143, 0.0931, 0.0391, 0.0505, 0.0728, 0.0423, 0.0328, 0.0520, 0.3631,\n",
            "         0.0050, 0.0093, 0.0706, 0.0089, 0.0065, 0.0976, 0.0146, 0.0112, 0.0120,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0299, 0.0585, 0.0964, 0.1571, 0.0928, 0.1018, 0.0447, 0.0196, 0.0702,\n",
            "         0.0118, 0.0144, 0.0823, 0.0192, 0.0095, 0.0258, 0.0563, 0.0745, 0.0252,\n",
            "         0.0101]], device='cuda:0')\n",
            "tensor([[0.0107, 0.0724, 0.0503, 0.0490, 0.0589, 0.0631, 0.0096, 0.0128, 0.0051,\n",
            "         0.0122, 0.0060, 0.0268, 0.0102, 0.0120, 0.0077, 0.3167, 0.1616, 0.1069,\n",
            "         0.0082]], device='cuda:0')\n",
            "tensor([[0.0181, 0.2358, 0.0926, 0.0218, 0.2756, 0.1092, 0.0080, 0.0062, 0.0078,\n",
            "         0.0025, 0.0040, 0.0123, 0.0073, 0.0049, 0.0084, 0.0847, 0.0677, 0.0308,\n",
            "         0.0021]], device='cuda:0')\n",
            "tensor([[0.0078, 0.0105, 0.0285, 0.0469, 0.0183, 0.0130, 0.0053, 0.0042, 0.0136,\n",
            "         0.0031, 0.0027, 0.6618, 0.0036, 0.0017, 0.0085, 0.0430, 0.1098, 0.0149,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0044, 0.0363, 0.0150, 0.0135, 0.0413, 0.0090, 0.0277, 0.0167, 0.7712,\n",
            "         0.0012, 0.0037, 0.0081, 0.0032, 0.0023, 0.0350, 0.0056, 0.0026, 0.0022,\n",
            "         0.0012]], device='cuda:0')\n",
            "tensor([[0.0243, 0.1319, 0.1172, 0.0786, 0.1694, 0.1383, 0.0147, 0.0205, 0.0139,\n",
            "         0.0034, 0.0033, 0.0462, 0.0045, 0.0033, 0.0067, 0.0820, 0.1039, 0.0344,\n",
            "         0.0034]], device='cuda:0')\n",
            "tensor([[0.0325, 0.0489, 0.0433, 0.1122, 0.1342, 0.1072, 0.0368, 0.0229, 0.0214,\n",
            "         0.0113, 0.0146, 0.1228, 0.0105, 0.0073, 0.0153, 0.1740, 0.0439, 0.0352,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0220, 0.0615, 0.0508, 0.0927, 0.0773, 0.0367, 0.0368, 0.0273, 0.2380,\n",
            "         0.0054, 0.0121, 0.0963, 0.0075, 0.0092, 0.1249, 0.0439, 0.0329, 0.0207,\n",
            "         0.0040]], device='cuda:0')\n",
            "tensor([[0.0312, 0.0537, 0.1576, 0.1133, 0.0850, 0.0378, 0.0263, 0.0188, 0.0725,\n",
            "         0.0089, 0.0058, 0.0972, 0.0062, 0.0075, 0.0418, 0.0812, 0.0983, 0.0534,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0269, 0.0736, 0.0940, 0.0356, 0.1501, 0.1680, 0.0114, 0.0099, 0.0078,\n",
            "         0.0048, 0.0041, 0.0077, 0.0079, 0.0052, 0.0081, 0.1860, 0.0927, 0.1018,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0328, 0.0255, 0.0266, 0.0447, 0.0274, 0.0283, 0.0254, 0.0372, 0.0518,\n",
            "         0.0150, 0.0165, 0.5023, 0.0127, 0.0061, 0.0566, 0.0198, 0.0515, 0.0138,\n",
            "         0.0061]], device='cuda:0')\n",
            "tensor([[0.0124, 0.0394, 0.0253, 0.0868, 0.2112, 0.0373, 0.0462, 0.0535, 0.2549,\n",
            "         0.0040, 0.0092, 0.0219, 0.0160, 0.0070, 0.1229, 0.0221, 0.0145, 0.0113,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0499, 0.0315, 0.0598, 0.0792, 0.0477, 0.0602, 0.0283, 0.0447, 0.0708,\n",
            "         0.0088, 0.0301, 0.1953, 0.0231, 0.0108, 0.1000, 0.0207, 0.0782, 0.0501,\n",
            "         0.0108]], device='cuda:0')\n",
            "tensor([[0.0184, 0.0232, 0.0561, 0.0895, 0.0268, 0.0181, 0.0206, 0.0187, 0.0799,\n",
            "         0.0077, 0.0099, 0.5375, 0.0080, 0.0047, 0.0404, 0.0136, 0.0121, 0.0115,\n",
            "         0.0034]], device='cuda:0')\n",
            "tensor([[0.0114, 0.0205, 0.0633, 0.0638, 0.0200, 0.0211, 0.0205, 0.0201, 0.0247,\n",
            "         0.0065, 0.0096, 0.5779, 0.0150, 0.0068, 0.0379, 0.0261, 0.0387, 0.0103,\n",
            "         0.0059]], device='cuda:0')\n",
            "tensor([[0.0153, 0.0767, 0.0957, 0.1634, 0.0927, 0.1170, 0.0123, 0.0074, 0.0069,\n",
            "         0.0055, 0.0027, 0.0417, 0.0074, 0.0029, 0.0055, 0.1375, 0.1512, 0.0547,\n",
            "         0.0035]], device='cuda:0')\n",
            "tensor([[0.0173, 0.0083, 0.0145, 0.0080, 0.0114, 0.0091, 0.0123, 0.0701, 0.5177,\n",
            "         0.0023, 0.0111, 0.0165, 0.0038, 0.0022, 0.2861, 0.0024, 0.0028, 0.0026,\n",
            "         0.0014]], device='cuda:0')\n",
            "tensor([[0.0363, 0.0773, 0.0608, 0.0568, 0.0669, 0.0685, 0.0170, 0.0215, 0.0045,\n",
            "         0.0160, 0.0115, 0.0337, 0.0131, 0.0110, 0.0205, 0.1588, 0.2258, 0.0900,\n",
            "         0.0098]], device='cuda:0')\n",
            "tensor([[0.0362, 0.0323, 0.0247, 0.0186, 0.0361, 0.0190, 0.0348, 0.1201, 0.0770,\n",
            "         0.0050, 0.0170, 0.0631, 0.0094, 0.0075, 0.4417, 0.0129, 0.0222, 0.0174,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0200, 0.0826, 0.0490, 0.0342, 0.0949, 0.0519, 0.0795, 0.0800, 0.2663,\n",
            "         0.0070, 0.0090, 0.0710, 0.0074, 0.0049, 0.0209, 0.0642, 0.0325, 0.0222,\n",
            "         0.0024]], device='cuda:0')\n",
            "tensor([[0.0416, 0.0521, 0.0254, 0.0380, 0.0474, 0.0529, 0.0424, 0.0975, 0.0706,\n",
            "         0.0049, 0.0206, 0.0368, 0.0178, 0.0080, 0.3418, 0.0262, 0.0497, 0.0219,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0136, 0.0280, 0.0169, 0.0268, 0.0277, 0.0402, 0.0332, 0.0282, 0.4370,\n",
            "         0.0048, 0.0114, 0.2003, 0.0065, 0.0055, 0.1011, 0.0059, 0.0041, 0.0043,\n",
            "         0.0045]], device='cuda:0')\n",
            "tensor([[0.0298, 0.0320, 0.0394, 0.0562, 0.0346, 0.0757, 0.0144, 0.0279, 0.0078,\n",
            "         0.0067, 0.0075, 0.0186, 0.0091, 0.0064, 0.0250, 0.2097, 0.2823, 0.1116,\n",
            "         0.0054]], device='cuda:0')\n",
            "tensor([[0.0128, 0.0417, 0.0292, 0.0509, 0.0616, 0.0414, 0.0367, 0.0194, 0.3922,\n",
            "         0.0074, 0.0074, 0.1472, 0.0069, 0.0062, 0.0954, 0.0134, 0.0077, 0.0171,\n",
            "         0.0053]], device='cuda:0')\n",
            "tensor([[0.0246, 0.0393, 0.1149, 0.0867, 0.0484, 0.0481, 0.0375, 0.0134, 0.0313,\n",
            "         0.0052, 0.0066, 0.0758, 0.0096, 0.0058, 0.0124, 0.1797, 0.1567, 0.0986,\n",
            "         0.0054]], device='cuda:0')\n",
            "tensor([[0.0391, 0.0347, 0.1134, 0.0983, 0.0295, 0.0264, 0.0146, 0.0292, 0.0142,\n",
            "         0.0129, 0.0163, 0.3882, 0.0060, 0.0049, 0.0507, 0.0444, 0.0443, 0.0285,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0130, 0.0177, 0.0217, 0.0357, 0.0169, 0.0131, 0.0139, 0.0224, 0.0114,\n",
            "         0.0109, 0.0102, 0.6968, 0.0073, 0.0050, 0.0195, 0.0153, 0.0487, 0.0152,\n",
            "         0.0053]], device='cuda:0')\n",
            "tensor([[0.0886, 0.0169, 0.0228, 0.0461, 0.0728, 0.0366, 0.0312, 0.1489, 0.1189,\n",
            "         0.0052, 0.0231, 0.0220, 0.0094, 0.0047, 0.2366, 0.0159, 0.0570, 0.0388,\n",
            "         0.0046]], device='cuda:0')\n",
            "tensor([[0.0289, 0.1002, 0.0713, 0.0959, 0.1523, 0.0872, 0.0353, 0.0592, 0.0172,\n",
            "         0.0138, 0.0190, 0.1556, 0.0181, 0.0067, 0.0294, 0.0293, 0.0635, 0.0114,\n",
            "         0.0058]], device='cuda:0')\n",
            "tensor([[0.0051, 0.1650, 0.0805, 0.0785, 0.2823, 0.1179, 0.0147, 0.0113, 0.0520,\n",
            "         0.0048, 0.0051, 0.0158, 0.0134, 0.0042, 0.0087, 0.0608, 0.0650, 0.0118,\n",
            "         0.0033]], device='cuda:0')\n",
            "tensor([[0.0265, 0.1387, 0.0901, 0.0931, 0.1557, 0.0420, 0.0499, 0.0078, 0.0446,\n",
            "         0.0092, 0.0102, 0.1370, 0.0088, 0.0064, 0.0199, 0.0553, 0.0618, 0.0370,\n",
            "         0.0059]], device='cuda:0')\n",
            "tensor([[0.0137, 0.0907, 0.0334, 0.0460, 0.0916, 0.0274, 0.0283, 0.0207, 0.4850,\n",
            "         0.0027, 0.0070, 0.0697, 0.0061, 0.0049, 0.0334, 0.0146, 0.0138, 0.0081,\n",
            "         0.0030]], device='cuda:0')\n",
            "tensor([[0.0263, 0.0420, 0.1716, 0.2421, 0.2206, 0.0313, 0.0286, 0.0117, 0.0726,\n",
            "         0.0050, 0.0061, 0.0563, 0.0041, 0.0045, 0.0161, 0.0342, 0.0129, 0.0105,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0479, 0.0295, 0.0235, 0.0238, 0.0758, 0.0237, 0.0775, 0.0225, 0.4078,\n",
            "         0.0052, 0.0106, 0.1437, 0.0076, 0.0041, 0.0618, 0.0133, 0.0114, 0.0063,\n",
            "         0.0042]], device='cuda:0')\n",
            "tensor([[0.0095, 0.2210, 0.1268, 0.0201, 0.2231, 0.1819, 0.0089, 0.0123, 0.0142,\n",
            "         0.0032, 0.0036, 0.0135, 0.0091, 0.0050, 0.0048, 0.0457, 0.0721, 0.0231,\n",
            "         0.0023]], device='cuda:0')\n",
            "tensor([[0.0275, 0.0828, 0.0739, 0.0884, 0.1775, 0.1272, 0.0233, 0.0164, 0.0981,\n",
            "         0.0072, 0.0063, 0.0375, 0.0147, 0.0057, 0.0308, 0.0507, 0.1049, 0.0220,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0219, 0.0861, 0.0437, 0.0462, 0.3794, 0.0979, 0.0146, 0.0150, 0.0615,\n",
            "         0.0036, 0.0046, 0.0066, 0.0050, 0.0038, 0.0269, 0.1252, 0.0334, 0.0218,\n",
            "         0.0028]], device='cuda:0')\n",
            "tensor([[0.0703, 0.0744, 0.0506, 0.0348, 0.0927, 0.0710, 0.0312, 0.1300, 0.1125,\n",
            "         0.0106, 0.0246, 0.0447, 0.0185, 0.0128, 0.1208, 0.0201, 0.0342, 0.0384,\n",
            "         0.0077]], device='cuda:0')\n",
            "tensor([[0.0169, 0.0924, 0.0993, 0.0661, 0.0740, 0.1016, 0.0052, 0.0092, 0.0068,\n",
            "         0.0084, 0.0041, 0.0114, 0.0080, 0.0042, 0.0059, 0.1975, 0.2290, 0.0561,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0330, 0.0599, 0.0332, 0.0436, 0.1117, 0.0485, 0.0397, 0.0432, 0.2589,\n",
            "         0.0086, 0.0229, 0.0280, 0.0091, 0.0077, 0.0986, 0.0758, 0.0437, 0.0288,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0452, 0.0511, 0.1394, 0.0639, 0.0611, 0.0574, 0.0424, 0.0264, 0.0323,\n",
            "         0.0097, 0.0124, 0.2567, 0.0152, 0.0063, 0.0466, 0.0248, 0.0669, 0.0338,\n",
            "         0.0084]], device='cuda:0')\n",
            "tensor([[0.0058, 0.0666, 0.0440, 0.0261, 0.5886, 0.0635, 0.0040, 0.0021, 0.0067,\n",
            "         0.0042, 0.0020, 0.0059, 0.0036, 0.0040, 0.0017, 0.0615, 0.0769, 0.0298,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0135, 0.0118, 0.0257, 0.0297, 0.0107, 0.0339, 0.0279, 0.1654, 0.1393,\n",
            "         0.0052, 0.0308, 0.0553, 0.0215, 0.0056, 0.3699, 0.0082, 0.0364, 0.0056,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0128, 0.1567, 0.0707, 0.0233, 0.0738, 0.1077, 0.0167, 0.0077, 0.0334,\n",
            "         0.0079, 0.0056, 0.0180, 0.0064, 0.0083, 0.0082, 0.2473, 0.0869, 0.1035,\n",
            "         0.0049]], device='cuda:0')\n",
            "tensor([[0.0229, 0.0155, 0.0215, 0.0089, 0.0132, 0.0278, 0.0197, 0.0390, 0.6628,\n",
            "         0.0052, 0.0131, 0.0391, 0.0048, 0.0029, 0.0819, 0.0060, 0.0060, 0.0073,\n",
            "         0.0024]], device='cuda:0')\n",
            "tensor([[0.0317, 0.1010, 0.0922, 0.1342, 0.2367, 0.1302, 0.0304, 0.0153, 0.0319,\n",
            "         0.0031, 0.0048, 0.0531, 0.0059, 0.0025, 0.0067, 0.0305, 0.0619, 0.0248,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0223, 0.0595, 0.0589, 0.1008, 0.1852, 0.0979, 0.0256, 0.0392, 0.0528,\n",
            "         0.0077, 0.0154, 0.0699, 0.0178, 0.0089, 0.0722, 0.0391, 0.0848, 0.0357,\n",
            "         0.0061]], device='cuda:0')\n",
            "tensor([[0.0088, 0.1011, 0.0445, 0.0521, 0.2657, 0.1036, 0.0160, 0.0158, 0.0364,\n",
            "         0.0046, 0.0076, 0.0421, 0.0063, 0.0045, 0.0066, 0.2173, 0.0418, 0.0217,\n",
            "         0.0035]], device='cuda:0')\n",
            "tensor([[0.0176, 0.0629, 0.0807, 0.1379, 0.0790, 0.0563, 0.0302, 0.0218, 0.2220,\n",
            "         0.0120, 0.0115, 0.0618, 0.0103, 0.0076, 0.0318, 0.0617, 0.0593, 0.0288,\n",
            "         0.0068]], device='cuda:0')\n",
            "tensor([[0.0209, 0.1092, 0.1460, 0.1108, 0.1408, 0.0494, 0.0320, 0.0212, 0.0881,\n",
            "         0.0048, 0.0078, 0.1466, 0.0087, 0.0086, 0.0284, 0.0165, 0.0407, 0.0153,\n",
            "         0.0042]], device='cuda:0')\n",
            "tensor([[0.0067, 0.0086, 0.0101, 0.0080, 0.0113, 0.0069, 0.0202, 0.0645, 0.2166,\n",
            "         0.0016, 0.0058, 0.0096, 0.0041, 0.0022, 0.6128, 0.0030, 0.0030, 0.0034,\n",
            "         0.0015]], device='cuda:0')\n",
            "tensor([[0.0239, 0.0205, 0.0480, 0.2288, 0.0340, 0.0278, 0.0336, 0.0113, 0.2982,\n",
            "         0.0027, 0.0081, 0.2014, 0.0064, 0.0026, 0.0186, 0.0122, 0.0104, 0.0081,\n",
            "         0.0034]], device='cuda:0')\n",
            "tensor([[0.0073, 0.0158, 0.0144, 0.0228, 0.0186, 0.0068, 0.0157, 0.0098, 0.6361,\n",
            "         0.0019, 0.0073, 0.2026, 0.0026, 0.0016, 0.0248, 0.0050, 0.0036, 0.0018,\n",
            "         0.0015]], device='cuda:0')\n",
            "tensor([[0.1038, 0.0310, 0.0721, 0.0683, 0.0723, 0.0556, 0.0248, 0.0559, 0.0954,\n",
            "         0.0096, 0.0139, 0.0875, 0.0140, 0.0077, 0.1340, 0.0279, 0.0692, 0.0532,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0227, 0.0150, 0.0458, 0.0453, 0.0271, 0.0185, 0.0461, 0.0268, 0.2914,\n",
            "         0.0066, 0.0075, 0.2887, 0.0065, 0.0037, 0.1188, 0.0054, 0.0126, 0.0084,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0060, 0.0080, 0.0246, 0.0327, 0.0045, 0.0126, 0.0200, 0.0039, 0.0425,\n",
            "         0.0015, 0.0037, 0.8093, 0.0022, 0.0011, 0.0026, 0.0153, 0.0060, 0.0027,\n",
            "         0.0010]], device='cuda:0')\n",
            "tensor([[0.0194, 0.0723, 0.1206, 0.0412, 0.0898, 0.0384, 0.0189, 0.0412, 0.0548,\n",
            "         0.0203, 0.0092, 0.1114, 0.0080, 0.0054, 0.0201, 0.0837, 0.1603, 0.0793,\n",
            "         0.0059]], device='cuda:0')\n",
            "tensor([[0.0260, 0.0619, 0.0838, 0.0352, 0.0585, 0.0616, 0.0343, 0.0329, 0.1166,\n",
            "         0.0147, 0.0112, 0.0284, 0.0063, 0.0060, 0.0990, 0.1259, 0.1239, 0.0676,\n",
            "         0.0061]], device='cuda:0')\n",
            "tensor([[0.0435, 0.0315, 0.0705, 0.0746, 0.0652, 0.0358, 0.0312, 0.0267, 0.0346,\n",
            "         0.0069, 0.0083, 0.0568, 0.0100, 0.0091, 0.0421, 0.1202, 0.1920, 0.1334,\n",
            "         0.0074]], device='cuda:0')\n",
            "tensor([[0.0128, 0.0746, 0.0472, 0.0199, 0.0848, 0.0280, 0.0219, 0.0224, 0.4626,\n",
            "         0.0050, 0.0081, 0.1057, 0.0074, 0.0073, 0.0361, 0.0202, 0.0138, 0.0177,\n",
            "         0.0045]], device='cuda:0')\n",
            "tensor([[0.0130, 0.0654, 0.0405, 0.0823, 0.1582, 0.0424, 0.0480, 0.0244, 0.2875,\n",
            "         0.0059, 0.0106, 0.0348, 0.0098, 0.0068, 0.0814, 0.0329, 0.0238, 0.0264,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0155, 0.1915, 0.0532, 0.0199, 0.1976, 0.0603, 0.0324, 0.0187, 0.0738,\n",
            "         0.0073, 0.0095, 0.0209, 0.0065, 0.0058, 0.0183, 0.1183, 0.1146, 0.0313,\n",
            "         0.0045]], device='cuda:0')\n",
            "tensor([[0.0562, 0.0175, 0.0473, 0.0750, 0.0229, 0.0784, 0.0371, 0.0632, 0.1747,\n",
            "         0.0109, 0.0164, 0.0842, 0.0129, 0.0038, 0.0902, 0.0338, 0.0910, 0.0785,\n",
            "         0.0059]], device='cuda:0')\n",
            "tensor([[0.0195, 0.0532, 0.0428, 0.0584, 0.0514, 0.0575, 0.0281, 0.0484, 0.0842,\n",
            "         0.0115, 0.0207, 0.3081, 0.0112, 0.0073, 0.0956, 0.0351, 0.0353, 0.0274,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0606, 0.0577, 0.0528, 0.0308, 0.0361, 0.0619, 0.0476, 0.0177, 0.4198,\n",
            "         0.0094, 0.0149, 0.0348, 0.0096, 0.0123, 0.0471, 0.0373, 0.0207, 0.0208,\n",
            "         0.0082]], device='cuda:0')\n",
            "tensor([[0.0260, 0.0691, 0.1706, 0.0491, 0.1725, 0.0635, 0.0279, 0.0169, 0.0420,\n",
            "         0.0083, 0.0036, 0.0175, 0.0060, 0.0048, 0.0228, 0.1072, 0.1396, 0.0494,\n",
            "         0.0032]], device='cuda:0')\n",
            "tensor([[0.0190, 0.0226, 0.0352, 0.0341, 0.0283, 0.0241, 0.0415, 0.0729, 0.2171,\n",
            "         0.0059, 0.0157, 0.1570, 0.0133, 0.0071, 0.2762, 0.0070, 0.0132, 0.0061,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0241, 0.0119, 0.0062, 0.0078, 0.0177, 0.0092, 0.0186, 0.1181, 0.0546,\n",
            "         0.0021, 0.0157, 0.0425, 0.0059, 0.0034, 0.6421, 0.0057, 0.0059, 0.0062,\n",
            "         0.0024]], device='cuda:0')\n",
            "tensor([[0.0203, 0.2890, 0.1352, 0.0206, 0.1250, 0.1257, 0.0230, 0.0194, 0.0193,\n",
            "         0.0059, 0.0068, 0.0114, 0.0124, 0.0101, 0.0194, 0.0332, 0.0865, 0.0318,\n",
            "         0.0049]], device='cuda:0')\n",
            "tensor([[0.0244, 0.1600, 0.0939, 0.0482, 0.1931, 0.1413, 0.0142, 0.0138, 0.0308,\n",
            "         0.0054, 0.0076, 0.0174, 0.0093, 0.0076, 0.0159, 0.0589, 0.0792, 0.0745,\n",
            "         0.0046]], device='cuda:0')\n",
            "tensor([[0.0263, 0.0585, 0.0907, 0.1150, 0.1073, 0.0568, 0.0191, 0.0120, 0.0199,\n",
            "         0.0119, 0.0066, 0.0219, 0.0119, 0.0080, 0.0234, 0.1807, 0.1797, 0.0447,\n",
            "         0.0054]], device='cuda:0')\n",
            "tensor([[0.0173, 0.0884, 0.0815, 0.0274, 0.2459, 0.0534, 0.0302, 0.0209, 0.0315,\n",
            "         0.0049, 0.0069, 0.0132, 0.0086, 0.0056, 0.0284, 0.1345, 0.1414, 0.0567,\n",
            "         0.0032]], device='cuda:0')\n",
            "tensor([[0.0211, 0.2492, 0.1041, 0.0266, 0.1500, 0.1091, 0.0226, 0.0631, 0.0630,\n",
            "         0.0039, 0.0118, 0.0086, 0.0155, 0.0086, 0.0395, 0.0478, 0.0354, 0.0160,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0705, 0.0438, 0.0342, 0.0538, 0.0646, 0.0519, 0.0497, 0.0829, 0.0832,\n",
            "         0.0109, 0.0218, 0.1036, 0.0217, 0.0100, 0.1324, 0.0273, 0.0714, 0.0568,\n",
            "         0.0096]], device='cuda:0')\n",
            "tensor([[0.0109, 0.1217, 0.0791, 0.1253, 0.2124, 0.1260, 0.0153, 0.0198, 0.0107,\n",
            "         0.0079, 0.0087, 0.0351, 0.0157, 0.0055, 0.0210, 0.1175, 0.0371, 0.0245,\n",
            "         0.0060]], device='cuda:0')\n",
            "tensor([[0.0380, 0.0295, 0.1051, 0.0761, 0.0665, 0.0385, 0.0140, 0.0283, 0.0359,\n",
            "         0.0225, 0.0071, 0.0450, 0.0107, 0.0055, 0.0259, 0.1457, 0.1942, 0.1053,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0159, 0.0117, 0.0333, 0.0776, 0.0125, 0.0244, 0.0562, 0.0055, 0.0201,\n",
            "         0.0032, 0.0042, 0.6986, 0.0037, 0.0017, 0.0104, 0.0111, 0.0046, 0.0040,\n",
            "         0.0013]], device='cuda:0')\n",
            "tensor([[0.0166, 0.0793, 0.0897, 0.0363, 0.0856, 0.0625, 0.0197, 0.0167, 0.0149,\n",
            "         0.0124, 0.0078, 0.2104, 0.0095, 0.0074, 0.0151, 0.0952, 0.1743, 0.0410,\n",
            "         0.0056]], device='cuda:0')\n",
            "tensor([[0.0177, 0.0858, 0.1453, 0.1131, 0.0756, 0.0350, 0.0462, 0.0336, 0.1670,\n",
            "         0.0069, 0.0121, 0.0575, 0.0052, 0.0098, 0.0638, 0.0731, 0.0276, 0.0198,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0180, 0.0073, 0.0166, 0.0423, 0.0125, 0.0192, 0.0222, 0.0117, 0.0270,\n",
            "         0.0032, 0.0077, 0.7591, 0.0074, 0.0024, 0.0167, 0.0052, 0.0110, 0.0075,\n",
            "         0.0028]], device='cuda:0')\n",
            "tensor([[0.0122, 0.1336, 0.0757, 0.0806, 0.2060, 0.1031, 0.0121, 0.0104, 0.0160,\n",
            "         0.0095, 0.0067, 0.0605, 0.0107, 0.0069, 0.0072, 0.0948, 0.1036, 0.0423,\n",
            "         0.0081]], device='cuda:0')\n",
            "tensor([[0.0238, 0.0351, 0.1027, 0.0689, 0.0539, 0.0475, 0.0099, 0.0274, 0.0158,\n",
            "         0.0227, 0.0114, 0.0418, 0.0059, 0.0059, 0.0205, 0.1310, 0.2337, 0.1357,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0154, 0.1333, 0.0588, 0.0534, 0.2669, 0.1246, 0.0467, 0.0212, 0.0782,\n",
            "         0.0076, 0.0117, 0.0325, 0.0100, 0.0084, 0.0140, 0.0216, 0.0585, 0.0234,\n",
            "         0.0138]], device='cuda:0')\n",
            "tensor([[0.0158, 0.3289, 0.0523, 0.0130, 0.2721, 0.0766, 0.0175, 0.0075, 0.1088,\n",
            "         0.0041, 0.0070, 0.0131, 0.0064, 0.0052, 0.0140, 0.0191, 0.0144, 0.0205,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0376, 0.0172, 0.0796, 0.1079, 0.0262, 0.0304, 0.0271, 0.0185, 0.0167,\n",
            "         0.0094, 0.0080, 0.4509, 0.0044, 0.0023, 0.0460, 0.0443, 0.0494, 0.0219,\n",
            "         0.0022]], device='cuda:0')\n",
            "tensor([[0.0398, 0.0169, 0.0556, 0.0643, 0.0278, 0.0185, 0.0374, 0.0426, 0.0591,\n",
            "         0.0044, 0.0108, 0.4277, 0.0109, 0.0052, 0.1307, 0.0087, 0.0183, 0.0161,\n",
            "         0.0052]], device='cuda:0')\n",
            "tensor([[0.0491, 0.0364, 0.0530, 0.1308, 0.0445, 0.0323, 0.0361, 0.0257, 0.0405,\n",
            "         0.0067, 0.0097, 0.3755, 0.0040, 0.0040, 0.0552, 0.0481, 0.0236, 0.0194,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0143, 0.1429, 0.0879, 0.0247, 0.2143, 0.0852, 0.0107, 0.0156, 0.0112,\n",
            "         0.0069, 0.0069, 0.0063, 0.0090, 0.0116, 0.0171, 0.1636, 0.0813, 0.0848,\n",
            "         0.0056]], device='cuda:0')\n",
            "tensor([[0.0528, 0.0137, 0.0784, 0.1249, 0.0478, 0.0321, 0.0195, 0.0404, 0.0163,\n",
            "         0.0117, 0.0079, 0.2221, 0.0063, 0.0046, 0.0271, 0.1056, 0.0974, 0.0887,\n",
            "         0.0027]], device='cuda:0')\n",
            "tensor([[0.0198, 0.0452, 0.2467, 0.2490, 0.0615, 0.0584, 0.0421, 0.0171, 0.0583,\n",
            "         0.0032, 0.0062, 0.1195, 0.0063, 0.0031, 0.0077, 0.0166, 0.0263, 0.0103,\n",
            "         0.0028]], device='cuda:0')\n",
            "tensor([[0.0118, 0.0310, 0.0130, 0.0122, 0.0192, 0.0222, 0.0223, 0.0583, 0.2720,\n",
            "         0.0044, 0.0196, 0.0297, 0.0124, 0.0093, 0.4262, 0.0081, 0.0133, 0.0115,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0199, 0.0935, 0.0620, 0.0415, 0.1322, 0.1405, 0.0435, 0.0126, 0.0969,\n",
            "         0.0103, 0.0104, 0.0621, 0.0066, 0.0058, 0.0120, 0.0940, 0.0827, 0.0667,\n",
            "         0.0068]], device='cuda:0')\n",
            "tensor([[0.0119, 0.0779, 0.0311, 0.0627, 0.0545, 0.0473, 0.0284, 0.0363, 0.3355,\n",
            "         0.0098, 0.0088, 0.0546, 0.0125, 0.0095, 0.0455, 0.0744, 0.0598, 0.0322,\n",
            "         0.0073]], device='cuda:0')\n",
            "tensor([[0.0223, 0.0316, 0.1018, 0.1255, 0.0299, 0.1306, 0.0160, 0.0151, 0.0048,\n",
            "         0.0101, 0.0113, 0.2573, 0.0145, 0.0056, 0.0088, 0.1039, 0.0759, 0.0300,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0185, 0.0477, 0.1223, 0.0385, 0.0609, 0.1100, 0.0088, 0.0070, 0.0123,\n",
            "         0.0053, 0.0047, 0.0904, 0.0079, 0.0053, 0.0045, 0.0923, 0.2293, 0.1287,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0140, 0.0203, 0.0188, 0.0449, 0.0129, 0.0261, 0.0262, 0.0114, 0.0511,\n",
            "         0.0041, 0.0081, 0.7131, 0.0054, 0.0021, 0.0123, 0.0086, 0.0121, 0.0047,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0180, 0.0120, 0.0275, 0.0797, 0.0605, 0.0083, 0.0322, 0.0496, 0.3970,\n",
            "         0.0064, 0.0054, 0.1635, 0.0045, 0.0038, 0.0655, 0.0278, 0.0151, 0.0216,\n",
            "         0.0016]], device='cuda:0')\n",
            "tensor([[0.0362, 0.0279, 0.0985, 0.1393, 0.0227, 0.0465, 0.0151, 0.0106, 0.0307,\n",
            "         0.0144, 0.0137, 0.2636, 0.0065, 0.0058, 0.0361, 0.1402, 0.0481, 0.0385,\n",
            "         0.0056]], device='cuda:0')\n",
            "tensor([[0.0709, 0.0289, 0.0210, 0.0579, 0.0274, 0.0414, 0.0424, 0.0687, 0.0584,\n",
            "         0.0067, 0.0250, 0.4020, 0.0079, 0.0047, 0.0882, 0.0120, 0.0105, 0.0193,\n",
            "         0.0068]], device='cuda:0')\n",
            "tensor([[0.0102, 0.0271, 0.0690, 0.0961, 0.0608, 0.0790, 0.0167, 0.0102, 0.0755,\n",
            "         0.0039, 0.0049, 0.4560, 0.0054, 0.0028, 0.0086, 0.0355, 0.0217, 0.0137,\n",
            "         0.0027]], device='cuda:0')\n",
            "tensor([[0.0185, 0.1938, 0.0657, 0.0256, 0.1500, 0.1513, 0.0183, 0.0163, 0.0576,\n",
            "         0.0050, 0.0052, 0.0109, 0.0115, 0.0068, 0.0078, 0.0271, 0.1757, 0.0474,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0265, 0.0167, 0.0324, 0.0411, 0.0414, 0.0137, 0.0594, 0.0921, 0.1681,\n",
            "         0.0119, 0.0152, 0.2929, 0.0072, 0.0035, 0.1193, 0.0146, 0.0306, 0.0091,\n",
            "         0.0042]], device='cuda:0')\n",
            "tensor([[0.0189, 0.0572, 0.0509, 0.0710, 0.5283, 0.0905, 0.0121, 0.0119, 0.0232,\n",
            "         0.0045, 0.0048, 0.0189, 0.0040, 0.0025, 0.0123, 0.0408, 0.0299, 0.0159,\n",
            "         0.0025]], device='cuda:0')\n",
            "tensor([[0.1037, 0.0276, 0.0509, 0.0513, 0.0421, 0.0779, 0.0305, 0.0990, 0.0730,\n",
            "         0.0093, 0.0396, 0.1244, 0.0219, 0.0067, 0.1221, 0.0226, 0.0507, 0.0383,\n",
            "         0.0084]], device='cuda:0')\n",
            "tensor([[0.0745, 0.0262, 0.0509, 0.0596, 0.0230, 0.0414, 0.0470, 0.0601, 0.0807,\n",
            "         0.0063, 0.0122, 0.1390, 0.0122, 0.0065, 0.2106, 0.0441, 0.0566, 0.0426,\n",
            "         0.0065]], device='cuda:0')\n",
            "tensor([[0.0079, 0.1594, 0.0456, 0.0509, 0.0624, 0.0232, 0.0218, 0.0121, 0.4308,\n",
            "         0.0057, 0.0045, 0.0494, 0.0056, 0.0102, 0.0209, 0.0265, 0.0335, 0.0233,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0135, 0.0565, 0.0757, 0.0788, 0.0915, 0.0519, 0.0160, 0.0187, 0.0217,\n",
            "         0.0132, 0.0071, 0.1037, 0.0090, 0.0076, 0.0097, 0.2288, 0.1309, 0.0607,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0520, 0.0722, 0.0297, 0.0420, 0.0862, 0.0640, 0.0615, 0.0463, 0.1361,\n",
            "         0.0148, 0.0275, 0.1353, 0.0150, 0.0110, 0.1019, 0.0273, 0.0317, 0.0333,\n",
            "         0.0123]], device='cuda:0')\n",
            "tensor([[0.0250, 0.0791, 0.0452, 0.1036, 0.2524, 0.1005, 0.0298, 0.0401, 0.1067,\n",
            "         0.0068, 0.0204, 0.0470, 0.0143, 0.0087, 0.0269, 0.0451, 0.0358, 0.0087,\n",
            "         0.0039]], device='cuda:0')\n",
            "tensor([[0.0313, 0.0525, 0.0349, 0.0995, 0.0204, 0.0232, 0.0562, 0.0214, 0.3601,\n",
            "         0.0040, 0.0136, 0.1876, 0.0095, 0.0065, 0.0358, 0.0204, 0.0128, 0.0055,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0272, 0.1493, 0.0860, 0.0205, 0.0827, 0.1321, 0.0252, 0.0313, 0.1763,\n",
            "         0.0080, 0.0181, 0.0277, 0.0154, 0.0106, 0.0538, 0.0382, 0.0509, 0.0421,\n",
            "         0.0047]], device='cuda:0')\n",
            "tensor([[0.0121, 0.1684, 0.0523, 0.0369, 0.2734, 0.1200, 0.0182, 0.0151, 0.1172,\n",
            "         0.0039, 0.0060, 0.0542, 0.0103, 0.0096, 0.0236, 0.0417, 0.0181, 0.0157,\n",
            "         0.0034]], device='cuda:0')\n",
            "tensor([[0.0223, 0.2312, 0.0705, 0.0325, 0.1213, 0.1413, 0.0187, 0.0365, 0.0488,\n",
            "         0.0044, 0.0114, 0.0479, 0.0127, 0.0079, 0.0243, 0.0716, 0.0483, 0.0428,\n",
            "         0.0056]], device='cuda:0')\n",
            "tensor([[0.0365, 0.0404, 0.0818, 0.1344, 0.0743, 0.1533, 0.0291, 0.0212, 0.0177,\n",
            "         0.0064, 0.0114, 0.0539, 0.0217, 0.0047, 0.0181, 0.0946, 0.1607, 0.0360,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0070, 0.0678, 0.0718, 0.0677, 0.0853, 0.0542, 0.0139, 0.0132, 0.0093,\n",
            "         0.0102, 0.0053, 0.0382, 0.0082, 0.0123, 0.0065, 0.2504, 0.1767, 0.0962,\n",
            "         0.0059]], device='cuda:0')\n",
            "tensor([[0.0085, 0.0533, 0.0899, 0.0742, 0.2909, 0.0497, 0.0262, 0.0052, 0.2884,\n",
            "         0.0022, 0.0030, 0.0301, 0.0039, 0.0031, 0.0126, 0.0216, 0.0240, 0.0108,\n",
            "         0.0023]], device='cuda:0')\n",
            "tensor([[0.0189, 0.1762, 0.0902, 0.0192, 0.1586, 0.0670, 0.0186, 0.0078, 0.1233,\n",
            "         0.0080, 0.0079, 0.0677, 0.0061, 0.0085, 0.0147, 0.0602, 0.0786, 0.0611,\n",
            "         0.0074]], device='cuda:0')\n",
            "tensor([[0.0269, 0.0547, 0.0529, 0.0747, 0.1009, 0.0619, 0.0717, 0.0377, 0.1581,\n",
            "         0.0085, 0.0117, 0.1102, 0.0085, 0.0063, 0.0921, 0.0417, 0.0349, 0.0384,\n",
            "         0.0080]], device='cuda:0')\n",
            "tensor([[0.0585, 0.0449, 0.1223, 0.1039, 0.0447, 0.1267, 0.0324, 0.0385, 0.0076,\n",
            "         0.0045, 0.0087, 0.1883, 0.0124, 0.0056, 0.0221, 0.0539, 0.0915, 0.0284,\n",
            "         0.0052]], device='cuda:0')\n",
            "tensor([[0.0179, 0.0144, 0.0525, 0.0415, 0.0203, 0.0184, 0.0153, 0.0339, 0.0390,\n",
            "         0.0125, 0.0050, 0.2110, 0.0045, 0.0044, 0.0271, 0.1622, 0.1583, 0.1575,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0162, 0.0906, 0.0892, 0.0758, 0.2381, 0.0677, 0.0477, 0.0530, 0.0590,\n",
            "         0.0062, 0.0139, 0.0820, 0.0163, 0.0103, 0.0604, 0.0185, 0.0288, 0.0219,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0081, 0.0434, 0.0471, 0.1246, 0.0433, 0.0542, 0.0291, 0.0225, 0.0558,\n",
            "         0.0038, 0.0083, 0.4615, 0.0094, 0.0054, 0.0166, 0.0241, 0.0254, 0.0133,\n",
            "         0.0040]], device='cuda:0')\n",
            "tensor([[0.0250, 0.0419, 0.0279, 0.0244, 0.0591, 0.0301, 0.0393, 0.0376, 0.2465,\n",
            "         0.0089, 0.0103, 0.1210, 0.0134, 0.0132, 0.2219, 0.0154, 0.0355, 0.0238,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0297, 0.0342, 0.1230, 0.1045, 0.0263, 0.2157, 0.0136, 0.0347, 0.0119,\n",
            "         0.0148, 0.0103, 0.1623, 0.0130, 0.0052, 0.0123, 0.0584, 0.0849, 0.0408,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0240, 0.0900, 0.1044, 0.1186, 0.2196, 0.0670, 0.0208, 0.0129, 0.0235,\n",
            "         0.0076, 0.0083, 0.0160, 0.0202, 0.0102, 0.0217, 0.0588, 0.1290, 0.0420,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0372, 0.0466, 0.0927, 0.1090, 0.0826, 0.0920, 0.0418, 0.0570, 0.0852,\n",
            "         0.0104, 0.0143, 0.0787, 0.0142, 0.0092, 0.0512, 0.0463, 0.0987, 0.0258,\n",
            "         0.0071]], device='cuda:0')\n",
            "tensor([[0.0479, 0.0913, 0.0901, 0.0459, 0.1799, 0.1624, 0.0280, 0.0481, 0.0332,\n",
            "         0.0071, 0.0129, 0.0314, 0.0167, 0.0063, 0.0300, 0.0271, 0.0996, 0.0384,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0142, 0.0060, 0.0260, 0.0170, 0.0096, 0.0067, 0.0116, 0.0260, 0.0281,\n",
            "         0.0072, 0.0074, 0.7607, 0.0036, 0.0021, 0.0345, 0.0079, 0.0181, 0.0112,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0180, 0.0304, 0.0279, 0.0792, 0.0309, 0.0319, 0.0410, 0.0198, 0.4055,\n",
            "         0.0085, 0.0105, 0.1888, 0.0061, 0.0051, 0.0521, 0.0199, 0.0133, 0.0076,\n",
            "         0.0033]], device='cuda:0')\n",
            "tensor([[0.0627, 0.0349, 0.0777, 0.0891, 0.1173, 0.0606, 0.0567, 0.0626, 0.0618,\n",
            "         0.0091, 0.0222, 0.1291, 0.0191, 0.0074, 0.0470, 0.0352, 0.0663, 0.0326,\n",
            "         0.0086]], device='cuda:0')\n",
            "tensor([[0.0354, 0.0619, 0.1206, 0.0382, 0.0522, 0.1483, 0.0111, 0.0118, 0.0067,\n",
            "         0.0099, 0.0079, 0.0180, 0.0113, 0.0099, 0.0092, 0.2326, 0.1084, 0.1005,\n",
            "         0.0061]], device='cuda:0')\n",
            "tensor([[0.0064, 0.0979, 0.0519, 0.0204, 0.6432, 0.0491, 0.0124, 0.0109, 0.0211,\n",
            "         0.0038, 0.0049, 0.0133, 0.0081, 0.0028, 0.0135, 0.0143, 0.0194, 0.0049,\n",
            "         0.0016]], device='cuda:0')\n",
            "tensor([[0.0127, 0.0873, 0.0630, 0.0135, 0.1963, 0.0784, 0.0623, 0.1347, 0.1059,\n",
            "         0.0060, 0.0263, 0.0250, 0.0273, 0.0069, 0.1149, 0.0136, 0.0169, 0.0066,\n",
            "         0.0024]], device='cuda:0')\n",
            "tensor([[0.0183, 0.1395, 0.0382, 0.1257, 0.0453, 0.1632, 0.0748, 0.0137, 0.0465,\n",
            "         0.0095, 0.0112, 0.1530, 0.0061, 0.0059, 0.0094, 0.0739, 0.0373, 0.0197,\n",
            "         0.0088]], device='cuda:0')\n",
            "tensor([[0.0383, 0.0267, 0.0805, 0.0409, 0.0220, 0.0198, 0.0270, 0.0400, 0.0838,\n",
            "         0.0135, 0.0139, 0.3342, 0.0054, 0.0052, 0.1102, 0.0423, 0.0501, 0.0410,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0082, 0.0231, 0.0234, 0.0416, 0.0185, 0.0192, 0.0265, 0.0207, 0.6993,\n",
            "         0.0021, 0.0081, 0.0604, 0.0038, 0.0026, 0.0266, 0.0058, 0.0046, 0.0038,\n",
            "         0.0019]], device='cuda:0')\n",
            "tensor([[0.0078, 0.0280, 0.0480, 0.0804, 0.0299, 0.0299, 0.0448, 0.0401, 0.2195,\n",
            "         0.0044, 0.0137, 0.3692, 0.0100, 0.0048, 0.0353, 0.0100, 0.0135, 0.0081,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0130, 0.0086, 0.0251, 0.0332, 0.0081, 0.0099, 0.0082, 0.0181, 0.0692,\n",
            "         0.0062, 0.0066, 0.7360, 0.0035, 0.0030, 0.0204, 0.0132, 0.0088, 0.0068,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0437, 0.0363, 0.1001, 0.1291, 0.0751, 0.0557, 0.0317, 0.0190, 0.0143,\n",
            "         0.0098, 0.0106, 0.0811, 0.0129, 0.0063, 0.0132, 0.1023, 0.1977, 0.0557,\n",
            "         0.0054]], device='cuda:0')\n",
            "tensor([[0.0203, 0.0457, 0.1063, 0.1649, 0.1764, 0.1038, 0.0408, 0.0324, 0.0148,\n",
            "         0.0069, 0.0074, 0.0861, 0.0231, 0.0037, 0.0138, 0.0779, 0.0592, 0.0143,\n",
            "         0.0024]], device='cuda:0')\n",
            "tensor([[0.0245, 0.0530, 0.0354, 0.0703, 0.1658, 0.0445, 0.0745, 0.0267, 0.2196,\n",
            "         0.0077, 0.0061, 0.0389, 0.0101, 0.0044, 0.0834, 0.0805, 0.0414, 0.0111,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0252, 0.0519, 0.1003, 0.0403, 0.1191, 0.0998, 0.0085, 0.0111, 0.0117,\n",
            "         0.0072, 0.0052, 0.0105, 0.0085, 0.0068, 0.0096, 0.1931, 0.1951, 0.0897,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0120, 0.1248, 0.0486, 0.0541, 0.4188, 0.0562, 0.0284, 0.0251, 0.1135,\n",
            "         0.0019, 0.0064, 0.0197, 0.0109, 0.0051, 0.0293, 0.0238, 0.0134, 0.0059,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0134, 0.0082, 0.0293, 0.0966, 0.0089, 0.0210, 0.0291, 0.0058, 0.0399,\n",
            "         0.0024, 0.0041, 0.7043, 0.0024, 0.0014, 0.0059, 0.0145, 0.0055, 0.0051,\n",
            "         0.0023]], device='cuda:0')\n",
            "tensor([[0.0187, 0.0123, 0.0260, 0.0781, 0.0207, 0.0173, 0.1034, 0.0441, 0.1836,\n",
            "         0.0072, 0.0084, 0.2691, 0.0066, 0.0036, 0.1402, 0.0213, 0.0230, 0.0127,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0413, 0.0492, 0.0942, 0.0434, 0.0970, 0.0872, 0.0188, 0.0207, 0.0325,\n",
            "         0.0104, 0.0129, 0.1199, 0.0155, 0.0097, 0.0208, 0.1007, 0.1385, 0.0823,\n",
            "         0.0049]], device='cuda:0')\n",
            "tensor([[0.0203, 0.0948, 0.0685, 0.0666, 0.0823, 0.0908, 0.0325, 0.0414, 0.1761,\n",
            "         0.0078, 0.0265, 0.1114, 0.0175, 0.0064, 0.0717, 0.0339, 0.0263, 0.0205,\n",
            "         0.0046]], device='cuda:0')\n",
            "tensor([[0.0143, 0.1115, 0.0730, 0.0291, 0.1054, 0.1164, 0.0241, 0.0165, 0.1635,\n",
            "         0.0065, 0.0078, 0.1296, 0.0086, 0.0065, 0.0144, 0.0651, 0.0594, 0.0422,\n",
            "         0.0061]], device='cuda:0')\n",
            "tensor([[0.0190, 0.0743, 0.0555, 0.0260, 0.5003, 0.0890, 0.0236, 0.0379, 0.0110,\n",
            "         0.0079, 0.0075, 0.0210, 0.0124, 0.0053, 0.0124, 0.0315, 0.0451, 0.0169,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[4.5240e-03, 1.1975e-02, 1.3157e-02, 1.8709e-02, 7.7939e-03, 2.3808e-02,\n",
            "         7.7395e-03, 1.0656e-02, 8.5947e-01, 9.3654e-04, 2.6925e-03, 6.2833e-03,\n",
            "         1.4090e-03, 1.2645e-03, 1.6812e-02, 6.5788e-03, 3.0223e-03, 2.6334e-03,\n",
            "         5.3351e-04]], device='cuda:0')\n",
            "tensor([[0.0317, 0.0643, 0.0929, 0.0413, 0.0952, 0.1438, 0.0107, 0.0200, 0.0085,\n",
            "         0.0077, 0.0089, 0.0608, 0.0105, 0.0058, 0.0116, 0.1053, 0.2357, 0.0384,\n",
            "         0.0068]], device='cuda:0')\n",
            "tensor([[0.0319, 0.0354, 0.0778, 0.1089, 0.0366, 0.0676, 0.0158, 0.0101, 0.0266,\n",
            "         0.0047, 0.0051, 0.1821, 0.0075, 0.0044, 0.0096, 0.0772, 0.2056, 0.0883,\n",
            "         0.0047]], device='cuda:0')\n",
            "tensor([[0.0193, 0.0541, 0.1016, 0.0719, 0.2200, 0.0707, 0.0571, 0.0137, 0.1122,\n",
            "         0.0079, 0.0099, 0.0769, 0.0243, 0.0050, 0.0157, 0.0447, 0.0695, 0.0187,\n",
            "         0.0070]], device='cuda:0')\n",
            "tensor([[0.0079, 0.1565, 0.0959, 0.0853, 0.3708, 0.0712, 0.0189, 0.0092, 0.0402,\n",
            "         0.0019, 0.0035, 0.0948, 0.0046, 0.0035, 0.0082, 0.0106, 0.0084, 0.0066,\n",
            "         0.0021]], device='cuda:0')\n",
            "tensor([[0.0134, 0.0772, 0.1140, 0.0516, 0.0245, 0.1017, 0.0145, 0.0156, 0.0169,\n",
            "         0.0086, 0.0080, 0.0732, 0.0125, 0.0139, 0.0099, 0.2210, 0.1224, 0.0940,\n",
            "         0.0072]], device='cuda:0')\n",
            "tensor([[0.0256, 0.0154, 0.0625, 0.0980, 0.0165, 0.0226, 0.0229, 0.0273, 0.0386,\n",
            "         0.0034, 0.0056, 0.5675, 0.0098, 0.0030, 0.0132, 0.0239, 0.0288, 0.0117,\n",
            "         0.0038]], device='cuda:0')\n",
            "tensor([[0.0325, 0.1236, 0.0607, 0.0566, 0.0637, 0.0996, 0.0489, 0.0733, 0.1389,\n",
            "         0.0155, 0.0235, 0.0366, 0.0146, 0.0107, 0.0644, 0.0532, 0.0347, 0.0406,\n",
            "         0.0083]], device='cuda:0')\n",
            "tensor([[0.0088, 0.0658, 0.1333, 0.0761, 0.1212, 0.0330, 0.0089, 0.0152, 0.0302,\n",
            "         0.0092, 0.0030, 0.0151, 0.0067, 0.0069, 0.0196, 0.1731, 0.1485, 0.1203,\n",
            "         0.0052]], device='cuda:0')\n",
            "tensor([[0.0159, 0.1407, 0.0872, 0.1231, 0.1660, 0.1270, 0.0266, 0.0145, 0.0393,\n",
            "         0.0071, 0.0137, 0.0669, 0.0131, 0.0092, 0.0229, 0.0795, 0.0286, 0.0156,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0138, 0.1871, 0.0412, 0.0221, 0.1080, 0.0656, 0.0394, 0.0162, 0.0510,\n",
            "         0.0096, 0.0080, 0.0227, 0.0077, 0.0082, 0.0302, 0.1795, 0.1279, 0.0527,\n",
            "         0.0091]], device='cuda:0')\n",
            "tensor([[0.0201, 0.0480, 0.0396, 0.0802, 0.1623, 0.0458, 0.0422, 0.0164, 0.0668,\n",
            "         0.0113, 0.0059, 0.1042, 0.0065, 0.0058, 0.0148, 0.2338, 0.0542, 0.0380,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0217, 0.0751, 0.0661, 0.0515, 0.1124, 0.0793, 0.0520, 0.0861, 0.0980,\n",
            "         0.0081, 0.0267, 0.1384, 0.0154, 0.0069, 0.1059, 0.0195, 0.0232, 0.0106,\n",
            "         0.0030]], device='cuda:0')\n",
            "tensor([[0.0373, 0.0243, 0.0786, 0.0562, 0.4288, 0.0332, 0.0292, 0.0193, 0.0575,\n",
            "         0.0057, 0.0068, 0.0119, 0.0107, 0.0034, 0.0348, 0.0459, 0.0766, 0.0356,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0317, 0.0211, 0.1289, 0.0397, 0.0357, 0.0095, 0.0254, 0.0210, 0.0962,\n",
            "         0.0112, 0.0073, 0.4011, 0.0051, 0.0049, 0.0561, 0.0324, 0.0439, 0.0245,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0161, 0.0521, 0.0496, 0.0293, 0.0212, 0.0716, 0.0070, 0.0072, 0.0032,\n",
            "         0.0039, 0.0038, 0.0071, 0.0054, 0.0036, 0.0046, 0.2555, 0.3371, 0.1180,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0153, 0.0593, 0.0709, 0.1011, 0.1261, 0.0337, 0.0371, 0.0396, 0.1653,\n",
            "         0.0131, 0.0086, 0.0883, 0.0071, 0.0094, 0.0196, 0.1118, 0.0503, 0.0386,\n",
            "         0.0049]], device='cuda:0')\n",
            "tensor([[0.0214, 0.0627, 0.0981, 0.1877, 0.0642, 0.0629, 0.0461, 0.0240, 0.0744,\n",
            "         0.0151, 0.0102, 0.1984, 0.0097, 0.0060, 0.0112, 0.0450, 0.0351, 0.0227,\n",
            "         0.0049]], device='cuda:0')\n",
            "tensor([[0.0184, 0.0417, 0.1148, 0.0714, 0.0349, 0.0916, 0.0165, 0.0094, 0.0852,\n",
            "         0.0032, 0.0057, 0.4268, 0.0062, 0.0031, 0.0134, 0.0245, 0.0191, 0.0121,\n",
            "         0.0019]], device='cuda:0')\n",
            "tensor([[0.0142, 0.0729, 0.0768, 0.0702, 0.2677, 0.1030, 0.0224, 0.0282, 0.0142,\n",
            "         0.0050, 0.0065, 0.1309, 0.0163, 0.0051, 0.0103, 0.0224, 0.1010, 0.0271,\n",
            "         0.0059]], device='cuda:0')\n",
            "tensor([[0.0207, 0.0203, 0.1091, 0.0890, 0.0378, 0.2102, 0.0072, 0.0092, 0.0018,\n",
            "         0.0031, 0.0031, 0.1818, 0.0113, 0.0027, 0.0019, 0.1157, 0.1542, 0.0180,\n",
            "         0.0030]], device='cuda:0')\n",
            "tensor([[0.0229, 0.0453, 0.1139, 0.1614, 0.0695, 0.0416, 0.0435, 0.0695, 0.1142,\n",
            "         0.0232, 0.0146, 0.0662, 0.0114, 0.0064, 0.0707, 0.0561, 0.0469, 0.0174,\n",
            "         0.0053]], device='cuda:0')\n",
            "tensor([[0.0128, 0.1027, 0.0824, 0.0234, 0.5290, 0.0438, 0.0165, 0.0089, 0.0221,\n",
            "         0.0050, 0.0053, 0.0131, 0.0054, 0.0050, 0.0216, 0.0443, 0.0245, 0.0313,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0230, 0.1237, 0.0820, 0.0525, 0.0643, 0.0668, 0.0199, 0.0434, 0.0485,\n",
            "         0.0145, 0.0164, 0.0346, 0.0208, 0.0338, 0.0649, 0.1254, 0.0751, 0.0799,\n",
            "         0.0106]], device='cuda:0')\n",
            "tensor([[0.0387, 0.0251, 0.0579, 0.0913, 0.0321, 0.0166, 0.0165, 0.0122, 0.5023,\n",
            "         0.0036, 0.0046, 0.1426, 0.0034, 0.0025, 0.0237, 0.0089, 0.0084, 0.0076,\n",
            "         0.0017]], device='cuda:0')\n",
            "tensor([[0.0190, 0.0336, 0.0673, 0.0326, 0.0362, 0.0492, 0.0125, 0.0123, 0.0236,\n",
            "         0.0131, 0.0105, 0.0563, 0.0112, 0.0070, 0.0105, 0.2320, 0.2668, 0.0991,\n",
            "         0.0071]], device='cuda:0')\n",
            "tensor([[0.0281, 0.0642, 0.1271, 0.1078, 0.1433, 0.0782, 0.0250, 0.0340, 0.0187,\n",
            "         0.0093, 0.0098, 0.1275, 0.0141, 0.0060, 0.0223, 0.0791, 0.0825, 0.0188,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0067, 0.0102, 0.0411, 0.0649, 0.0121, 0.0060, 0.0366, 0.0039, 0.0626,\n",
            "         0.0016, 0.0038, 0.7170, 0.0017, 0.0015, 0.0065, 0.0105, 0.0050, 0.0058,\n",
            "         0.0025]], device='cuda:0')\n",
            "tensor([[0.0119, 0.0498, 0.0957, 0.2606, 0.1169, 0.0255, 0.0255, 0.0111, 0.1471,\n",
            "         0.0049, 0.0056, 0.1056, 0.0048, 0.0053, 0.0158, 0.0511, 0.0364, 0.0221,\n",
            "         0.0042]], device='cuda:0')\n",
            "tensor([[0.0086, 0.0152, 0.0247, 0.0518, 0.0190, 0.0118, 0.0214, 0.0193, 0.5952,\n",
            "         0.0026, 0.0023, 0.1336, 0.0038, 0.0026, 0.0481, 0.0110, 0.0184, 0.0085,\n",
            "         0.0022]], device='cuda:0')\n",
            "tensor([[0.0137, 0.0903, 0.0709, 0.0929, 0.0937, 0.0461, 0.0397, 0.0210, 0.1112,\n",
            "         0.0028, 0.0070, 0.3276, 0.0076, 0.0052, 0.0225, 0.0185, 0.0168, 0.0081,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0294, 0.0151, 0.0714, 0.2214, 0.0217, 0.0449, 0.0123, 0.0158, 0.0124,\n",
            "         0.0032, 0.0044, 0.1697, 0.0095, 0.0028, 0.0074, 0.1083, 0.1619, 0.0854,\n",
            "         0.0032]], device='cuda:0')\n",
            "tensor([[0.0150, 0.0078, 0.0139, 0.0191, 0.0080, 0.0044, 0.0123, 0.0081, 0.0242,\n",
            "         0.0044, 0.0042, 0.8496, 0.0023, 0.0013, 0.0115, 0.0049, 0.0039, 0.0041,\n",
            "         0.0012]], device='cuda:0')\n",
            "tensor([[0.0379, 0.0369, 0.0738, 0.2065, 0.0562, 0.0462, 0.0815, 0.0128, 0.1148,\n",
            "         0.0108, 0.0108, 0.1738, 0.0111, 0.0058, 0.0207, 0.0387, 0.0318, 0.0227,\n",
            "         0.0072]], device='cuda:0')\n",
            "tensor([[0.0149, 0.0366, 0.0851, 0.1951, 0.0261, 0.0237, 0.0133, 0.0040, 0.0042,\n",
            "         0.0048, 0.0046, 0.5033, 0.0042, 0.0035, 0.0028, 0.0489, 0.0128, 0.0093,\n",
            "         0.0028]], device='cuda:0')\n",
            "tensor([[0.0146, 0.0651, 0.0558, 0.1820, 0.2887, 0.0876, 0.0271, 0.0119, 0.0229,\n",
            "         0.0072, 0.0049, 0.0250, 0.0072, 0.0046, 0.0070, 0.0989, 0.0448, 0.0419,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0057, 0.0596, 0.0363, 0.0549, 0.0942, 0.0358, 0.0276, 0.0522, 0.2979,\n",
            "         0.0028, 0.0122, 0.1666, 0.0111, 0.0044, 0.1116, 0.0122, 0.0066, 0.0065,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0285, 0.1044, 0.0570, 0.0315, 0.1993, 0.0812, 0.0195, 0.0223, 0.2402,\n",
            "         0.0041, 0.0134, 0.0713, 0.0101, 0.0064, 0.0226, 0.0214, 0.0382, 0.0217,\n",
            "         0.0071]], device='cuda:0')\n",
            "tensor([[0.0106, 0.0553, 0.0380, 0.2021, 0.1221, 0.0196, 0.0184, 0.0100, 0.2492,\n",
            "         0.0045, 0.0042, 0.0312, 0.0053, 0.0061, 0.0296, 0.1434, 0.0232, 0.0241,\n",
            "         0.0030]], device='cuda:0')\n",
            "tensor([[0.0259, 0.1327, 0.0700, 0.0389, 0.1788, 0.1893, 0.0359, 0.0226, 0.0160,\n",
            "         0.0108, 0.0212, 0.0742, 0.0195, 0.0096, 0.0143, 0.0584, 0.0435, 0.0324,\n",
            "         0.0060]], device='cuda:0')\n",
            "tensor([[0.0296, 0.0302, 0.0420, 0.0383, 0.0415, 0.0723, 0.0795, 0.1015, 0.2132,\n",
            "         0.0144, 0.0198, 0.2201, 0.0179, 0.0055, 0.0492, 0.0058, 0.0095, 0.0065,\n",
            "         0.0033]], device='cuda:0')\n",
            "tensor([[0.0141, 0.0880, 0.1598, 0.2556, 0.0662, 0.1224, 0.0422, 0.0072, 0.0331,\n",
            "         0.0024, 0.0040, 0.0538, 0.0072, 0.0043, 0.0038, 0.0662, 0.0481, 0.0191,\n",
            "         0.0027]], device='cuda:0')\n",
            "tensor([[0.0222, 0.0444, 0.1271, 0.1605, 0.0531, 0.0670, 0.0214, 0.0349, 0.0798,\n",
            "         0.0166, 0.0099, 0.0813, 0.0104, 0.0035, 0.0272, 0.0453, 0.1554, 0.0332,\n",
            "         0.0069]], device='cuda:0')\n",
            "tensor([[0.0119, 0.0643, 0.1137, 0.1574, 0.1247, 0.0403, 0.0263, 0.0082, 0.0470,\n",
            "         0.0057, 0.0065, 0.2440, 0.0061, 0.0093, 0.0099, 0.0404, 0.0554, 0.0233,\n",
            "         0.0056]], device='cuda:0')\n",
            "tensor([[0.0117, 0.2764, 0.1002, 0.0549, 0.1020, 0.1184, 0.0352, 0.0309, 0.1070,\n",
            "         0.0046, 0.0068, 0.0148, 0.0132, 0.0082, 0.0292, 0.0357, 0.0238, 0.0222,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0172, 0.0551, 0.0796, 0.0894, 0.2819, 0.0451, 0.0191, 0.0191, 0.0481,\n",
            "         0.0074, 0.0075, 0.0847, 0.0131, 0.0071, 0.0231, 0.0732, 0.0814, 0.0402,\n",
            "         0.0078]], device='cuda:0')\n",
            "tensor([[0.0236, 0.0539, 0.0652, 0.0409, 0.0256, 0.0281, 0.0099, 0.0173, 0.0480,\n",
            "         0.0148, 0.0090, 0.0164, 0.0073, 0.0109, 0.0728, 0.1579, 0.1426, 0.2479,\n",
            "         0.0079]], device='cuda:0')\n",
            "tensor([[0.0101, 0.1414, 0.0579, 0.0522, 0.3907, 0.1370, 0.0109, 0.0043, 0.0123,\n",
            "         0.0027, 0.0032, 0.0163, 0.0061, 0.0026, 0.0033, 0.0462, 0.0687, 0.0301,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0185, 0.0206, 0.0801, 0.0362, 0.0135, 0.0691, 0.0059, 0.0141, 0.0033,\n",
            "         0.0062, 0.0048, 0.0158, 0.0070, 0.0042, 0.0072, 0.1971, 0.3508, 0.1417,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0642, 0.0688, 0.0972, 0.0968, 0.1667, 0.0911, 0.0288, 0.0406, 0.1505,\n",
            "         0.0028, 0.0076, 0.0711, 0.0105, 0.0044, 0.0141, 0.0335, 0.0311, 0.0168,\n",
            "         0.0034]], device='cuda:0')\n",
            "tensor([[0.0273, 0.0442, 0.0676, 0.0887, 0.0550, 0.0844, 0.0419, 0.0832, 0.0404,\n",
            "         0.0396, 0.0200, 0.0474, 0.0101, 0.0094, 0.0447, 0.0624, 0.1552, 0.0660,\n",
            "         0.0124]], device='cuda:0')\n",
            "tensor([[0.0173, 0.0566, 0.0501, 0.0353, 0.4423, 0.0339, 0.0207, 0.0106, 0.0335,\n",
            "         0.0102, 0.0072, 0.0174, 0.0092, 0.0089, 0.0227, 0.0891, 0.1077, 0.0222,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0219, 0.0320, 0.0302, 0.0759, 0.0348, 0.0425, 0.1627, 0.0623, 0.2462,\n",
            "         0.0213, 0.0273, 0.0861, 0.0134, 0.0068, 0.1036, 0.0105, 0.0099, 0.0076,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.1071, 0.0311, 0.0470, 0.0185, 0.0398, 0.0393, 0.0234, 0.2334, 0.0552,\n",
            "         0.0059, 0.0289, 0.0578, 0.0166, 0.0068, 0.2331, 0.0122, 0.0179, 0.0214,\n",
            "         0.0046]], device='cuda:0')\n",
            "tensor([[0.0108, 0.0959, 0.0815, 0.0765, 0.3656, 0.0654, 0.0262, 0.0070, 0.0517,\n",
            "         0.0060, 0.0025, 0.0152, 0.0113, 0.0060, 0.0175, 0.0542, 0.0818, 0.0217,\n",
            "         0.0033]], device='cuda:0')\n",
            "tensor([[0.0141, 0.0461, 0.0342, 0.0228, 0.0745, 0.0447, 0.0705, 0.0968, 0.3632,\n",
            "         0.0096, 0.0198, 0.0387, 0.0147, 0.0122, 0.0881, 0.0151, 0.0174, 0.0140,\n",
            "         0.0034]], device='cuda:0')\n",
            "tensor([[0.0198, 0.0707, 0.1021, 0.1014, 0.1430, 0.0301, 0.0968, 0.0355, 0.0518,\n",
            "         0.0081, 0.0125, 0.1692, 0.0176, 0.0078, 0.0326, 0.0436, 0.0367, 0.0171,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0079, 0.0769, 0.0487, 0.0532, 0.0668, 0.0555, 0.0120, 0.0054, 0.0197,\n",
            "         0.0048, 0.0039, 0.0093, 0.0036, 0.0028, 0.0049, 0.2262, 0.2640, 0.1293,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0555, 0.0325, 0.0814, 0.1055, 0.0307, 0.0642, 0.0323, 0.0324, 0.0270,\n",
            "         0.0069, 0.0113, 0.1445, 0.0124, 0.0075, 0.0231, 0.0718, 0.1541, 0.0995,\n",
            "         0.0075]], device='cuda:0')\n",
            "tensor([[0.0258, 0.0105, 0.0220, 0.0546, 0.0128, 0.0189, 0.0409, 0.0383, 0.0246,\n",
            "         0.0130, 0.0147, 0.6549, 0.0055, 0.0045, 0.0212, 0.0132, 0.0140, 0.0075,\n",
            "         0.0031]], device='cuda:0')\n",
            "tensor([[0.0305, 0.1117, 0.0426, 0.0339, 0.3262, 0.1181, 0.0318, 0.0237, 0.0946,\n",
            "         0.0087, 0.0163, 0.0481, 0.0135, 0.0091, 0.0312, 0.0224, 0.0198, 0.0100,\n",
            "         0.0075]], device='cuda:0')\n",
            "tensor([[0.0228, 0.0656, 0.1582, 0.0426, 0.0960, 0.0923, 0.0373, 0.0363, 0.0150,\n",
            "         0.0077, 0.0096, 0.1421, 0.0159, 0.0091, 0.0232, 0.0671, 0.1166, 0.0325,\n",
            "         0.0102]], device='cuda:0')\n",
            "tensor([[0.0631, 0.0480, 0.0735, 0.1401, 0.0346, 0.0946, 0.0205, 0.0286, 0.0190,\n",
            "         0.0104, 0.0120, 0.1200, 0.0138, 0.0075, 0.0136, 0.1115, 0.1133, 0.0696,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0106, 0.0905, 0.1317, 0.0965, 0.0860, 0.1215, 0.0297, 0.0390, 0.0295,\n",
            "         0.0094, 0.0112, 0.0407, 0.0235, 0.0095, 0.0102, 0.0595, 0.1663, 0.0250,\n",
            "         0.0098]], device='cuda:0')\n",
            "tensor([[0.0228, 0.0185, 0.0146, 0.0221, 0.0157, 0.0216, 0.0836, 0.1333, 0.3452,\n",
            "         0.0144, 0.0284, 0.0224, 0.0067, 0.0040, 0.2193, 0.0084, 0.0101, 0.0054,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0321, 0.1399, 0.0709, 0.0722, 0.1849, 0.0424, 0.0168, 0.0277, 0.1034,\n",
            "         0.0019, 0.0029, 0.1500, 0.0016, 0.0035, 0.0573, 0.0422, 0.0345, 0.0153,\n",
            "         0.0006]], device='cuda:0')\n",
            "tensor([[0.0220, 0.0049, 0.0263, 0.0358, 0.0056, 0.0078, 0.0150, 0.0105, 0.0039,\n",
            "         0.0045, 0.0041, 0.8052, 0.0045, 0.0020, 0.0109, 0.0092, 0.0179, 0.0069,\n",
            "         0.0027]], device='cuda:0')\n",
            "tensor([[0.0613, 0.0575, 0.0673, 0.0521, 0.0318, 0.0419, 0.0725, 0.0801, 0.0748,\n",
            "         0.0274, 0.0450, 0.1364, 0.0114, 0.0100, 0.0764, 0.0514, 0.0485, 0.0457,\n",
            "         0.0083]], device='cuda:0')\n",
            "tensor([[0.0031, 0.0227, 0.0086, 0.0075, 0.0419, 0.0071, 0.0127, 0.0107, 0.8212,\n",
            "         0.0012, 0.0047, 0.0107, 0.0031, 0.0017, 0.0317, 0.0049, 0.0031, 0.0021,\n",
            "         0.0014]], device='cuda:0')\n",
            "tensor([[0.0299, 0.0719, 0.0843, 0.0306, 0.1477, 0.0650, 0.0218, 0.0491, 0.0434,\n",
            "         0.0108, 0.0127, 0.0439, 0.0190, 0.0138, 0.0584, 0.0977, 0.1256, 0.0684,\n",
            "         0.0060]], device='cuda:0')\n",
            "tensor([[0.0244, 0.0526, 0.1196, 0.0617, 0.2528, 0.0684, 0.0208, 0.0216, 0.0138,\n",
            "         0.0243, 0.0104, 0.0690, 0.0079, 0.0048, 0.0071, 0.0825, 0.0977, 0.0546,\n",
            "         0.0060]], device='cuda:0')\n",
            "tensor([[0.0517, 0.0563, 0.0346, 0.0204, 0.0766, 0.0378, 0.0317, 0.0633, 0.1582,\n",
            "         0.0092, 0.0233, 0.0320, 0.0082, 0.0105, 0.2765, 0.0345, 0.0372, 0.0323,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0082, 0.0790, 0.0388, 0.0153, 0.0614, 0.0387, 0.0180, 0.0543, 0.4911,\n",
            "         0.0042, 0.0109, 0.0540, 0.0129, 0.0080, 0.0712, 0.0093, 0.0071, 0.0147,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0319, 0.0837, 0.0468, 0.0500, 0.1136, 0.0827, 0.0504, 0.0530, 0.0814,\n",
            "         0.0110, 0.0400, 0.1136, 0.0275, 0.0174, 0.0916, 0.0274, 0.0399, 0.0264,\n",
            "         0.0116]], device='cuda:0')\n",
            "tensor([[0.0319, 0.1040, 0.1436, 0.1624, 0.0771, 0.1460, 0.0440, 0.0203, 0.0281,\n",
            "         0.0055, 0.0085, 0.0594, 0.0148, 0.0063, 0.0061, 0.0525, 0.0552, 0.0291,\n",
            "         0.0053]], device='cuda:0')\n",
            "tensor([[0.0064, 0.0037, 0.0108, 0.0179, 0.0041, 0.0024, 0.0057, 0.0039, 0.0073,\n",
            "         0.0020, 0.0018, 0.9030, 0.0014, 0.0010, 0.0054, 0.0065, 0.0091, 0.0067,\n",
            "         0.0010]], device='cuda:0')\n",
            "tensor([[3.7148e-03, 2.1043e-03, 7.5445e-03, 1.3888e-02, 3.5140e-03, 3.8583e-03,\n",
            "         1.0469e-02, 1.6904e-03, 2.0406e-02, 1.3140e-03, 1.7818e-03, 9.1670e-01,\n",
            "         8.5899e-04, 4.9169e-04, 2.7385e-03, 3.6591e-03, 2.3993e-03, 1.7854e-03,\n",
            "         1.0829e-03]], device='cuda:0')\n",
            "tensor([[0.0273, 0.1192, 0.0763, 0.0799, 0.1612, 0.0738, 0.0431, 0.0210, 0.1561,\n",
            "         0.0081, 0.0114, 0.0409, 0.0075, 0.0115, 0.0396, 0.0519, 0.0393, 0.0276,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[0.0188, 0.0994, 0.0488, 0.0341, 0.3356, 0.1369, 0.0285, 0.0343, 0.0607,\n",
            "         0.0057, 0.0141, 0.0366, 0.0182, 0.0094, 0.0149, 0.0539, 0.0325, 0.0143,\n",
            "         0.0031]], device='cuda:0')\n",
            "tensor([[0.0095, 0.0940, 0.0441, 0.0188, 0.4918, 0.0918, 0.0157, 0.0126, 0.0311,\n",
            "         0.0052, 0.0064, 0.0058, 0.0134, 0.0058, 0.0122, 0.0501, 0.0667, 0.0202,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0205, 0.0635, 0.1489, 0.2064, 0.1023, 0.0722, 0.0246, 0.0094, 0.0231,\n",
            "         0.0048, 0.0051, 0.0496, 0.0083, 0.0055, 0.0089, 0.1285, 0.0676, 0.0469,\n",
            "         0.0039]], device='cuda:0')\n",
            "tensor([[0.0127, 0.0770, 0.0182, 0.0482, 0.4167, 0.0480, 0.0150, 0.0124, 0.0381,\n",
            "         0.0085, 0.0064, 0.0121, 0.0050, 0.0043, 0.0234, 0.1673, 0.0384, 0.0448,\n",
            "         0.0035]], device='cuda:0')\n",
            "tensor([[0.0123, 0.1693, 0.0477, 0.0186, 0.4414, 0.1132, 0.0176, 0.0160, 0.0236,\n",
            "         0.0057, 0.0106, 0.0073, 0.0203, 0.0079, 0.0146, 0.0244, 0.0355, 0.0107,\n",
            "         0.0032]], device='cuda:0')\n",
            "tensor([[0.0147, 0.0111, 0.0147, 0.0178, 0.0305, 0.0053, 0.0315, 0.0063, 0.7332,\n",
            "         0.0023, 0.0031, 0.0503, 0.0015, 0.0012, 0.0605, 0.0072, 0.0038, 0.0038,\n",
            "         0.0011]], device='cuda:0')\n",
            "tensor([[0.0414, 0.0058, 0.0246, 0.0236, 0.0103, 0.0177, 0.0418, 0.1196, 0.2443,\n",
            "         0.0063, 0.0240, 0.0903, 0.0096, 0.0042, 0.2868, 0.0127, 0.0182, 0.0150,\n",
            "         0.0038]], device='cuda:0')\n",
            "tensor([[0.0154, 0.0600, 0.0344, 0.0798, 0.0363, 0.0789, 0.0289, 0.0112, 0.4562,\n",
            "         0.0042, 0.0074, 0.0283, 0.0070, 0.0050, 0.1038, 0.0185, 0.0092, 0.0124,\n",
            "         0.0029]], device='cuda:0')\n",
            "tensor([[0.0222, 0.1312, 0.1221, 0.0433, 0.0824, 0.1463, 0.0263, 0.0277, 0.0371,\n",
            "         0.0081, 0.0128, 0.0727, 0.0150, 0.0160, 0.0304, 0.0828, 0.0590, 0.0557,\n",
            "         0.0088]], device='cuda:0')\n",
            "tensor([[0.0134, 0.1789, 0.0586, 0.0414, 0.0773, 0.1504, 0.0198, 0.0150, 0.0202,\n",
            "         0.0100, 0.0068, 0.0071, 0.0145, 0.0117, 0.0219, 0.1734, 0.1210, 0.0509,\n",
            "         0.0077]], device='cuda:0')\n",
            "tensor([[0.0279, 0.1131, 0.1955, 0.0740, 0.2307, 0.0966, 0.0117, 0.0126, 0.0073,\n",
            "         0.0048, 0.0051, 0.0280, 0.0091, 0.0058, 0.0072, 0.0735, 0.0575, 0.0358,\n",
            "         0.0040]], device='cuda:0')\n",
            "tensor([[0.0209, 0.0759, 0.1273, 0.0516, 0.2153, 0.1137, 0.0117, 0.0060, 0.0135,\n",
            "         0.0064, 0.0037, 0.0368, 0.0066, 0.0053, 0.0043, 0.1656, 0.0916, 0.0405,\n",
            "         0.0033]], device='cuda:0')\n",
            "tensor([[0.0196, 0.1598, 0.0709, 0.0556, 0.2223, 0.1149, 0.0276, 0.0348, 0.0118,\n",
            "         0.0079, 0.0115, 0.0186, 0.0168, 0.0057, 0.0165, 0.0654, 0.0948, 0.0420,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0158, 0.0424, 0.0704, 0.0346, 0.0683, 0.0253, 0.0060, 0.0051, 0.0085,\n",
            "         0.0054, 0.0033, 0.0149, 0.0086, 0.0046, 0.0109, 0.2453, 0.3640, 0.0627,\n",
            "         0.0038]], device='cuda:0')\n",
            "tensor([[0.0095, 0.0297, 0.0336, 0.0189, 0.0455, 0.0495, 0.0239, 0.1453, 0.4081,\n",
            "         0.0035, 0.0165, 0.0394, 0.0179, 0.0043, 0.1350, 0.0056, 0.0089, 0.0028,\n",
            "         0.0021]], device='cuda:0')\n",
            "tensor([[0.0400, 0.0424, 0.0776, 0.1210, 0.2526, 0.0507, 0.0199, 0.0093, 0.0152,\n",
            "         0.0109, 0.0080, 0.0516, 0.0089, 0.0044, 0.0115, 0.1393, 0.0814, 0.0512,\n",
            "         0.0040]], device='cuda:0')\n",
            "tensor([[0.0405, 0.0612, 0.0533, 0.0694, 0.0679, 0.0652, 0.0705, 0.0436, 0.0326,\n",
            "         0.0370, 0.0128, 0.2050, 0.0106, 0.0062, 0.0266, 0.0785, 0.0661, 0.0483,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0149, 0.1786, 0.1089, 0.0331, 0.0738, 0.0891, 0.0240, 0.0258, 0.0599,\n",
            "         0.0089, 0.0068, 0.1080, 0.0138, 0.0076, 0.0118, 0.0655, 0.1178, 0.0430,\n",
            "         0.0087]], device='cuda:0')\n",
            "tensor([[0.0296, 0.0349, 0.0292, 0.0755, 0.0549, 0.0605, 0.0698, 0.0232, 0.2243,\n",
            "         0.0087, 0.0112, 0.2186, 0.0095, 0.0086, 0.0965, 0.0141, 0.0126, 0.0116,\n",
            "         0.0066]], device='cuda:0')\n",
            "tensor([[0.0330, 0.0295, 0.1067, 0.0755, 0.0347, 0.1441, 0.0067, 0.0115, 0.0046,\n",
            "         0.0068, 0.0057, 0.0865, 0.0078, 0.0049, 0.0035, 0.1464, 0.2017, 0.0863,\n",
            "         0.0042]], device='cuda:0')\n",
            "tensor([[0.0328, 0.0255, 0.0689, 0.1862, 0.0298, 0.0485, 0.0383, 0.0241, 0.0256,\n",
            "         0.0238, 0.0125, 0.1018, 0.0073, 0.0073, 0.0198, 0.1145, 0.1498, 0.0760,\n",
            "         0.0074]], device='cuda:0')\n",
            "tensor([[0.0178, 0.1078, 0.0572, 0.0786, 0.2587, 0.0725, 0.0228, 0.0114, 0.0383,\n",
            "         0.0117, 0.0093, 0.0531, 0.0133, 0.0096, 0.0171, 0.0999, 0.0737, 0.0411,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0203, 0.0840, 0.1242, 0.1067, 0.0997, 0.0501, 0.0105, 0.0100, 0.0232,\n",
            "         0.0150, 0.0067, 0.0513, 0.0089, 0.0058, 0.0256, 0.1109, 0.1671, 0.0706,\n",
            "         0.0096]], device='cuda:0')\n",
            "tensor([[0.0112, 0.0063, 0.0090, 0.0225, 0.0082, 0.0109, 0.0225, 0.0184, 0.6226,\n",
            "         0.0020, 0.0059, 0.1097, 0.0024, 0.0016, 0.1357, 0.0045, 0.0019, 0.0037,\n",
            "         0.0013]], device='cuda:0')\n",
            "tensor([[0.0162, 0.1080, 0.1858, 0.1539, 0.1187, 0.0395, 0.0193, 0.0115, 0.0917,\n",
            "         0.0039, 0.0038, 0.0972, 0.0033, 0.0063, 0.0186, 0.0483, 0.0457, 0.0256,\n",
            "         0.0028]], device='cuda:0')\n",
            "tensor([[0.0798, 0.0677, 0.0764, 0.0700, 0.1171, 0.0428, 0.0418, 0.0405, 0.0379,\n",
            "         0.0211, 0.0190, 0.1257, 0.0159, 0.0119, 0.0560, 0.0393, 0.0754, 0.0516,\n",
            "         0.0101]], device='cuda:0')\n",
            "tensor([[0.0145, 0.0367, 0.0719, 0.0648, 0.0438, 0.0308, 0.0195, 0.0124, 0.0922,\n",
            "         0.0112, 0.0067, 0.1966, 0.0085, 0.0041, 0.0131, 0.1286, 0.1817, 0.0570,\n",
            "         0.0061]], device='cuda:0')\n",
            "tensor([[0.0090, 0.0483, 0.0386, 0.1396, 0.1667, 0.0832, 0.0097, 0.0101, 0.0083,\n",
            "         0.0060, 0.0035, 0.0132, 0.0051, 0.0033, 0.0050, 0.3210, 0.0682, 0.0583,\n",
            "         0.0030]], device='cuda:0')\n",
            "tensor([[0.0103, 0.1529, 0.1248, 0.0539, 0.2594, 0.0303, 0.0384, 0.0189, 0.0498,\n",
            "         0.0037, 0.0065, 0.1433, 0.0058, 0.0040, 0.0305, 0.0274, 0.0246, 0.0120,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0296, 0.1432, 0.0634, 0.0468, 0.1587, 0.1496, 0.0446, 0.0272, 0.0252,\n",
            "         0.0193, 0.0241, 0.1140, 0.0198, 0.0129, 0.0112, 0.0346, 0.0378, 0.0217,\n",
            "         0.0162]], device='cuda:0')\n",
            "tensor([[0.0149, 0.0492, 0.0880, 0.1490, 0.0253, 0.0973, 0.0161, 0.0107, 0.0103,\n",
            "         0.0046, 0.0051, 0.1058, 0.0078, 0.0064, 0.0128, 0.1239, 0.1785, 0.0889,\n",
            "         0.0054]], device='cuda:0')\n",
            "tensor([[0.0220, 0.1007, 0.0513, 0.0141, 0.0927, 0.0466, 0.0143, 0.0140, 0.0196,\n",
            "         0.0180, 0.0074, 0.0269, 0.0073, 0.0058, 0.0155, 0.1518, 0.3176, 0.0669,\n",
            "         0.0076]], device='cuda:0')\n",
            "tensor([[0.0450, 0.0992, 0.0669, 0.1437, 0.0955, 0.0595, 0.0226, 0.0427, 0.0901,\n",
            "         0.0069, 0.0295, 0.0244, 0.0120, 0.0070, 0.1167, 0.0585, 0.0356, 0.0367,\n",
            "         0.0077]], device='cuda:0')\n",
            "tensor([[0.0081, 0.0138, 0.0134, 0.0163, 0.0278, 0.0200, 0.0245, 0.0413, 0.6025,\n",
            "         0.0025, 0.0105, 0.0299, 0.0040, 0.0021, 0.1676, 0.0039, 0.0060, 0.0041,\n",
            "         0.0017]], device='cuda:0')\n",
            "tensor([[0.0229, 0.2159, 0.1066, 0.0581, 0.1938, 0.0687, 0.0195, 0.0195, 0.0550,\n",
            "         0.0033, 0.0046, 0.0409, 0.0032, 0.0065, 0.0395, 0.0538, 0.0573, 0.0295,\n",
            "         0.0015]], device='cuda:0')\n",
            "tensor([[0.0120, 0.0454, 0.0560, 0.0596, 0.1082, 0.0152, 0.0369, 0.0212, 0.4232,\n",
            "         0.0038, 0.0071, 0.0442, 0.0043, 0.0050, 0.0891, 0.0217, 0.0236, 0.0201,\n",
            "         0.0034]], device='cuda:0')\n",
            "tensor([[0.0299, 0.0555, 0.0413, 0.0622, 0.0252, 0.0981, 0.0566, 0.0141, 0.1817,\n",
            "         0.0069, 0.0098, 0.2781, 0.0061, 0.0047, 0.0129, 0.0540, 0.0271, 0.0277,\n",
            "         0.0082]], device='cuda:0')\n",
            "tensor([[0.0434, 0.0279, 0.0877, 0.1788, 0.0632, 0.1456, 0.0269, 0.0219, 0.0156,\n",
            "         0.0120, 0.0097, 0.0560, 0.0135, 0.0042, 0.0142, 0.0920, 0.1443, 0.0362,\n",
            "         0.0068]], device='cuda:0')\n",
            "tensor([[0.0300, 0.0426, 0.0870, 0.0600, 0.0343, 0.0272, 0.0261, 0.0373, 0.0901,\n",
            "         0.0168, 0.0100, 0.0783, 0.0064, 0.0055, 0.0664, 0.1372, 0.1202, 0.1197,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0129, 0.0412, 0.0615, 0.0238, 0.1067, 0.0450, 0.0264, 0.0421, 0.1822,\n",
            "         0.0073, 0.0143, 0.2431, 0.0139, 0.0112, 0.0589, 0.0242, 0.0460, 0.0328,\n",
            "         0.0063]], device='cuda:0')\n",
            "tensor([[0.0234, 0.0257, 0.1591, 0.2131, 0.0431, 0.0820, 0.0130, 0.0136, 0.0133,\n",
            "         0.0124, 0.0105, 0.0137, 0.0135, 0.0070, 0.0150, 0.1465, 0.1297, 0.0583,\n",
            "         0.0073]], device='cuda:0')\n",
            "tensor([[0.0151, 0.0143, 0.1124, 0.0802, 0.0210, 0.0374, 0.0218, 0.0051, 0.0256,\n",
            "         0.0045, 0.0057, 0.5847, 0.0039, 0.0029, 0.0046, 0.0329, 0.0166, 0.0087,\n",
            "         0.0027]], device='cuda:0')\n",
            "tensor([[0.0126, 0.1297, 0.0913, 0.0435, 0.0602, 0.1841, 0.0104, 0.0083, 0.0088,\n",
            "         0.0029, 0.0051, 0.0225, 0.0055, 0.0039, 0.0042, 0.2744, 0.0872, 0.0433,\n",
            "         0.0022]], device='cuda:0')\n",
            "tensor([[0.0689, 0.0433, 0.0324, 0.0584, 0.0908, 0.0557, 0.0496, 0.0568, 0.0479,\n",
            "         0.0204, 0.0233, 0.1641, 0.0096, 0.0058, 0.0881, 0.0785, 0.0521, 0.0449,\n",
            "         0.0093]], device='cuda:0')\n",
            "tensor([[0.0363, 0.0580, 0.0507, 0.0418, 0.1169, 0.0469, 0.0627, 0.0365, 0.3276,\n",
            "         0.0084, 0.0109, 0.0548, 0.0092, 0.0074, 0.0838, 0.0182, 0.0162, 0.0102,\n",
            "         0.0033]], device='cuda:0')\n",
            "tensor([[0.0090, 0.1145, 0.0308, 0.0517, 0.2685, 0.0721, 0.0243, 0.0398, 0.1869,\n",
            "         0.0029, 0.0084, 0.0242, 0.0093, 0.0056, 0.0455, 0.0750, 0.0163, 0.0138,\n",
            "         0.0016]], device='cuda:0')\n",
            "tensor([[0.0258, 0.0403, 0.0472, 0.0384, 0.0580, 0.0346, 0.0146, 0.0249, 0.0233,\n",
            "         0.0165, 0.0114, 0.1491, 0.0090, 0.0068, 0.0527, 0.0641, 0.3051, 0.0666,\n",
            "         0.0117]], device='cuda:0')\n",
            "tensor([[0.0216, 0.0923, 0.1081, 0.1724, 0.1463, 0.0886, 0.0269, 0.0209, 0.0190,\n",
            "         0.0081, 0.0071, 0.0614, 0.0135, 0.0033, 0.0142, 0.0333, 0.1138, 0.0439,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0861, 0.0212, 0.0328, 0.0609, 0.0335, 0.0264, 0.0309, 0.1062, 0.1342,\n",
            "         0.0063, 0.0184, 0.1150, 0.0104, 0.0054, 0.2023, 0.0374, 0.0399, 0.0271,\n",
            "         0.0056]], device='cuda:0')\n",
            "tensor([[0.0086, 0.0107, 0.0177, 0.0261, 0.0033, 0.0044, 0.0461, 0.0169, 0.6339,\n",
            "         0.0024, 0.0087, 0.1257, 0.0021, 0.0015, 0.0756, 0.0085, 0.0024, 0.0038,\n",
            "         0.0016]], device='cuda:0')\n",
            "tensor([[0.0057, 0.0120, 0.0185, 0.0215, 0.0039, 0.0088, 0.0177, 0.0098, 0.8207,\n",
            "         0.0021, 0.0044, 0.0417, 0.0019, 0.0016, 0.0176, 0.0055, 0.0029, 0.0028,\n",
            "         0.0013]], device='cuda:0')\n",
            "tensor([[0.0038, 0.0208, 0.0622, 0.0566, 0.0113, 0.0107, 0.0055, 0.0053, 0.0138,\n",
            "         0.0039, 0.0033, 0.6524, 0.0032, 0.0033, 0.0117, 0.0346, 0.0740, 0.0205,\n",
            "         0.0032]], device='cuda:0')\n",
            "tensor([[0.0117, 0.0449, 0.1011, 0.0725, 0.0498, 0.0499, 0.0130, 0.0217, 0.0195,\n",
            "         0.0112, 0.0093, 0.2491, 0.0214, 0.0132, 0.0196, 0.0872, 0.1524, 0.0444,\n",
            "         0.0080]], device='cuda:0')\n",
            "tensor([[0.0190, 0.1201, 0.1044, 0.1323, 0.0890, 0.1206, 0.0185, 0.0113, 0.0217,\n",
            "         0.0082, 0.0119, 0.0598, 0.0119, 0.0084, 0.0189, 0.1200, 0.0896, 0.0263,\n",
            "         0.0080]], device='cuda:0')\n",
            "tensor([[0.0149, 0.0967, 0.0671, 0.0775, 0.1899, 0.0284, 0.0147, 0.0295, 0.3051,\n",
            "         0.0045, 0.0068, 0.0285, 0.0041, 0.0039, 0.0482, 0.0421, 0.0172, 0.0193,\n",
            "         0.0016]], device='cuda:0')\n",
            "tensor([[0.0914, 0.0128, 0.0323, 0.0480, 0.0186, 0.0248, 0.0331, 0.0608, 0.1497,\n",
            "         0.0041, 0.0096, 0.1170, 0.0099, 0.0042, 0.3241, 0.0154, 0.0258, 0.0148,\n",
            "         0.0035]], device='cuda:0')\n",
            "tensor([[0.0463, 0.0181, 0.0245, 0.0267, 0.0067, 0.0371, 0.0394, 0.1792, 0.0965,\n",
            "         0.0083, 0.0271, 0.0879, 0.0102, 0.0066, 0.2601, 0.0230, 0.0706, 0.0260,\n",
            "         0.0059]], device='cuda:0')\n",
            "tensor([[0.0259, 0.0828, 0.0716, 0.0346, 0.0469, 0.1054, 0.0234, 0.0787, 0.0676,\n",
            "         0.0114, 0.0277, 0.2162, 0.0234, 0.0110, 0.0630, 0.0319, 0.0522, 0.0210,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0461, 0.0277, 0.0725, 0.1759, 0.0214, 0.0353, 0.0384, 0.0287, 0.0248,\n",
            "         0.0147, 0.0131, 0.4082, 0.0072, 0.0061, 0.0254, 0.0160, 0.0204, 0.0148,\n",
            "         0.0032]], device='cuda:0')\n",
            "tensor([[0.0105, 0.0039, 0.0166, 0.0141, 0.0043, 0.0033, 0.0114, 0.0264, 0.0119,\n",
            "         0.0042, 0.0063, 0.8327, 0.0016, 0.0012, 0.0351, 0.0030, 0.0077, 0.0045,\n",
            "         0.0011]], device='cuda:0')\n",
            "tensor([[0.0111, 0.0055, 0.0235, 0.0297, 0.0053, 0.0108, 0.0223, 0.0081, 0.0323,\n",
            "         0.0037, 0.0051, 0.7873, 0.0034, 0.0021, 0.0080, 0.0263, 0.0075, 0.0060,\n",
            "         0.0022]], device='cuda:0')\n",
            "tensor([[0.0318, 0.0318, 0.0477, 0.0245, 0.0216, 0.0229, 0.0386, 0.0219, 0.3969,\n",
            "         0.0041, 0.0082, 0.0703, 0.0070, 0.0047, 0.2203, 0.0124, 0.0168, 0.0149,\n",
            "         0.0036]], device='cuda:0')\n",
            "tensor([[0.0057, 0.0023, 0.0172, 0.0314, 0.0025, 0.0068, 0.0095, 0.0028, 0.0331,\n",
            "         0.0010, 0.0011, 0.8419, 0.0015, 0.0011, 0.0027, 0.0149, 0.0128, 0.0106,\n",
            "         0.0011]], device='cuda:0')\n",
            "tensor([[0.0109, 0.0494, 0.1218, 0.0710, 0.0360, 0.0778, 0.0137, 0.0139, 0.0106,\n",
            "         0.0082, 0.0066, 0.0197, 0.0089, 0.0067, 0.0083, 0.1107, 0.3464, 0.0736,\n",
            "         0.0058]], device='cuda:0')\n",
            "tensor([[0.0105, 0.0471, 0.1070, 0.4401, 0.0561, 0.0524, 0.0241, 0.0115, 0.0629,\n",
            "         0.0032, 0.0041, 0.0962, 0.0033, 0.0049, 0.0169, 0.0228, 0.0254, 0.0098,\n",
            "         0.0017]], device='cuda:0')\n",
            "tensor([[0.0187, 0.0771, 0.0578, 0.1795, 0.1307, 0.0498, 0.0254, 0.0272, 0.0999,\n",
            "         0.0127, 0.0107, 0.0506, 0.0085, 0.0075, 0.0133, 0.0830, 0.0869, 0.0555,\n",
            "         0.0053]], device='cuda:0')\n",
            "tensor([[0.0451, 0.0567, 0.0701, 0.0524, 0.0438, 0.3433, 0.0321, 0.0605, 0.0080,\n",
            "         0.0080, 0.0208, 0.0369, 0.0266, 0.0066, 0.0216, 0.0426, 0.0971, 0.0239,\n",
            "         0.0039]], device='cuda:0')\n",
            "tensor([[0.0117, 0.0608, 0.0900, 0.0718, 0.0345, 0.1258, 0.0578, 0.0194, 0.0423,\n",
            "         0.0063, 0.0073, 0.3122, 0.0098, 0.0061, 0.0099, 0.0488, 0.0565, 0.0246,\n",
            "         0.0045]], device='cuda:0')\n",
            "tensor([[0.0371, 0.0532, 0.0430, 0.0162, 0.0395, 0.0492, 0.0248, 0.0778, 0.0929,\n",
            "         0.0058, 0.0411, 0.0188, 0.0144, 0.0075, 0.4418, 0.0091, 0.0111, 0.0124,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0419, 0.0208, 0.0741, 0.0905, 0.0091, 0.0404, 0.0520, 0.0483, 0.0724,\n",
            "         0.0351, 0.0305, 0.1384, 0.0084, 0.0056, 0.0562, 0.1013, 0.0982, 0.0673,\n",
            "         0.0095]], device='cuda:0')\n",
            "tensor([[4.9803e-03, 4.8419e-03, 7.4982e-03, 6.6057e-03, 6.1907e-03, 9.0679e-03,\n",
            "         1.4129e-02, 1.0049e-02, 8.6372e-01, 1.7681e-03, 4.2720e-03, 1.0979e-02,\n",
            "         1.3037e-03, 1.1104e-03, 4.8152e-02, 1.7169e-03, 1.3457e-03, 1.4127e-03,\n",
            "         8.5627e-04]], device='cuda:0')\n",
            "tensor([[0.0324, 0.0572, 0.0549, 0.0211, 0.0472, 0.1558, 0.0105, 0.0196, 0.0076,\n",
            "         0.0165, 0.0055, 0.0265, 0.0049, 0.0047, 0.0120, 0.1609, 0.2358, 0.1221,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0030, 0.0056, 0.0070, 0.0129, 0.0052, 0.0058, 0.0113, 0.0192, 0.7779,\n",
            "         0.0010, 0.0055, 0.0843, 0.0018, 0.0012, 0.0508, 0.0027, 0.0021, 0.0019,\n",
            "         0.0009]], device='cuda:0')\n",
            "tensor([[0.0237, 0.0144, 0.0593, 0.1745, 0.1026, 0.0581, 0.0467, 0.0460, 0.1500,\n",
            "         0.0052, 0.0083, 0.2301, 0.0091, 0.0034, 0.0211, 0.0166, 0.0122, 0.0141,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0313, 0.0041, 0.0184, 0.0176, 0.0064, 0.0066, 0.0554, 0.0405, 0.2745,\n",
            "         0.0072, 0.0124, 0.2492, 0.0039, 0.0023, 0.2392, 0.0096, 0.0103, 0.0088,\n",
            "         0.0022]], device='cuda:0')\n",
            "tensor([[0.0217, 0.0608, 0.0676, 0.0474, 0.0943, 0.0538, 0.0233, 0.0460, 0.0367,\n",
            "         0.0235, 0.0111, 0.0170, 0.0069, 0.0050, 0.0400, 0.0789, 0.2598, 0.0985,\n",
            "         0.0076]], device='cuda:0')\n",
            "tensor([[0.0326, 0.0490, 0.0856, 0.0734, 0.0347, 0.1204, 0.0116, 0.0195, 0.0275,\n",
            "         0.0054, 0.0089, 0.0765, 0.0077, 0.0043, 0.0085, 0.1577, 0.1840, 0.0888,\n",
            "         0.0040]], device='cuda:0')\n",
            "tensor([[0.0430, 0.0524, 0.0740, 0.0529, 0.1445, 0.1248, 0.0446, 0.1248, 0.0346,\n",
            "         0.0086, 0.0214, 0.0623, 0.0293, 0.0091, 0.0479, 0.0287, 0.0620, 0.0282,\n",
            "         0.0070]], device='cuda:0')\n",
            "tensor([[0.0303, 0.1249, 0.0952, 0.0708, 0.1601, 0.0448, 0.0472, 0.0400, 0.1199,\n",
            "         0.0062, 0.0094, 0.0537, 0.0096, 0.0072, 0.0726, 0.0351, 0.0376, 0.0309,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0273, 0.0360, 0.1218, 0.0857, 0.1880, 0.0740, 0.0175, 0.0149, 0.0142,\n",
            "         0.0124, 0.0100, 0.0729, 0.0116, 0.0044, 0.0161, 0.1653, 0.0675, 0.0552,\n",
            "         0.0051]], device='cuda:0')\n",
            "tensor([[0.0350, 0.1045, 0.0341, 0.0328, 0.0553, 0.0733, 0.0296, 0.0131, 0.1777,\n",
            "         0.0085, 0.0089, 0.0716, 0.0060, 0.0051, 0.0175, 0.1006, 0.1630, 0.0570,\n",
            "         0.0064]], device='cuda:0')\n",
            "tensor([[0.0157, 0.0407, 0.0601, 0.0268, 0.0282, 0.0240, 0.0340, 0.0325, 0.1115,\n",
            "         0.0165, 0.0112, 0.3712, 0.0103, 0.0092, 0.0448, 0.0509, 0.0680, 0.0333,\n",
            "         0.0110]], device='cuda:0')\n",
            "tensor([[0.0181, 0.0155, 0.0247, 0.0248, 0.0106, 0.0145, 0.0625, 0.0540, 0.3801,\n",
            "         0.0083, 0.0189, 0.0871, 0.0065, 0.0039, 0.2390, 0.0108, 0.0071, 0.0106,\n",
            "         0.0031]], device='cuda:0')\n",
            "tensor([[0.0344, 0.0704, 0.0440, 0.0181, 0.0757, 0.0670, 0.0337, 0.0819, 0.2491,\n",
            "         0.0046, 0.0165, 0.0415, 0.0124, 0.0134, 0.1754, 0.0163, 0.0174, 0.0227,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0208, 0.0700, 0.0452, 0.0791, 0.0789, 0.0598, 0.0540, 0.0643, 0.0462,\n",
            "         0.0230, 0.0123, 0.0986, 0.0154, 0.0154, 0.0288, 0.1109, 0.1024, 0.0605,\n",
            "         0.0143]], device='cuda:0')\n",
            "tensor([[0.0250, 0.1029, 0.0773, 0.0497, 0.3222, 0.0655, 0.0161, 0.0128, 0.0160,\n",
            "         0.0137, 0.0089, 0.0137, 0.0090, 0.0103, 0.0197, 0.0961, 0.0922, 0.0420,\n",
            "         0.0067]], device='cuda:0')\n",
            "tensor([[0.0256, 0.0545, 0.1069, 0.0702, 0.0465, 0.0395, 0.0122, 0.0238, 0.0280,\n",
            "         0.0106, 0.0061, 0.1029, 0.0073, 0.0066, 0.0261, 0.1876, 0.1320, 0.1091,\n",
            "         0.0046]], device='cuda:0')\n",
            "tensor([[0.0152, 0.0556, 0.0373, 0.0584, 0.0194, 0.0439, 0.0376, 0.0246, 0.2634,\n",
            "         0.0073, 0.0139, 0.2678, 0.0136, 0.0100, 0.0750, 0.0145, 0.0189, 0.0136,\n",
            "         0.0099]], device='cuda:0')\n",
            "tensor([[0.0043, 0.0086, 0.0117, 0.0288, 0.0063, 0.0085, 0.0107, 0.0116, 0.2282,\n",
            "         0.0039, 0.0043, 0.6386, 0.0027, 0.0024, 0.0108, 0.0081, 0.0058, 0.0034,\n",
            "         0.0013]], device='cuda:0')\n",
            "tensor([[0.0136, 0.0097, 0.0584, 0.0760, 0.0155, 0.0090, 0.0167, 0.0274, 0.1153,\n",
            "         0.0065, 0.0043, 0.4724, 0.0052, 0.0031, 0.0793, 0.0255, 0.0477, 0.0124,\n",
            "         0.0020]], device='cuda:0')\n",
            "tensor([[0.0202, 0.0153, 0.0283, 0.0416, 0.0058, 0.0156, 0.0794, 0.0325, 0.0680,\n",
            "         0.0156, 0.0210, 0.5673, 0.0051, 0.0040, 0.0343, 0.0183, 0.0128, 0.0111,\n",
            "         0.0037]], device='cuda:0')\n",
            "tensor([[0.0167, 0.0660, 0.0446, 0.0690, 0.0438, 0.2022, 0.0450, 0.0126, 0.1258,\n",
            "         0.0153, 0.0093, 0.1047, 0.0175, 0.0063, 0.0190, 0.0870, 0.0698, 0.0362,\n",
            "         0.0094]], device='cuda:0')\n",
            "tensor([[0.0552, 0.0248, 0.0965, 0.1193, 0.0398, 0.0438, 0.0411, 0.0634, 0.0586,\n",
            "         0.0102, 0.0136, 0.2511, 0.0149, 0.0050, 0.0328, 0.0529, 0.0525, 0.0202,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0241, 0.0665, 0.0470, 0.0826, 0.0366, 0.0439, 0.1000, 0.0106, 0.0432,\n",
            "         0.0067, 0.0079, 0.4298, 0.0044, 0.0061, 0.0176, 0.0287, 0.0207, 0.0186,\n",
            "         0.0050]], device='cuda:0')\n",
            "tensor([[0.0334, 0.1198, 0.1390, 0.0389, 0.1726, 0.1715, 0.0271, 0.0284, 0.0113,\n",
            "         0.0071, 0.0069, 0.0444, 0.0134, 0.0078, 0.0197, 0.0419, 0.0779, 0.0347,\n",
            "         0.0044]], device='cuda:0')\n",
            "tensor([[0.0210, 0.1248, 0.0903, 0.0863, 0.1554, 0.0382, 0.0216, 0.0140, 0.0365,\n",
            "         0.0051, 0.0051, 0.0779, 0.0075, 0.0081, 0.0345, 0.1244, 0.0835, 0.0618,\n",
            "         0.0039]], device='cuda:0')\n",
            "tensor([[0.0097, 0.0774, 0.0403, 0.0473, 0.5360, 0.0943, 0.0147, 0.0198, 0.0226,\n",
            "         0.0021, 0.0057, 0.0553, 0.0114, 0.0036, 0.0148, 0.0197, 0.0165, 0.0067,\n",
            "         0.0021]], device='cuda:0')\n",
            "tensor([[0.0161, 0.1167, 0.0955, 0.0515, 0.1058, 0.0881, 0.0095, 0.0104, 0.0057,\n",
            "         0.0192, 0.0073, 0.0301, 0.0059, 0.0058, 0.0085, 0.1118, 0.2564, 0.0496,\n",
            "         0.0062]], device='cuda:0')\n",
            "tensor([[0.0113, 0.0047, 0.0635, 0.0611, 0.0064, 0.0103, 0.0313, 0.0419, 0.0299,\n",
            "         0.0018, 0.0059, 0.6774, 0.0050, 0.0014, 0.0235, 0.0075, 0.0084, 0.0075,\n",
            "         0.0010]], device='cuda:0')\n",
            "tensor([[0.0367, 0.0342, 0.0283, 0.0291, 0.0558, 0.0267, 0.0596, 0.0481, 0.1572,\n",
            "         0.0178, 0.0149, 0.3706, 0.0075, 0.0060, 0.0478, 0.0225, 0.0222, 0.0117,\n",
            "         0.0033]], device='cuda:0')\n",
            "tensor([[0.0240, 0.0253, 0.0957, 0.2100, 0.0124, 0.1720, 0.0185, 0.0174, 0.0056,\n",
            "         0.0108, 0.0079, 0.0816, 0.0144, 0.0040, 0.0057, 0.1703, 0.0881, 0.0306,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0276, 0.1165, 0.0857, 0.0547, 0.1325, 0.0533, 0.0970, 0.0219, 0.0408,\n",
            "         0.0078, 0.0169, 0.0812, 0.0177, 0.0096, 0.0628, 0.0758, 0.0564, 0.0356,\n",
            "         0.0061]], device='cuda:0')\n",
            "tensor([[0.0263, 0.0752, 0.0645, 0.0653, 0.3100, 0.0397, 0.0213, 0.0207, 0.0546,\n",
            "         0.0130, 0.0059, 0.0211, 0.0055, 0.0045, 0.0254, 0.0667, 0.1008, 0.0750,\n",
            "         0.0043]], device='cuda:0')\n",
            "tensor([[3.8405e-03, 2.0851e-01, 2.3452e-01, 7.4444e-02, 3.8701e-02, 2.7481e-02,\n",
            "         9.5646e-03, 9.5907e-03, 2.5965e-01, 3.4948e-04, 9.0064e-04, 2.9227e-02,\n",
            "         3.3190e-04, 1.3271e-03, 2.7592e-02, 2.8281e-02, 3.5374e-02, 1.0142e-02,\n",
            "         1.7436e-04]], device='cuda:0')\n",
            "tensor([[0.0278, 0.0300, 0.0729, 0.1227, 0.0234, 0.1005, 0.0135, 0.0078, 0.0060,\n",
            "         0.0058, 0.0037, 0.0524, 0.0086, 0.0046, 0.0070, 0.2499, 0.1742, 0.0836,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0379, 0.0299, 0.0844, 0.0623, 0.0220, 0.0375, 0.0405, 0.0811, 0.1794,\n",
            "         0.0400, 0.0278, 0.0399, 0.0096, 0.0051, 0.1658, 0.0425, 0.0438, 0.0438,\n",
            "         0.0066]], device='cuda:0')\n",
            "tensor([[0.0138, 0.1260, 0.0645, 0.0344, 0.3450, 0.0769, 0.0483, 0.0232, 0.0315,\n",
            "         0.0076, 0.0079, 0.0189, 0.0231, 0.0087, 0.0302, 0.0529, 0.0646, 0.0157,\n",
            "         0.0068]], device='cuda:0')\n",
            "tensor([[0.0147, 0.1359, 0.1093, 0.0903, 0.2734, 0.0565, 0.0145, 0.0048, 0.0201,\n",
            "         0.0037, 0.0030, 0.0266, 0.0040, 0.0055, 0.0068, 0.1385, 0.0454, 0.0443,\n",
            "         0.0026]], device='cuda:0')\n",
            "tensor([[0.0103, 0.1566, 0.1207, 0.0360, 0.3649, 0.0915, 0.0059, 0.0033, 0.0061,\n",
            "         0.0054, 0.0031, 0.0112, 0.0077, 0.0049, 0.0051, 0.0626, 0.0886, 0.0134,\n",
            "         0.0027]], device='cuda:0')\n",
            "tensor([[0.0434, 0.0544, 0.0696, 0.1254, 0.0699, 0.1065, 0.0297, 0.0389, 0.0228,\n",
            "         0.0460, 0.0273, 0.1431, 0.0120, 0.0080, 0.0229, 0.0703, 0.0612, 0.0419,\n",
            "         0.0065]], device='cuda:0')\n",
            "tensor([[0.0232, 0.0306, 0.0572, 0.1804, 0.0321, 0.0323, 0.0423, 0.0087, 0.0772,\n",
            "         0.0117, 0.0116, 0.4058, 0.0065, 0.0045, 0.0131, 0.0316, 0.0138, 0.0129,\n",
            "         0.0045]], device='cuda:0')\n",
            "tensor([[0.0409, 0.0493, 0.1091, 0.1025, 0.1679, 0.1092, 0.0492, 0.0345, 0.0146,\n",
            "         0.0079, 0.0101, 0.0517, 0.0203, 0.0084, 0.0265, 0.0730, 0.0986, 0.0209,\n",
            "         0.0056]], device='cuda:0')\n",
            "tensor([[0.0262, 0.0424, 0.0452, 0.1558, 0.1642, 0.0648, 0.0386, 0.0306, 0.0662,\n",
            "         0.0117, 0.0136, 0.0681, 0.0115, 0.0059, 0.0126, 0.1613, 0.0512, 0.0260,\n",
            "         0.0041]], device='cuda:0')\n",
            "tensor([[0.0427, 0.0801, 0.0510, 0.0345, 0.2867, 0.1615, 0.0246, 0.0410, 0.0296,\n",
            "         0.0091, 0.0139, 0.0417, 0.0192, 0.0078, 0.0274, 0.0361, 0.0704, 0.0169,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0384, 0.0611, 0.0334, 0.0231, 0.0975, 0.0320, 0.0327, 0.0965, 0.2609,\n",
            "         0.0055, 0.0215, 0.0250, 0.0131, 0.0090, 0.2056, 0.0135, 0.0162, 0.0103,\n",
            "         0.0048]], device='cuda:0')\n",
            "tensor([[0.0123, 0.0940, 0.1122, 0.1504, 0.2558, 0.0675, 0.0227, 0.0114, 0.0475,\n",
            "         0.0024, 0.0027, 0.0549, 0.0026, 0.0039, 0.0224, 0.0780, 0.0368, 0.0208,\n",
            "         0.0015]], device='cuda:0')\n",
            "tensor([[0.0150, 0.0806, 0.1792, 0.1416, 0.0871, 0.1268, 0.0100, 0.0105, 0.0079,\n",
            "         0.0051, 0.0039, 0.0182, 0.0044, 0.0045, 0.0067, 0.1478, 0.1049, 0.0436,\n",
            "         0.0022]], device='cuda:0')\n",
            "tensor([[0.0133, 0.0866, 0.0880, 0.1104, 0.1315, 0.1274, 0.0269, 0.0162, 0.0383,\n",
            "         0.0082, 0.0153, 0.0591, 0.0266, 0.0086, 0.0101, 0.0770, 0.1159, 0.0328,\n",
            "         0.0080]], device='cuda:0')\n",
            "tensor([[0.0089, 0.1283, 0.0422, 0.0404, 0.3629, 0.0249, 0.0153, 0.0098, 0.0657,\n",
            "         0.0096, 0.0032, 0.0169, 0.0048, 0.0045, 0.0092, 0.1419, 0.0591, 0.0485,\n",
            "         0.0040]], device='cuda:0')\n",
            "tensor([[0.0204, 0.0759, 0.0951, 0.1277, 0.1849, 0.0546, 0.0179, 0.0127, 0.0619,\n",
            "         0.0137, 0.0067, 0.0137, 0.0066, 0.0070, 0.0219, 0.1249, 0.0589, 0.0897,\n",
            "         0.0057]], device='cuda:0')\n",
            "tensor([[0.0318, 0.0343, 0.0715, 0.1003, 0.0474, 0.0270, 0.0427, 0.0353, 0.1141,\n",
            "         0.0197, 0.0181, 0.2740, 0.0069, 0.0053, 0.0684, 0.0448, 0.0326, 0.0211,\n",
            "         0.0049]], device='cuda:0')\n",
            "tensor([[0.0131, 0.0055, 0.0094, 0.0197, 0.0085, 0.0110, 0.0391, 0.0892, 0.0698,\n",
            "         0.0016, 0.0077, 0.5423, 0.0074, 0.0020, 0.1590, 0.0025, 0.0073, 0.0034,\n",
            "         0.0017]], device='cuda:0')\n",
            "tensor([[0.0168, 0.0889, 0.0864, 0.0506, 0.0761, 0.0762, 0.0647, 0.0539, 0.0383,\n",
            "         0.0082, 0.0283, 0.2088, 0.0227, 0.0110, 0.0676, 0.0299, 0.0509, 0.0153,\n",
            "         0.0055]], device='cuda:0')\n",
            "tensor([[0.0213, 0.0734, 0.0463, 0.0605, 0.1290, 0.0699, 0.0422, 0.0311, 0.1422,\n",
            "         0.0086, 0.0160, 0.1909, 0.0104, 0.0102, 0.0704, 0.0199, 0.0322, 0.0197,\n",
            "         0.0058]], device='cuda:0')\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[72], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtrained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#applying softmax to model logits. This is done implicitley during the training\u001b[39;00m\n\u001b[0;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\inception.py:166\u001b[0m, in \u001b[0;36mInception3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InceptionOutputs:\n\u001b[0;32m    165\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_input(x)\n\u001b[1;32m--> 166\u001b[0m     x, aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     aux_defined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_logits\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\inception.py:140\u001b[0m, in \u001b[0;36mInception3._forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    138\u001b[0m         aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAuxLogits(x)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# N x 768 x 17 x 17\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMixed_7a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# N x 1280 x 8 x 8\u001b[39;00m\n\u001b[0;32m    142\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMixed_7b(x)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\inception.py:317\u001b[0m, in \u001b[0;36mInceptionD.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    316\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(x)\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_file = 'trained_model.pth'\n",
        "trained_model, _ = initialize_inception_model(num_classes, feature_extract, use_pretrained=True)\n",
        "trained_model.load_state_dict(torch.load(model_file))\n",
        "trained_model.to(device)\n",
        "trained_model.eval()\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = trained_model(images)\n",
        "        #applying softmax to model logits. This is done implicitley during the training but not during evaluation\n",
        "        outputs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"Number of test predictions:\", total_predictions)\n",
        "print(f\"Accuracy on the test dataset: {accuracy:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=19, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=19, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(trained_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNV3MXGUZOrTXYIMUGxxCsi",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
