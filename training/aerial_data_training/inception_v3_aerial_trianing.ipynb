{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download(r'https://drive.google.com/file/d/1-7lEmQDmf06beJUD3NaQk82125NGqYpm/view?usp=drive_link', r'../../data/aerial_data/val_labels.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1-54Z1sN8uYgNG66MwWumRTlYMJmX7wWw/view?usp=drive_link', r'../../data/aerial_data/val_images.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1vKs-th9eHU_oMXTasVm-FD9Dximer82Q/view?usp=drive_link', r'../../data/aerial_data/train_labels.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1aJkI-7d5KCAAYCoXkrEcHVXvSsXc_-8n/view?usp=drive_link', r'../../data/aerial_data/train_images.npy',fuzzy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading numpy files from memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "#system specific\n",
        "folder = r\"C:\\Users\\bench\\OneDrive\\Documents\\EMAT Year 3\\MDM3\\Phase C\\ratio_adjusted_aerial_dataset\"\n",
        "train_images = np.load(os.path.join(folder, 'train_images.npy'))\n",
        "train_labels = np.load(os.path.join(folder, 'train_labels.npy'))\n",
        "val_images = np.load(os.path.join(folder, 'val_images.npy'))\n",
        "val_labels = np.load(os.path.join(folder, 'val_labels.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zFEOXefkLVV",
        "outputId": "0d22abcb-ead4-4531-a9a7-7379b33404c8"
      },
      "outputs": [],
      "source": [
        "#inspecting data\n",
        "print(\"train data:\")\n",
        "print(\"images shape:\")\n",
        "print(train_images.shape)\n",
        "print(\"labels shape:\")\n",
        "print(train_labels.shape)\n",
        "\n",
        "#print(\"test data:\")\n",
        "#print(\"images shape:\")\n",
        "#print(test_images.shape)\n",
        "#print(\"labels shape:\")\n",
        "#print(test_labels.shape)\n",
        "\n",
        "print(\"val data:\")\n",
        "print(\"images shape:\")\n",
        "print(val_images.shape)\n",
        "print(\"labels shape:\")\n",
        "print(val_labels.shape)\n",
        "\n",
        "print(\"image format check:\")\n",
        "print(train_images[0,:,:,0])\n",
        "\n",
        "print(\"label check:\")\n",
        "print(train_labels[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhZptPJtcRl5"
      },
      "source": [
        "# Performing Feature Extraction on Inception-V3, which is currently trained on image net\n",
        "Adapted from: <https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/finetuning_torchvision_models_tutorial.ipynb#scrollTo=NiFT4EYmprqG>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HzgA5ZHDUKo"
      },
      "source": [
        "# Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYkVMsSdcXlF",
        "outputId": "50a4c307-1d55-46d0-a133-67aa651d0f24"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torchvision import  transforms\n",
        "\n",
        "# Number of tree species categories\n",
        "num_classes = 19\n",
        "\n",
        "# Batch size for training (should be a power of 2 if training on the GPU and is limited by memory)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 100\n",
        "\n",
        "#True if we are just training the output layer of the network\n",
        "feature_extract = True\n",
        "\n",
        "print(\"cuda is available = \",torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMnqaEq2ibRf"
      },
      "source": [
        "# Defining function to reshape the model to account for the number of classes\n",
        "By default Inception-v3 has 1000 classes as it is trained on imageNet, whilst our dataset has 19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvCE732PQME9"
      },
      "source": [
        "# Initializing Custom Inception-V3Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdqIslSxQF09",
        "outputId": "578c2b85-4a50-49de-b584-a22c3bfe9a98"
      },
      "outputs": [],
      "source": [
        "from training_funcs import initialize_inception_model\n",
        "\n",
        "model_ft, input_size = initialize_inception_model(num_classes, feature_extract, use_pretrained=True)\n",
        "print(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc8biARA66oL"
      },
      "source": [
        "# Formatting Loaded Data and creating data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#from PIL import Image\n",
        "#converting numpy arrays to PIL images\n",
        "#train_images_pil = [Image.fromarray(image) for image in train_images]\n",
        "#val_images_pil = [Image.fromarray(image) for image in val_images]\n",
        "#creating one hot encoding labels from numpy arrays\n",
        "train_categories, train_labels_numeric = np.unique(train_labels, return_inverse=True)\n",
        "val_categories, val_labels_numeric = np.unique(val_labels, return_inverse=True)\n",
        "\n",
        "print(\"Train Categories:\", train_categories)\n",
        "print(\"Train Labels Numeric:\", train_labels_numeric[0:10])\n",
        "print(\"Val Categories:\", val_categories)\n",
        "print(\"Val Labels Numeric:\", val_labels_numeric[0:10])\n",
        "print(train_labels_numeric.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if np.all(train_categories == val_categories):\n",
        "    print(\"categories are consistent between train and val sets\")\n",
        "    categories = train_categories = val_categories\n",
        "else:\n",
        "    raise ValueError(\"Train and val categories don't match\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iBUGQu37VXm",
        "outputId": "52176e3f-8f40-4acd-9999-3c833de0f5a8"
      },
      "outputs": [],
      "source": [
        "# normalization for training and validation\n",
        "# right now validation and training transform is the same and no augmentation\n",
        "# Calculate mean and std for 4-channel images\n",
        "\n",
        "#mean = np.mean(train_images[:,:,:,3], axis=(0, 1, 2)) / 255  # divide by 255 to normalize between 0 and 1\n",
        "#std = np.std(train_images[:,:,:,3], axis=(0, 1, 2)) / 255\n",
        "#print(\"Mean: \", mean)\n",
        "#print(\"Std: \", std)\n",
        "\n",
        "#Consider using standard ImageNet normalization values for RGB channels\n",
        "#rgb_mean = [0.485, 0.456, 0.406] \n",
        "#rgb_std = [0.229, 0.224, 0.225]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import training_funcs\n",
        "\n",
        "#creating training and validation pytorch datasets\n",
        "training_dataset = training_funcs.CustomDataset(train_images, train_labels_numeric, input_size)\n",
        "val_dataset = training_funcs.CustomDataset(val_images, val_labels_numeric, input_size)\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True),\n",
        "                    'val': torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIbdexT1A2l8"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxVIfck-A54U",
        "outputId": "e37efeb0-d405-4b4e-d3fe-cff967a9b7df"
      },
      "outputs": [],
      "source": [
        "## Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"sending model to\",device)\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Creating the Optimizer\n",
        "if feature_extract:\n",
        "  params_to_update = []\n",
        "  for name,param in model_ft.named_parameters():\n",
        "    if param.requires_grad==True:\n",
        "      params_to_update.append(param)\n",
        "      print(\"\\t\",name)\n",
        "else:\n",
        "  params_to_update = model_ft.parameters()\n",
        "\n",
        "print(\"number of parameters to train =\",len(params_to_update))\n",
        "for i, param in enumerate(params_to_update):\n",
        "  print(\"parameter {}:\".format(i),param.shape)\n",
        "\n",
        "optimizer_ft = optim.AdamW(params_to_update, lr=0.01, betas=(0.8, 0.99), weight_decay=0.001)\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcrgqxB0tf9E",
        "outputId": "b811be3e-cb65-4996-ec9c-6a62127fe24b"
      },
      "outputs": [],
      "source": [
        "from training_funcs import train_model\n",
        "#fixing random seed for consistent results\n",
        "torch.manual_seed(0)\n",
        "\n",
        "#creating a tensorboard writer for logging\n",
        "#from torch.utils.tensorboard import SummaryWriter\n",
        "#writer = SummaryWriter(\"runs/train_run_test\")\n",
        "# Train and evaluate\n",
        "model_ft, convergence_dict = train_model(model_ft,\n",
        "                             dataloaders_dict,\n",
        "                             criterion,\n",
        "                             optimizer_ft,\n",
        "                             num_epochs=num_epochs,\n",
        "                             is_inception=True,\n",
        "                             tensorboard_writer=None,\n",
        "                             early_stopping=False,\n",
        "                             device=device)\n",
        "\n",
        "\n",
        "filename = \"temp.pth\"\n",
        "if not os.path.exists(filename) or filename == \"temp.pth\":\n",
        "    torch.save(model_ft.state_dict(),filename)\n",
        "else:\n",
        "    print(\"model file already exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(acc_hist)\n",
        "print(loss_hist)\n",
        "\n",
        "for entry in acc_hist:\n",
        "  entry = entry.cpu().detach().numpy()\n",
        "\n",
        "acc_hist_array = np.array(loss_hist)\n",
        "\n",
        "plt.plot(acc_hist_array,\"x-\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"AdamW w. lr=0.01, betas=[0.8,0.99], w_decay=0.001\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Search Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "import random\n",
        "\n",
        "def adamRandomSearch(model_ft, result_file, max_epochs=100, stop_tol=1e-3, patience=2, parameters=None):\n",
        "    #initializing model\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"sending model to\",device)\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    params_to_update = []\n",
        "    \n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad==True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "    \n",
        "    # fixing the random seed for PyTorch\n",
        "    torch.manual_seed(42)\n",
        "    # fixing the random seed for NumPy\n",
        "    np.random.seed(42)\n",
        "    #fixing the random seed for the random module\n",
        "    random.seed(42)\n",
        "    try:\n",
        "        count = 0\n",
        "        while True:\n",
        "            print(\"Random search iteration: \", count)\n",
        "            # not fixing the random seed for choosing hyperparameters so that seperate runs are independent\n",
        "            rng = np.random.default_rng()\n",
        "            lr = rng.choice(parameters[\"lr\"])\n",
        "            beta1 = rng.choice(parameters[\"beta1\"])\n",
        "            beta2 = rng.choice(parameters[\"beta2\"])\n",
        "            weight_decay = rng.choice(parameters[\"weight_decay\"])\n",
        "            batch_size = int(rng.choice(parameters[\"batch_size\"]))\n",
        "            print(\"parameters: lr = \", lr, \"beta1 = \", beta1, \"beta2 = \", beta2, \"weight_decay = \", weight_decay, \"batch_size = \", batch_size)\n",
        "            #setting optimizer and dataloaders\n",
        "            optimizer = optim.AdamW(params_to_update, lr=lr, betas=(beta1, beta2), weight_decay=weight_decay)\n",
        "            dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True),\n",
        "                                'val': torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)}\n",
        "            # Train and evaluate\n",
        "            model_ft, convergence_dict, epoch = train_model(model_ft,\n",
        "                                                                dataloaders_dict,\n",
        "                                                                criterion,\n",
        "                                                                optimizer,\n",
        "                                                                num_epochs=max_epochs,\n",
        "                                                                is_inception=True,\n",
        "                                                                early_stopping=True,\n",
        "                                                                patience=patience,\n",
        "                                                                stop_tol=stop_tol)\n",
        "                \n",
        "            # Append the result to a new line of the CSV file\n",
        "            with open(result_file, \"a\", newline='') as file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow([epoch, max(convergence_dict[\"val_acc\"]), min(convergence_dict[\"val_loss\"]), lr, beta1, beta2, weight_decay, batch_size])                \n",
        "\n",
        "            count += 1\n",
        "            \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Random search stopped\")\n",
        "        return\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running the Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#setting hyperparameters to search over\n",
        "parameters={\"lr\":np.array([0.0001,0.0005,0.001,0.005,0.01,]),\n",
        "            \"beta1\":np.array([0.7,0.75,0.8,0.85,0.9,0.95,0.99]),\n",
        "            \"beta2\":np.array([0.9,0.95,0.99,0.995,0.999]),\n",
        "            \"weight_decay\":np.array([0,0.0001,0.001,0.01,0.015,0.1,0.2]),\n",
        "            \"batch_size\":np.array([8,16,32,64],dtype=int)}\n",
        "#running random search. Can be stopped and started at whim, but the file \"random_search.csv\"\n",
        "#must exist in the current working directory\n",
        "adamRandomSearch(model_ft,\"random_search_2.csv\",max_epochs=50,stop_tol=1e-3,patience=3,parameters=parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualizing the dataset and model layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#visuallizing training data\n",
        "# Select 20 random indices\n",
        "random_indices = random.sample(range(train_images.shape[0]), 20)\n",
        "plt.tight_layout()\n",
        "\n",
        "print(\"----unnormalized images from training data----\")\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
        "for i, ax in zip(random_indices, axes.flatten()):\n",
        "    ax.imshow(train_images[i,:,:,1:])\n",
        "    ax.set_title(train_labels[i])  # Add title to each image\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n",
        "print(\"----normalized images from training data----\")\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
        "for i, ax in zip(random_indices, axes.flatten()):\n",
        "    \n",
        "    ax.imshow(training_dataset[i][0].permute(1, 2, 0))\n",
        "    ax.set_title(train_labels[i])  # Add title to each image\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n",
        "print(\"----denormalized images from training data----\")\n",
        "unorm = transforms.Normalize(-np.divide(mean,std), 1/std)\n",
        "\n",
        "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
        "for i, ax in zip(random_indices, axes.flatten()):\n",
        "    image = unorm(training_dataset[i][0])\n",
        "    \n",
        "    ax.imshow(image[1:,:,:].permute(1, 2, 0))\n",
        "    ax.set_title(train_labels[i])  # Add title to each image\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"----first layer embeddings from training data----\")\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
        "for i, ax in zip(random_indices, axes.flatten()):\n",
        "    image_4c = training_dataset[i][0]\n",
        "    image_3c = model_ft.pre_layer.input_conv(image_4c)\n",
        "    ax.imshow(image_3c.detach().permute(1, 2, 0))\n",
        "    ax.set_title(train_labels[i])  # Add title to each image\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"----first layer embeddings from training data: unnormalized----\")\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
        "for i, ax in zip(random_indices, axes.flatten()):\n",
        "    unorm2 = transforms.Normalize(-np.divide(mean[1:],std[1:]), 1/std[1:])\n",
        "    image_4c = training_dataset[i][0]\n",
        "    image_3c = model_ft.pre_layer.input_conv(image_4c)\n",
        "    img = unorm2(image_3c.detach())\n",
        "    ax.imshow(img.permute(1, 2, 0))\n",
        "    ax.set_title(train_labels[i])  # Add title to each image\n",
        "    ax.axis('off')\n",
        "\n",
        "# print(\"train_images shape:\",train_images.shape)\n",
        "# for i in range(10):\n",
        "#     writer.add_images('unnormalized_images, batch {}'.format(i),\n",
        "#                         train_images[(i*20):(i*20+20),:,:,1:],\n",
        "#                         i,\n",
        "#                         dataformats='NHWC')\n",
        "\n",
        "# for i in range(10):\n",
        "#     writer.add_images('first_layer_embedding_normalized_3',\n",
        "#                         training_dataset[i][0][:3,:,:], \n",
        "#                         i,\n",
        "#                         dataformats='CHW'\n",
        "#     )\n",
        "\n",
        "# for i in range(10):\n",
        "#     image_4c = training_dataset[i][0]\n",
        "#     image_3c = model_ft.pre_layer.input_conv(image_4c)\n",
        "#     writer.add_images('first_layer_embedding',\n",
        "#                         image_3c, \n",
        "#                         i,\n",
        "#                         dataformats='CHW'\n",
        "#     )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download(r'https://drive.google.com/file/d/1-4ZKGtGrWCEfaRDBobEgeQJmtdJIFobi/view?usp=drive_link', r'../../data/aerial_data/test_labels.npy',fuzzy=True)\n",
        "gdown.download(r'https://drive.google.com/file/d/1-01C3LjzGSz7QGzvharc52yZRwEgMzni/view?usp=drive_link', r'../../data/aerial_data/test_images.npy',fuzzy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "print(os.getcwd())\n",
        "test_labels = np.load('../../data/aerial_data/test_labels.npy')\n",
        "test_images = np.load('../../data/aerial_data/test_images.npy')\n",
        "\n",
        "#converting numpy arrays into RGB PIL images, ignoring the IR channel for now\n",
        "test_images_pil = [Image.fromarray(image) for image in test_images]\n",
        "#creating one hot encoding labels from numpy arrays\n",
        "test_categories, test_categories_numeric = np.unique(test_labels, return_inverse=True)\n",
        "\n",
        "print(\"Test Categories:\", test_categories)\n",
        "print(\"train Categories:\", train_categories)\n",
        "\n",
        "test_dataset = CustomDataset(test_images_pil, test_categories_numeric, image_transform)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### evaluating on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_file = 'training_run_2_4_channels.pth'\n",
        "trained_model, _ = initialize_inception_model(num_classes, feature_extract, use_pretrained=True)\n",
        "trained_model.load_state_dict(torch.load(model_file))\n",
        "trained_model.to(device)\n",
        "trained_model.eval()\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = trained_model(images)\n",
        "        #applying softmax to model logits. This is done implicitley during the training but not during evaluation\n",
        "        outputs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"Number of test predictions:\", total_predictions)\n",
        "print(f\"Accuracy on the test dataset: {accuracy:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(trained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting logits from trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "eval_images = np.load(r\"C:\\Users\\bench\\OneDrive\\Documents\\EMAT Year 3\\MDM3\\Phase C\\ratio_adjusted_aerial_dataset\\aerial_99_images.npy\")\n",
        "eval_labels = np.load(r\"C:\\Users\\bench\\OneDrive\\Documents\\EMAT Year 3\\MDM3\\Phase C\\ratio_adjusted_aerial_dataset\\aerial_99_labels.npy\")\n",
        "model_file = r\"C:\\Users\\bench\\OneDrive\\Documents\\GitHub\\MDM3-Rep-3\\training\\aerial_data_training\\training_run_3_filtered_data.pth\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "trained_model, _ = initialize_inception_model(num_classes, feature_extract, use_pretrained=True)\n",
        "trained_model.load_state_dict(torch.load(model_file))\n",
        "trained_model.to(device)\n",
        "trained_model.eval()\n",
        "\n",
        "\n",
        "eval_categories, eval_categories_numeric = np.unique(eval_labels, return_inverse=True)\n",
        "\n",
        "test_dataset = CustomDataset(eval_images, eval_categories_numeric, image_transform)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "eval_logits = np.zeros((len(eval_labels), num_classes))\n",
        "with torch.no_grad():\n",
        "    i=0\n",
        "    for image, _ in test_dataloader:\n",
        "        image = image.to(device)\n",
        "        output = trained_model(image)\n",
        "        eval_logits[i,:] = output.cpu().numpy()\n",
        "        i+=1\n",
        "\n",
        "print(eval_logits.shape)\n",
        "print(eval_logits[0,:])        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(\"aerial_99_logits.npy\", eval_logits)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNV3MXGUZOrTXYIMUGxxCsi",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
